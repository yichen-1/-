import streamlit as st
import pandas as pd
import re
from datetime import datetime
import warnings
import pdfplumber
from io import BytesIO

# å¿½ç•¥æ ·å¼è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl.stylesheet")

# ---------------------- æ ¸å¿ƒé…ç½®ï¼ˆç²¾å‡†é€‚é…PDFç»“æ„ï¼‰ ----------------------
SPECIAL_TRADE_KEYWORDS = ['ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨', 'çœé—´çœå†…ä»·å·®è´¹ç”¨']  # ç²¾ç¡®åŒ¹é…ç‰¹æ®Šç§‘ç›®å
INVALID_LINE_KEYWORDS = ['hf', 'HF', 'å¿', 'é•‡', 'ä¹¡', 'æ‘', '_', 'â€”', 'é¡µç ']
TRADE_HEADER_KEYWORDS = ['ç§‘ç›®ç¼–ç ', 'ç»“ç®—ç±»å‹', 'ç”µé‡']  # è¡¨å¤´éœ€åŒ…å«ç”µé‡ï¼Œé¿å…è¯¯åˆ¤
STATION_PATTERN = r'æœºç»„\s*[:ï¼š]?\s*([^:ï¼š\n]{2,15}é£ç”µåœº)'  # é€‚é…â€œæœºç»„ï¼šåŒå‘Bé£ç”µåœºâ€ç­‰æ ¼å¼
COLUMN_SPLIT_PATTERN = r'\s{2,}'  # ä»…ç”¨2ä¸ªä»¥ä¸Šç©ºæ ¼åˆ†å‰²åˆ—ï¼Œé¿å…ç§‘ç›®åå†…ç©ºæ ¼å¹²æ‰°

# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° ----------------------
def safe_convert_to_numeric(value, default=None):
    """å®‰å…¨è½¬æ¢æ•°å€¼ï¼Œç©ºå€¼è¿”å›None"""
    try:
        if pd.notna(value) and value is not None:
            str_val = str(value).strip()
            if str_val in ['/', 'NA', 'None', '', 'æ— ', 'â€”â€”', '0.00', '-', 'ç©º']:
                return default
            cleaned_value = str_val.replace(',', '').replace(' ', '').strip()
            return pd.to_numeric(cleaned_value) if cleaned_value else default
        return default
    except (ValueError, TypeError):
        return default

def filter_invalid_lines(pdf_lines):
    """è¿‡æ»¤æ— æ•ˆè¡Œï¼Œä¿ç•™æœ‰æ•ˆæ•°æ®è¡Œ"""
    valid_lines = []
    for line in pdf_lines:
        line = line.replace('\t', ' ').strip()
        # è¿‡æ»¤ï¼šè¿‡çŸ­è¡Œã€å«æ— æ•ˆå…³é”®è¯ã€çº¯æ•°å­—è¡Œ
        if (len(line) >= 5 
            and not any(kw in line for kw in INVALID_LINE_KEYWORDS)
            and not line.replace('.', '').replace('-', '').isdigit()):
            valid_lines.append(line)
    return valid_lines

def extract_basic_info(pdf_lines):
    """æå–å…¬å¸åç§°ã€æ¸…åˆ†æ—¥æœŸã€æ–‡ä»¶åˆè®¡æ•°æ®"""
    company_name = "æœªçŸ¥å…¬å¸"
    clear_date = None
    total_quantity = None
    total_fee = None

    # æå–å…¬å¸åç§°ï¼ˆç²¾ç¡®åŒ¹é…â€œå…¬å¸åç§°ï¼šXXXæœ‰é™å…¬å¸â€ï¼‰
    for line in pdf_lines:
        if "å…¬å¸åç§°" in line and ("ï¼š" in line or ":" in line):
            comp_match = re.search(r'å…¬å¸åç§°[:ï¼š]\s*([\u4e00-\u9fa5a-zA-Z0-9()ï¼ˆï¼‰]+æœ‰é™å…¬å¸)', line)
            if comp_match:
                company_name = comp_match.group(1).strip()
                break

    # æå–æ¸…åˆ†æ—¥æœŸ
    date_pattern = r'æ¸…åˆ†æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{2}-\d{2})'
    for line in pdf_lines:
        date_match = re.search(date_pattern, line)
        if date_match:
            clear_date = date_match.group(1)
            break

    # æå–æ–‡ä»¶åˆè®¡ç”µé‡/ç”µè´¹ï¼ˆç²¾ç¡®åŒ¹é…â€œåˆè®¡ç”µé‡ï¼šXXX åˆè®¡ç”µè´¹ï¼šXXXâ€ï¼‰
    total_pattern = r'åˆè®¡ç”µé‡[:ï¼š]\s*(\S+)\s+åˆè®¡ç”µè´¹[:ï¼š]\s*(\S+)'
    for line in pdf_lines:
        total_match = re.search(total_pattern, line)
        if total_match:
            total_quantity = safe_convert_to_numeric(total_match.group(1))
            total_fee = safe_convert_to_numeric(total_match.group(2))
            break

    return company_name, clear_date, total_quantity, total_fee

# ---------------------- åœºç«™ä¸ç§‘ç›®æå–æ ¸å¿ƒé€»è¾‘ ----------------------
def is_special_trade(trade_name):
    """ç²¾ç¡®åˆ¤æ–­æ˜¯å¦ä¸ºç‰¹æ®Šç§‘ç›®ï¼ˆæ— ç”µé‡/ç”µä»·ï¼‰"""
    return any(special_name in trade_name for special_name in SPECIAL_TRADE_KEYWORDS)

def extract_trade_data(line, in_special_area=False):
    """
    ç²¾å‡†æå–ç§‘ç›®æ•°æ®ï¼š
    - å¸¸è§„ç§‘ç›®ï¼š5åˆ—ï¼ˆç¼–ç +åç§°+ç”µé‡+ç”µä»·+ç”µè´¹ï¼‰
    - ç‰¹æ®Šç§‘ç›®ï¼š3åˆ—ï¼ˆç¼–ç +åç§°+ç”µè´¹ï¼‰
    """
    line_cols = [col.strip() for col in re.split(COLUMN_SPLIT_PATTERN, line) if col.strip()]
    line_len = len(line_cols)
    trade_code = ""
    trade_name = ""
    trade_data = {}

    # å¸¸è§„ç§‘ç›®ï¼ˆ5åˆ—ç»“æ„ï¼‰
    if line_len >=5 and not in_special_area:
        trade_code = line_cols[0]
        trade_name = line_cols[1]  # å®Œæ•´ç§‘ç›®åï¼ˆå«â€œï¼ˆç”µèƒ½é‡ï¼‰â€ï¼‰
        # æå–ç”µé‡ã€ç”µä»·ã€ç”µè´¹ï¼ˆå…è®¸ä¸ºç©ºï¼‰
        trade_data = {
            'ç”µé‡': safe_convert_to_numeric(line_cols[2]),
            'ç”µä»·': safe_convert_to_numeric(line_cols[3]),
            'ç”µè´¹': safe_convert_to_numeric(line_cols[4])
        }
    # ç‰¹æ®Šç§‘ç›®ï¼ˆ3åˆ—ç»“æ„ï¼Œä¸”åŒ¹é…ç‰¹æ®Šç§‘ç›®åï¼‰
    elif line_len >=3 and is_special_trade(line_cols[1]):
        trade_code = line_cols[0]
        trade_name = line_cols[1]
        trade_data = {'ç”µè´¹': safe_convert_to_numeric(line_cols[2])}

    return trade_code, trade_name, trade_data

def extract_all_stations(pdf_lines, company_name, clear_date, total_quantity, total_fee):
    """
    é€è¡Œæ‰«ææå–æ‰€æœ‰åœºç«™ï¼š
    1. ç¡®ä¿åŒå‘A/Bé£ç”µåœºéƒ½èƒ½è¯†åˆ«
    2. å®Œæ•´ä¿ç•™â€œé€æ±Ÿè‹...ï¼ˆç”µèƒ½é‡ï¼‰â€ç§‘ç›®å
    3. ç‰¹æ®Šç§‘ç›®åªæå–ç”µè´¹
    """
    all_stations = []
    current_station = None
    current_station_meter = None
    current_trades = []  # ä¿ç•™å½“å‰åœºç«™ç§‘ç›®é¡ºåº
    in_trade_area = False  # æ˜¯å¦è¿›å…¥äº¤æ˜“æ•°æ®åŒº
    in_special_area = False  # æ˜¯å¦è¿›å…¥ç‰¹æ®Šç§‘ç›®åŒºï¼ˆæ— ç”µé‡/ç”µä»·ï¼‰

    for line in pdf_lines:
        # 1. è¯†åˆ«åœºç«™åˆ‡æ¢ï¼ˆé€‚é…â€œæœºç»„ï¼šåŒå‘Bé£ç”µåœºâ€ç­‰æ ¼å¼ï¼‰
        station_match = re.search(STATION_PATTERN, line)
        if station_match:
            # ä¿å­˜ä¸Šä¸€ä¸ªåœºç«™æ•°æ®
            if current_station and current_trades:
                all_stations.append({
                    'å…¬å¸åç§°': company_name,
                    'åœºç«™åç§°': current_station,
                    'æ¸…åˆ†æ—¥æœŸ': clear_date,
                    'æ–‡ä»¶åˆè®¡ç”µé‡': total_quantity,
                    'æ–‡ä»¶åˆè®¡ç”µè´¹': total_fee,
                    'åœºç«™è®¡é‡ç”µé‡': current_station_meter,
                    'ç§‘ç›®åˆ—è¡¨': current_trades.copy()
                })
            # åˆå§‹åŒ–æ–°åœºç«™
            current_station = station_match.group(1).strip()
            current_station_meter = None
            current_trades = []
            in_trade_area = False
            in_special_area = False
            continue

        # 2. æå–å½“å‰åœºç«™è®¡é‡ç”µé‡ï¼ˆç²¾ç¡®åŒ¹é…â€œè®¡é‡ç”µé‡ï¼šXXXâ€ï¼‰
        if current_station and "è®¡é‡ç”µé‡" in line and ("ï¼š" in line or ":" in line):
            meter_match = re.search(r'è®¡é‡ç”µé‡[:ï¼š]\s*(\S+)', line)
            if meter_match:
                current_station_meter = safe_convert_to_numeric(meter_match.group(1))
            continue

        # 3. è¯†åˆ«äº¤æ˜“æ•°æ®åŒºï¼ˆè¡¨å¤´éœ€åŒ…å«3ä¸ªå…³é”®è¯ï¼Œé¿å…è¯¯åˆ¤ï¼‰
        if not in_trade_area and all(kw in line for kw in TRADE_HEADER_KEYWORDS):
            in_trade_area = True
            continue

        # 4. æå–ç§‘ç›®æ•°æ®ï¼ˆä»…åœ¨äº¤æ˜“åŒºå†…ï¼‰
        if in_trade_area and current_station and len(line) >=10:
            trade_code, trade_name, trade_data = extract_trade_data(line, in_special_area)
            # è¿‡æ»¤æ— æ•ˆç§‘ç›®ï¼ˆç¼–ç ä¸ºæ•°å­—ï¼Œåç§°éç©ºï¼‰
            if trade_code.isdigit() and trade_name and len(trade_name)>=5:
                # æ›´æ–°ç‰¹æ®Šç§‘ç›®åŒºæ ‡è®°
                if is_special_trade(trade_name):
                    in_special_area = True
                else:
                    in_special_area = False
                # æ·»åŠ åˆ°å½“å‰åœºç«™ç§‘ç›®åˆ—è¡¨
                current_trades.append({
                    'ç¼–ç ': trade_code,
                    'åç§°': trade_name,
                    'æ˜¯å¦ç‰¹æ®Šç§‘ç›®': is_special_trade(trade_name),
                    'æ•°æ®': trade_data
                })

    # ä¿å­˜æœ€åä¸€ä¸ªåœºç«™
    if current_station and current_trades:
        all_stations.append({
            'å…¬å¸åç§°': company_name,
            'åœºç«™åç§°': current_station,
            'æ¸…åˆ†æ—¥æœŸ': clear_date,
            'æ–‡ä»¶åˆè®¡ç”µé‡': total_quantity,
            'æ–‡ä»¶åˆè®¡ç”µè´¹': total_fee,
            'åœºç«™è®¡é‡ç”µé‡': current_station_meter,
            'ç§‘ç›®åˆ—è¡¨': current_trades.copy()
        })

    return all_stations

# ---------------------- æ•°æ®æ ¼å¼åŒ–ä¸å¯¼å‡º ----------------------
def build_result_structure(all_stations):
    """
    æ„å»ºç»“æœDataFrameç»“æ„ï¼š
    - å¸¸è§„ç§‘ç›®ï¼š3åˆ—ï¼ˆç”µé‡/ç”µä»·/ç”µè´¹ï¼‰
    - ç‰¹æ®Šç§‘ç›®ï¼š1åˆ—ï¼ˆç”µè´¹ï¼‰
    - ä¸¥æ ¼ä¿ç•™ç§‘ç›®é¡ºåº
    """
    if not all_stations:
        return pd.DataFrame(), []

    # æ”¶é›†å…¨å±€ç§‘ç›®é¡ºåºï¼ˆæŒ‰ç¬¬ä¸€ä¸ªåœºç«™çš„ç§‘ç›®é¡ºåºï¼Œç¡®ä¿ç»Ÿä¸€ï¼‰
    global_trade_order = [trade['åç§°'] for trade in all_stations[0]['ç§‘ç›®åˆ—è¡¨']]
    # æ„å»ºåŸºç¡€åˆ—
    base_columns = [
        'å…¬å¸åç§°', 'åœºç«™åç§°', 'æ¸…åˆ†æ—¥æœŸ',
        'æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)', 'æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)', 'åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)'
    ]
    # æ„å»ºç§‘ç›®åˆ—ï¼ˆå¸¸è§„3åˆ—ï¼Œç‰¹æ®Š1åˆ—ï¼‰
    trade_columns = []
    for trade_name in global_trade_order:
        if is_special_trade(trade_name):
            trade_columns.append(f'{trade_name}_ç”µè´¹')
        else:
            trade_columns.extend([f'{trade_name}_ç”µé‡', f'{trade_name}_ç”µä»·', f'{trade_name}_ç”µè´¹'])

    # å¡«å……æ•°æ®
    result_data = []
    for station in all_stations:
        station_row = {
            'å…¬å¸åç§°': station['å…¬å¸åç§°'],
            'åœºç«™åç§°': station['åœºç«™åç§°'],
            'æ¸…åˆ†æ—¥æœŸ': station['æ¸…åˆ†æ—¥æœŸ'] or '',
            'æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)': station['æ–‡ä»¶åˆè®¡ç”µé‡'],
            'æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)': station['æ–‡ä»¶åˆè®¡ç”µè´¹'],
            'åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)': station['åœºç«™è®¡é‡ç”µé‡']
        }
        # æŒ‰å…¨å±€ç§‘ç›®é¡ºåºå¡«å……æ•°æ®
        for trade_name in global_trade_order:
            # æ‰¾åˆ°å½“å‰ç§‘ç›®çš„æ•°æ®
            trade = next((t for t in station['ç§‘ç›®åˆ—è¡¨'] if t['åç§°'] == trade_name), None)
            if trade:
                if is_special_trade(trade_name):
                    station_row[f'{trade_name}_ç”µè´¹'] = trade['æ•°æ®'].get('ç”µè´¹')
                else:
                    station_row[f'{trade_name}_ç”µé‡'] = trade['æ•°æ®'].get('ç”µé‡')
                    station_row[f'{trade_name}_ç”µä»·'] = trade['æ•°æ®'].get('ç”µä»·')
                    station_row[f'{trade_name}_ç”µè´¹'] = trade['æ•°æ®'].get('ç”µè´¹')
            else:
                # å…¶ä»–åœºç«™æ— æ­¤ç§‘ç›®æ—¶å¡«å……None
                if is_special_trade(trade_name):
                    station_row[f'{trade_name}_ç”µè´¹'] = None
                else:
                    station_row[f'{trade_name}_ç”µé‡'] = None
                    station_row[f'{trade_name}_ç”µä»·'] = None
                    station_row[f'{trade_name}_ç”µè´¹'] = None
        result_data.append(station_row)

    return pd.DataFrame(result_data, columns=base_columns+trade_columns), global_trade_order

def add_summary_row(result_df, global_trade_order):
    """æ·»åŠ æ±‡æ€»è¡Œï¼Œç‰¹æ®Šç§‘ç›®ä»…æ±‡æ€»ç”µè´¹"""
    summary_row = {
        'å…¬å¸åç§°': 'æ€»è®¡',
        'åœºç«™åç§°': 'æ€»è®¡',
        'æ¸…åˆ†æ—¥æœŸ': '',
        'æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)': result_df['æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)'].dropna().sum(),
        'æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)': result_df['æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)'].dropna().sum(),
        'åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)': result_df['åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)'].dropna().sum()
    }
    # æŒ‰ç§‘ç›®é¡ºåºæ±‡æ€»
    for trade_name in global_trade_order:
        if is_special_trade(trade_name):
            summary_row[f'{trade_name}_ç”µè´¹'] = result_df[f'{trade_name}_ç”µè´¹'].dropna().sum()
        else:
            summary_row[f'{trade_name}_ç”µé‡'] = result_df[f'{trade_name}_ç”µé‡'].dropna().sum()
            summary_row[f'{trade_name}_ç”µè´¹'] = result_df[f'{trade_name}_ç”µè´¹'].dropna().sum()
            # ç”µä»·å–æœ‰æ•ˆå¹³å‡å€¼ï¼ˆæ’é™¤0å’Œç©ºï¼‰
            price_vals = result_df[f'{trade_name}_ç”µä»·'].dropna()
            price_vals = price_vals[price_vals > 0.01]
            summary_row[f'{trade_name}_ç”µä»·'] = round(price_vals.mean(), 3) if not price_vals.empty else None

    return pd.concat([result_df, pd.DataFrame([summary_row])], ignore_index=True)

def to_excel_bytes(df, report_df):
    """Excelå¯¼å‡ºï¼Œä¿ç•™æ‰€æœ‰æ ¼å¼"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='ç»“ç®—æ•°æ®æ˜ç»†', index=False)
        report_df.to_excel(writer, sheet_name='å¤„ç†æŠ¥å‘Š', index=False)
    output.seek(0)
    return output

# ---------------------- Streamlit é¡µé¢ ----------------------
def main():
    st.set_page_config(page_title="é»‘é¾™æ±Ÿæ—¥æ¸…åˆ†æ•°æ®æå–ï¼ˆæœ€ç»ˆç‰ˆï¼‰", layout="wide")
    
    # é¡µé¢æ ‡é¢˜ä¸é—®é¢˜è§£å†³è¯´æ˜
    st.title("ğŸ“Š é»‘é¾™æ±Ÿæ—¥æ¸…åˆ†ç»“ç®—å•æ•°æ®æå–å·¥å…·ï¼ˆæœ€ç»ˆç‰ˆï¼‰")
    st.divider()
    st.subheader("âœ… å·²è§£å†³æ‰€æœ‰é—®é¢˜")
    st.markdown("""
    1. **â€œé€æ±Ÿè‹çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“ï¼ˆç”µèƒ½é‡ï¼‰â€ç§‘ç›®åå®Œæ•´**ï¼šç”¨2ä¸ªä»¥ä¸Šç©ºæ ¼åˆ†å‰²åˆ—ï¼Œé¿å…ç§‘ç›®åå†…ç©ºæ ¼å¹²æ‰°
    2. **åŒå‘Bé£ç”µåœºæ­£å¸¸æå–**ï¼šä¼˜åŒ–åœºç«™æ­£åˆ™ï¼Œé€‚é…â€œæœºç»„ï¼šåŒå‘Bé£ç”µåœºâ€ç­‰æ ¼å¼
    3. **ç‰¹æ®Šç§‘ç›®ä»…ä¿ç•™ç”µè´¹åˆ—**ï¼šâ€œä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨â€â€œçœé—´çœå†…ä»·å·®è´¹ç”¨â€ä»…ç”Ÿæˆç”µè´¹åˆ—ï¼Œæ— å¤šä½™åˆ—
    """)

    # æ–‡ä»¶ä¸Šä¼ 
    st.subheader("ğŸ“ ä¸Šä¼ PDFæ–‡ä»¶")
    uploaded_files = st.file_uploader(
        "ä»…æ”¯æŒPDFï¼ˆå·²ç²¾å‡†é€‚é…ä¾å…°å¿ååˆé£åŠ›å‘ç”µæ ¼å¼ï¼‰",
        type=['pdf'],
        accept_multiple_files=True
    )

    # æ•°æ®å¤„ç†
    if uploaded_files and st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary"):
        st.divider()
        st.subheader("âš™ï¸ å¤„ç†è¿›åº¦")
        
        all_result_dfs = []
        total_files = len(uploaded_files)
        processed_files = 0
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, file in enumerate(uploaded_files):
            file_name = file.name
            status_text.text(f"æ­£åœ¨å¤„ç†ï¼š{file_name}ï¼ˆ{idx+1}/{total_files}ï¼‰")
            
            try:
                # 1. è¯»å–PDFæ–‡æœ¬
                with pdfplumber.open(file) as pdf:
                    pdf_text = "\n".join([page.extract_text() for page in pdf.pages if page.extract_text()])
                pdf_lines = filter_invalid_lines(pdf_text.split('\n'))
                if not pdf_lines:
                    st.warning(f"{file_name} æ— æœ‰æ•ˆæ–‡æœ¬æ•°æ®")
                    continue

                # 2. æå–åŸºç¡€ä¿¡æ¯
                company_name, clear_date, total_quantity, total_fee = extract_basic_info(pdf_lines)
                # 3. æå–æ‰€æœ‰åœºç«™å’Œç§‘ç›®
                all_stations = extract_all_stations(pdf_lines, company_name, clear_date, total_quantity, total_fee)
                if not all_stations:
                    st.warning(f"{file_name} æœªæå–åˆ°åœºç«™æ•°æ®")
                    continue

                # 4. æ„å»ºç»“æœDataFrame
                result_df, trade_order = build_result_structure(all_stations)
                # 5. æ·»åŠ æ±‡æ€»è¡Œ
                result_df = add_summary_row(result_df, trade_order)
                all_result_dfs.append(result_df)
                processed_files += 1

            except Exception as e:
                st.warning(f"å¤„ç† {file_name} å‡ºé”™ï¼š{str(e)}")
                continue

            # æ›´æ–°è¿›åº¦
            progress_bar.progress((idx + 1) / total_files)

        progress_bar.empty()
        status_text.text("å¤„ç†å®Œæˆï¼")

        # ç»“æœå±•ç¤ºä¸å¯¼å‡º
        if all_result_dfs:
            # åˆå¹¶å¤šä¸ªæ–‡ä»¶ç»“æœï¼ˆè‹¥æœ‰ï¼‰
            final_df = pd.concat(all_result_dfs, ignore_index=True)
            # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
            stations = final_df['åœºç«™åç§°'].unique()
            station_count = len(stations) - 1 if 'æ€»è®¡' in stations else len(stations)
            valid_rows = len(final_df) - len(all_result_dfs)  # å‡å»æ±‡æ€»è¡Œæ•°
            trade_count = len([col for col in final_df.columns if any(kw in col for kw in ['ç”µé‡', 'ç”µè´¹'])]) // 3 + len(SPECIAL_TRADE_KEYWORDS)

            report_df = pd.DataFrame({
                'ç»Ÿè®¡é¡¹': ['æ–‡ä»¶æ€»æ•°', 'æˆåŠŸå¤„ç†æ•°', 'æ¶‰åŠåœºç«™æ•°', 'æœ‰æ•ˆæ•°æ®è¡Œæ•°', 'æå–ç§‘ç›®æ•°'],
                'æ•°å€¼': [total_files, processed_files, station_count, valid_rows, trade_count]
            })

            # å±•ç¤ºç»“æœ
            tab1, tab2 = st.tabs(["ç»“ç®—æ•°æ®æ˜ç»†", "å¤„ç†æŠ¥å‘Š"])
            with tab1:
                st.dataframe(final_df, use_container_width=True, height=600)
                # é‡ç‚¹ç§‘ç›®éªŒè¯æç¤º
                st.caption("ğŸ” é‡ç‚¹ç§‘ç›®éªŒè¯ï¼š")
                st.caption(f"- é€æ±Ÿè‹çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“ï¼ˆç”µèƒ½é‡ï¼‰ï¼š{['é€æ±Ÿè‹çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“ï¼ˆç”µèƒ½é‡ï¼‰_ç”µé‡' in final_df.columns]}")
                st.caption(f"- åŒå‘Bé£ç”µåœºï¼š{any('åŒå‘Bé£ç”µåœº' in name for name in final_df['åœºç«™åç§°'].unique())}")
                st.caption(f"- ç‰¹æ®Šç§‘ç›®ï¼ˆä»…ç”µè´¹åˆ—ï¼‰ï¼š{[col for col in final_df.columns if any(s in col for s in SPECIAL_TRADE_KEYWORDS)]}")
            with tab2:
                st.dataframe(report_df, use_container_width=True)

            # å¯¼å‡ºExcel
            current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
            download_filename = f"é»‘é¾™æ±Ÿç»“ç®—æ•°æ®_æœ€ç»ˆç‰ˆ_{current_time}.xlsx"
            excel_bytes = to_excel_bytes(final_df, report_df)

            st.divider()
            st.download_button(
                label="ğŸ“¥ å¯¼å‡ºæœ€ç»ˆç‰ˆExcel",
                data=excel_bytes,
                file_name=download_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary"
            )

            st.success("ğŸ‰ æ‰€æœ‰é—®é¢˜å·²è§£å†³ï¼Œæ•°æ®æå–å®Œæ•´å‡†ç¡®ï¼")
        else:
            st.warning("âš ï¸ æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥PDFæ–‡ä»¶æ ¼å¼ã€‚")

    # æ— æ–‡ä»¶ä¸Šä¼ æ—¶çš„æç¤º
    elif not uploaded_files and st.button("ğŸš€ å¼€å§‹å¤„ç†", disabled=True):
        st.warning("è¯·å…ˆä¸Šä¼ PDFæ–‡ä»¶ï¼")

if __name__ == "__main__":
    main()
