import streamlit as st
import pandas as pd
import re
from datetime import datetime
import warnings
import pdfplumber
from io import BytesIO

# å¿½ç•¥æ ·å¼è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl.stylesheet")

# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° ----------------------
def safe_convert_to_numeric(value, default=None):
    """å®‰å…¨è½¬æ¢ä¸ºæ•°å€¼ï¼Œå…¼å®¹é€—å·åˆ†éš”çš„é‡‘é¢å’Œç©ºå€¼"""
    try:
        if pd.notna(value) and value is not None:
            str_val = str(value).strip()
            if str_val in ['/', 'NA', 'None', '', 'æ— ', 'â€”â€”']:
                return default
            cleaned_value = str_val.replace(',', '').replace(' ', '').strip()
            return pd.to_numeric(cleaned_value)
        return default
    except (ValueError, TypeError):
        return default

def extract_company_name(pdf_lines):
    """ä»PDFæå–å…¬å¸åç§°"""
    for line in pdf_lines:
        if "å…¬å¸åç§°:" in line:
            return re.sub(r'å…¬å¸åç§°:\s*', '', line).strip()
    return "æœªçŸ¥å…¬å¸"

def extract_clear_date(pdf_lines):
    """æå–æ¸…åˆ†æ—¥æœŸ"""
    date_pattern = r'æ¸…åˆ†æ—¥æœŸ\s*(\d{4}-\d{2}-\d{2})'
    for line in pdf_lines:
        date_match = re.search(date_pattern, line)
        if date_match:
            return date_match.group(1)
    return None

def extract_total_data(pdf_lines):
    """æå–æ–‡ä»¶çº§åˆè®¡ç”µé‡å’Œåˆè®¡ç”µè´¹"""
    total_quantity = None
    total_amount = None
    for line in pdf_lines:
        line_cols = [col.strip() for col in re.split(r'\s+', line) if col.strip()]
        if "åˆè®¡ç”µé‡" in line_cols and "åˆè®¡ç”µè´¹" in line_cols:
            if "åˆè®¡ç”µé‡" in line_cols:
                qty_idx = line_cols.index("åˆè®¡ç”µé‡") + 1
                if qty_idx < len(line_cols):
                    total_quantity = safe_convert_to_numeric(line_cols[qty_idx])
            if "åˆè®¡ç”µè´¹" in line_cols:
                fee_idx = line_cols.index("åˆè®¡ç”µè´¹") + 1
                if fee_idx < len(line_cols):
                    total_amount = safe_convert_to_numeric(line_cols[fee_idx])
            break
    return total_quantity, total_amount

# ---------------------- æ ¸å¿ƒæå–é€»è¾‘ï¼ˆé€‚é…å¤šåœºç«™+åŠ¨æ€ç§‘ç›®ï¼‰ ----------------------
def extract_station_data(pdf_lines, company_name, clear_date, total_quantity, total_amount):
    """æå–å•ä¸ªPDFä¸­çš„æ‰€æœ‰åœºç«™æ•°æ®ï¼ˆåŠ¨æ€è¯†åˆ«ç§‘ç›®ï¼‰"""
    all_station_data = []
    station_pattern = r'æœºç»„\s+([^:ï¼š\s]+é£ç”µåœº)'  # åŒ¹é…"æœºç»„ åŒå‘Aé£ç”µåœº"æ ¼å¼
    current_station = None
    current_station_meter_qty = None
    trade_data_started = False  # æ ‡è®°æ˜¯å¦è¿›å…¥äº¤æ˜“æ•°æ®åŒºåŸŸ
    all_trade_names = set()  # æ”¶é›†æ‰€æœ‰åŠ¨æ€è¯†åˆ«çš„ç§‘ç›®åç§°

    # ç¬¬ä¸€æ­¥ï¼šæ‰«ææ‰€æœ‰äº¤æ˜“ç§‘ç›®åç§°å’Œåœºç«™ä¿¡æ¯
    for line in pdf_lines:
        line = line.strip()
        # è¯†åˆ«åœºç«™åˆ‡æ¢
        station_match = re.search(station_pattern, line)
        if station_match:
            current_station = station_match.group(1)
            trade_data_started = False
            continue
        
        # è¯†åˆ«å½“å‰åœºç«™çš„è®¡é‡ç”µé‡
        if current_station and "è®¡é‡ç”µé‡" in line:
            meter_qty_match = re.search(r'è®¡é‡ç”µé‡\s*(\S+)', line)
            if meter_qty_match:
                current_station_meter_qty = safe_convert_to_numeric(meter_qty_match.group(1))
            continue
        
        # æ ‡è®°äº¤æ˜“æ•°æ®å¼€å§‹ï¼ˆç”µèƒ½é‡ç”µè´¹ä¸‹æ–¹ï¼‰
        if "ç”µèƒ½é‡ç”µè´¹" in line:
            trade_data_started = True
            continue
        
        # æå–äº¤æ˜“ç§‘ç›®ï¼ˆç»“ç®—ç±»å‹åˆ—ï¼‰
        if trade_data_started and current_station:
            line_cols = [col.strip() for col in re.split(r'\s+', line) if col.strip()]
            # äº¤æ˜“æ•°æ®è¡Œç‰¹å¾ï¼šè‡³å°‘5åˆ—ï¼Œç¬¬2åˆ—ä¸ºç»“ç®—ç±»å‹åç§°ï¼Œç¬¬3-5åˆ—ä¸ºæ•°å€¼
            if len(line_cols) >= 5 and line_cols[1] not in ['ç»“ç®—ç±»å‹', 'ç§‘ç›®ç¼–ç '] and not line_cols[1].isdigit():
                trade_name = line_cols[1]
                if trade_name not in ['ç”µé‡', 'ç”µä»·', 'ç”µè´¹', 'å°è®¡']:
                    all_trade_names.add(trade_name)
    
    # ç¬¬äºŒæ­¥ï¼šæå–æ¯ä¸ªåœºç«™çš„å…·ä½“äº¤æ˜“æ•°æ®
    current_station = None
    current_station_meter_qty = None
    trade_data_started = False
    station_trade_data = {}

    for line in pdf_lines:
        line = line.strip()
        line_cols = [col.strip() for col in re.split(r'\s+', line) if col.strip()]
        
        # åœºç«™åˆ‡æ¢å¤„ç†ï¼ˆä¿å­˜ä¸Šä¸€ä¸ªåœºç«™æ•°æ®ï¼‰
        station_match = re.search(station_pattern, line)
        if station_match:
            if current_station and station_trade_data:
                # æ„å»ºå½“å‰åœºç«™å®Œæ•´æ•°æ®
                station_row = {
                    'å…¬å¸åç§°': company_name,
                    'åœºç«™åç§°': current_station,
                    'æ¸…åˆ†æ—¥æœŸ': clear_date,
                    'æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)': total_quantity,
                    'æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)': total_amount,
                    'åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)': current_station_meter_qty
                }
                # è¡¥å……æ‰€æœ‰äº¤æ˜“ç§‘ç›®çš„æ•°æ®
                for trade in all_trade_names:
                    station_row[f'{trade}_ç”µé‡'] = station_trade_data.get(trade, {}).get('ç”µé‡')
                    station_row[f'{trade}_ç”µä»·'] = station_trade_data.get(trade, {}).get('ç”µä»·')
                    station_row[f'{trade}_ç”µè´¹'] = station_trade_data.get(trade, {}).get('ç”µè´¹')
                all_station_data.append(station_row)
            
            # åˆå§‹åŒ–æ–°åœºç«™
            current_station = station_match.group(1)
            station_trade_data = {}
            trade_data_started = False
            continue
        
        # è¯†åˆ«å½“å‰åœºç«™çš„è®¡é‡ç”µé‡
        if current_station and "è®¡é‡ç”µé‡" in line:
            meter_qty_match = re.search(r'è®¡é‡ç”µé‡\s*(\S+)', line)
            if meter_qty_match:
                current_station_meter_qty = safe_convert_to_numeric(meter_qty_match.group(1))
            continue
        
        # æ ‡è®°äº¤æ˜“æ•°æ®å¼€å§‹
        if "ç”µèƒ½é‡ç”µè´¹" in line:
            trade_data_started = True
            continue
        
        # æå–å½“å‰äº¤æ˜“ç§‘ç›®çš„æ•°æ®
        if trade_data_started and current_station and len(line_cols) >= 5:
            trade_name = line_cols[1]
            if trade_name in all_trade_names:
                quantity = safe_convert_to_numeric(line_cols[2])
                price = safe_convert_to_numeric(line_cols[3])
                fee = safe_convert_to_numeric(line_cols[4])
                station_trade_data[trade_name] = {
                    'ç”µé‡': quantity,
                    'ç”µä»·': price,
                    'ç”µè´¹': fee
                }
    
    # ä¿å­˜æœ€åä¸€ä¸ªåœºç«™çš„æ•°æ®
    if current_station and station_trade_data:
        station_row = {
            'å…¬å¸åç§°': company_name,
            'åœºç«™åç§°': current_station,
            'æ¸…åˆ†æ—¥æœŸ': clear_date,
            'æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)': total_quantity,
            'æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)': total_amount,
            'åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)': current_station_meter_qty
        }
        for trade in all_trade_names:
            station_row[f'{trade}_ç”µé‡'] = station_trade_data.get(trade, {}).get('ç”µé‡')
            station_row[f'{trade}_ç”µä»·'] = station_trade_data.get(trade, {}).get('ç”µä»·')
            station_row[f'{trade}_ç”µè´¹'] = station_trade_data.get(trade, {}).get('ç”µè´¹')
        all_station_data.append(station_row)
    
    return all_station_data, list(all_trade_names)

def extract_data_from_pdf(file_obj, file_name):
    """ä»PDFæ–‡ä»¶å¯¹è±¡æå–æ•°æ®ï¼ˆæ”¯æŒå¤šåœºç«™+åŠ¨æ€ç§‘ç›®ï¼‰"""
    try:
        with pdfplumber.open(file_obj) as pdf:
            if not pdf.pages:
                raise ValueError("PDFæ— æœ‰æ•ˆé¡µé¢")
            
            # è¯»å–æ‰€æœ‰é¡µé¢æ–‡æœ¬
            all_text = ""
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    all_text += page_text + "\n"
            pdf_lines = [line.strip() for line in all_text.split('\n') if line.strip()]
            if not pdf_lines:
                raise ValueError("PDFä¸ºæ‰«æä»¶ï¼Œæ— å¯ç”¨æ–‡æœ¬")

        # æå–åŸºç¡€ä¿¡æ¯
        company_name = extract_company_name(pdf_lines)
        clear_date = extract_clear_date(pdf_lines)
        total_quantity, total_amount = extract_total_data(pdf_lines)
        
        # æå–æ‰€æœ‰åœºç«™æ•°æ®å’ŒåŠ¨æ€ç§‘ç›®
        station_data_list, all_trade_names = extract_station_data(
            pdf_lines, company_name, clear_date, total_quantity, total_amount
        )
        
        return station_data_list, all_trade_names

    except Exception as e:
        st.warning(f"å¤„ç†PDF {file_name} å‡ºé”™: {str(e)}")
        return [], []

def extract_data_from_excel(file_obj, file_name):
    """Excelæ–‡ä»¶å¤„ç†ï¼ˆä¿æŒåŸé€»è¾‘ï¼Œé€‚é…åŠ¨æ€ç§‘ç›®ï¼‰"""
    try:
        df = pd.read_excel(file_obj, dtype=object)
        company_name = "æœªçŸ¥å…¬å¸"
        # ä»æ–‡ä»¶åæå–å…¬å¸å
        name_without_ext = file_name.split('.')[0]
        if "æ™¶ç››" in name_without_ext:
            company_name = "å¤§åº†æ™¶ç››å…‰ä¼ç”µç«™"
        
        # æå–æ—¥æœŸ
        date_match = re.search(r'\d{4}-\d{2}-\d{2}', name_without_ext)
        clear_date = date_match.group() if date_match else None

        # æå–åˆè®¡æ•°æ®
        total_quantity = safe_convert_to_numeric(df.iloc[0, 3] if len(df) > 0 else None)
        total_amount = safe_convert_to_numeric(df.iloc[0, 5] if len(df) > 0 else None)

        # å›ºå®šåŸºç¡€åˆ—ï¼ˆExcelæš‚æŒ‰åŸé€»è¾‘å¤„ç†ï¼Œå¯æ ¹æ®å®é™…æ ¼å¼è°ƒæ•´ï¼‰
        station_data = [{
            'å…¬å¸åç§°': company_name,
            'åœºç«™åç§°': company_name.replace('æœ‰é™å…¬å¸', 'åœºç«™'),
            'æ¸…åˆ†æ—¥æœŸ': clear_date,
            'æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)': total_quantity,
            'æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)': total_amount,
            'åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)': total_quantity
        }]
        
        # é»˜è®¤Excelç§‘ç›®ï¼ˆå¯æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´ï¼‰
        excel_trade_names = [
            'ä¼˜å…ˆå‘ç”µäº¤æ˜“', 'ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“', 'çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“'
        ]
        
        return station_data, excel_trade_names

    except Exception as e:
        st.warning(f"å¤„ç†Excel {file_name} å‡ºé”™: {str(e)}")
        return [], []

# ---------------------- æ•°æ®æ±‡æ€»ä¸å¯¼å‡º ----------------------
def calculate_summary_row(data_df, all_trade_names):
    """è®¡ç®—æ±‡æ€»è¡Œï¼ˆé€‚é…åŠ¨æ€ç§‘ç›®ï¼‰"""
    summary_row = {
        'å…¬å¸åç§°': 'æ€»è®¡',
        'åœºç«™åç§°': 'æ€»è®¡',
        'æ¸…åˆ†æ—¥æœŸ': '',
        'æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)': data_df['æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)'].dropna().sum(),
        'æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)': data_df['æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)'].dropna().sum(),
        'åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)': data_df['åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)'].dropna().sum()
    }
    
    # æ±‡æ€»å„äº¤æ˜“ç§‘ç›®çš„æ•°æ®
    for trade in all_trade_names:
        summary_row[f'{trade}_ç”µé‡'] = data_df[f'{trade}_ç”µé‡'].dropna().sum()
        summary_row[f'{trade}_ç”µè´¹'] = data_df[f'{trade}_ç”µè´¹'].dropna().sum()
        # ç”µä»·å–å¹³å‡å€¼ï¼ˆæ’é™¤0å€¼ï¼‰
        price_vals = data_df[f'{trade}_ç”µä»·'].dropna()
        price_vals = price_vals[price_vals > 0]
        summary_row[f'{trade}_ç”µä»·'] = round(price_vals.mean(), 3) if not price_vals.empty else None
    
    return pd.DataFrame([summary_row])

def to_excel_bytes(df, report_df):
    """å°†DataFrameè½¬ä¸ºExcelå­—èŠ‚æµ"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='ç»“ç®—æ•°æ®æ˜ç»†', index=False)
        report_df.to_excel(writer, sheet_name='å¤„ç†æŠ¥å‘Š', index=False)
    output.seek(0)
    return output

# ---------------------- Streamlit é¡µé¢å¸ƒå±€ ----------------------
def main():
    st.set_page_config(page_title="é»‘é¾™æ±Ÿæ—¥æ¸…åˆ†æ•°æ®æå–ï¼ˆå¤šåœºç«™ç‰ˆï¼‰", layout="wide")
    
    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ“Š é»‘é¾™æ±Ÿæ—¥æ¸…åˆ†ç»“ç®—å•æ•°æ®æå–å·¥å…·ï¼ˆæ”¯æŒå¤šåœºç«™+åŠ¨æ€ç§‘ç›®ï¼‰")
    st.divider()

    # 1. æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.subheader("ğŸ“ ä¸Šä¼ æ–‡ä»¶")
    uploaded_files = st.file_uploader(
        "æ”¯æŒPDF/Excelæ ¼å¼ï¼Œå¯æ‰¹é‡ä¸Šä¼ ï¼ˆPDFè‡ªåŠ¨è¯†åˆ«å¤šåœºç«™å’ŒåŠ¨æ€ç§‘ç›®ï¼‰",
        type=['pdf', 'xlsx'],
        accept_multiple_files=True
    )

    # 2. æ•°æ®å¤„ç†é€»è¾‘
    if uploaded_files and st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary"):
        st.divider()
        st.subheader("âš™ï¸ å¤„ç†è¿›åº¦")
        
        all_station_data = []
        all_trade_names = set()  # æ”¶é›†æ‰€æœ‰æ–‡ä»¶çš„äº¤æ˜“ç§‘ç›®
        total_files = len(uploaded_files)
        processed_files = 0

        # æ‰¹é‡å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, file in enumerate(uploaded_files):
            file_name = file.name
            status_text.text(f"æ­£åœ¨å¤„ç†ï¼š{file_name}")
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹è°ƒç”¨å¯¹åº”æå–å‡½æ•°
            if file_name.lower().endswith('.pdf'):
                station_data, trade_names = extract_data_from_pdf(file, file_name)
            else:
                station_data, trade_names = extract_data_from_excel(file, file_name)
            
            # ç´¯ç§¯æ•°æ®å’Œç§‘ç›®
            if station_data:
                all_station_data.extend(station_data)
                all_trade_names.update(trade_names)
                processed_files += 1
            
            # æ›´æ–°è¿›åº¦
            progress_bar.progress((idx + 1) / total_files)

        progress_bar.empty()
        status_text.text("å¤„ç†å®Œæˆï¼")

        # 3. ç»“æœå±•ç¤ºä¸å¯¼å‡º
        if all_station_data and all_trade_names:
            st.divider()
            st.subheader("ğŸ“ˆ æå–ç»“æœ")
            
            # æ„å»ºç»“æœåˆ—åï¼ˆåŸºç¡€åˆ— + åŠ¨æ€ç§‘ç›®åˆ—ï¼‰
            base_columns = [
                'å…¬å¸åç§°', 'åœºç«™åç§°', 'æ¸…åˆ†æ—¥æœŸ',
                'æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)', 'æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)', 'åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)'
            ]
            trade_columns = []
            for trade in sorted(all_trade_names):
                trade_columns.extend([f'{trade}_ç”µé‡', f'{trade}_ç”µä»·', f'{trade}_ç”µè´¹'])
            result_columns = base_columns + trade_columns

            # æ„å»ºDataFrameå¹¶æ ¼å¼åŒ–
            result_df = pd.DataFrame(all_station_data)
            # è¡¥å……ç¼ºå¤±çš„åˆ—ï¼ˆä¸åŒæ–‡ä»¶å¯èƒ½æœ‰ä¸åŒç§‘ç›®ï¼‰
            for col in result_columns:
                if col not in result_df.columns:
                    result_df[col] = None
            # åªä¿ç•™ç›®æ ‡åˆ—
            result_df = result_df[result_columns]
            # æ•°å€¼åˆ—æ ¼å¼åŒ–
            numeric_cols = [col for col in result_columns if any(key in col for key in ['ç”µé‡', 'ç”µä»·', 'ç”µè´¹'])]
            result_df[numeric_cols] = result_df[numeric_cols].apply(pd.to_numeric, errors='coerce')

            # æ’åº
            result_df['æ¸…åˆ†æ—¥æœŸ'] = pd.to_datetime(result_df['æ¸…åˆ†æ—¥æœŸ'], errors='coerce')
            result_df = result_df.sort_values(['å…¬å¸åç§°', 'åœºç«™åç§°', 'æ¸…åˆ†æ—¥æœŸ']).reset_index(drop=True)
            result_df['æ¸…åˆ†æ—¥æœŸ'] = result_df['æ¸…åˆ†æ—¥æœŸ'].dt.strftime('%Y-%m-%d').fillna('')

            # æ·»åŠ æ±‡æ€»è¡Œ
            summary_row = calculate_summary_row(result_df, all_trade_names)
            result_df = pd.concat([result_df, summary_row], ignore_index=True)

            # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
            failed_files = total_files - processed_files
            success_rate = f"{processed_files / total_files:.2%}" if total_files > 0 else "0%"
            stations = result_df['åœºç«™åç§°'].unique()
            station_count = len(stations) - 1 if 'æ€»è®¡' in stations else len(stations)
            valid_rows = len(result_df) - 1

            report_df = pd.DataFrame({
                'ç»Ÿè®¡é¡¹': ['æ–‡ä»¶æ€»æ•°', 'æˆåŠŸå¤„ç†æ•°', 'å¤±è´¥æ•°', 'å¤„ç†æˆåŠŸç‡', 'æ¶‰åŠåœºç«™æ•°', 'æœ‰æ•ˆæ•°æ®è¡Œæ•°', 'è¯†åˆ«ç§‘ç›®æ•°'],
                'æ•°å€¼': [total_files, processed_files, failed_files,
                         success_rate, station_count, valid_rows, len(all_trade_names)]
            })

            # å±•ç¤ºç»“æœè¡¨æ ¼
            tab1, tab2 = st.tabs(["ç»“ç®—æ•°æ®æ˜ç»†", "å¤„ç†æŠ¥å‘Š"])
            with tab1:
                st.dataframe(result_df, use_container_width=True)
            with tab2:
                st.dataframe(report_df, use_container_width=True)

            # ç”Ÿæˆä¸‹è½½æ–‡ä»¶
            current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
            download_filename = f"é»‘é¾™æ±Ÿç»“ç®—æ•°æ®æå–_{current_time}.xlsx"
            excel_bytes = to_excel_bytes(result_df, report_df)

            # ä¸‹è½½æŒ‰é’®
            st.divider()
            st.download_button(
                label="ğŸ“¥ å¯¼å‡ºExcelæ–‡ä»¶",
                data=excel_bytes,
                file_name=download_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary"
            )

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            st.info(
                f"""å¤„ç†å®Œæˆï¼
                - æ€»è®¡ä¸Šä¼  {total_files} ä¸ªæ–‡ä»¶ï¼ŒæˆåŠŸå¤„ç† {processed_files} ä¸ªï¼ˆæˆåŠŸç‡ {success_rate}ï¼‰
                - è¯†åˆ«åˆ° {len(all_trade_names)} ä¸ªäº¤æ˜“ç§‘ç›®ï¼Œæ¶‰åŠ {station_count} ä¸ªåœºç«™ï¼Œ{valid_rows} è¡Œæœ‰æ•ˆæ•°æ®
                - PDFæ–‡ä»¶å·²è‡ªåŠ¨æ‹†åˆ†å¤šåœºç«™æ•°æ®ï¼Œç§‘ç›®éšç»“ç®—å•åŠ¨æ€æ›´æ–°
                """
            )
        else:
            st.warning("âš ï¸ æœªæå–åˆ°æœ‰æ•ˆæ•°æ®ï¼è¯·æ£€æŸ¥ï¼š")
            st.markdown("""
                1. PDFæ˜¯å¦ä¸ºå¯å¤åˆ¶æ–‡æœ¬ï¼ˆéæ‰«æä»¶ï¼‰ï¼›
                2. æ–‡ä»¶æ˜¯å¦ä¸ºé»‘é¾™æ±Ÿæ—¥æ¸…åˆ†æ ¼å¼ï¼ˆåŒ…å«"æœºç»„ æŸæŸé£ç”µåœº"æ ‡è¯†ï¼‰ï¼›
                3. Excelæ–‡ä»¶æ ¼å¼æ˜¯å¦åŒ¹é…ã€‚
            """)

    # æ— æ–‡ä»¶ä¸Šä¼ æ—¶çš„æç¤º
    elif not uploaded_files and st.button("ğŸš€ å¼€å§‹å¤„ç†", disabled=True):
        st.warning("è¯·å…ˆä¸Šä¼ PDF/Excelæ–‡ä»¶ï¼")

if __name__ == "__main__":
    main()
