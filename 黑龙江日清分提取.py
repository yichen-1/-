import streamlit as st
import pandas as pd
import re
from datetime import datetime
import warnings
import pdfplumber
from io import BytesIO

# å¿½ç•¥æ ·å¼è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl.stylesheet")

# ---------------------- æ ¸å¿ƒé…ç½®ï¼ˆæ–°å¢ï¼šè§£å†³ç§‘ç›®/åœºç«™/æ— æ•ˆåˆ—é—®é¢˜ï¼‰ ----------------------
# æ–°å¢ï¼šæ‰©å±•ç›®æ ‡ç§‘ç›®ï¼ˆåŒ…å«ç¼ºå¤±ç§‘ç›®ï¼ŒåŒºåˆ†å¸¸è§„/ç‰¹æ®Šç§‘ç›®ï¼‰
NORMAL_TRADES = [
    'ä¼˜å…ˆå‘ç”µäº¤æ˜“',
    'ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“',
    'çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“',
    'é€ä¸Šæµ·çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“(ç”µèƒ½é‡ )',
    'é€è¾½å®äº¤æ˜“',
    'é€ååŒ—äº¤æ˜“',
    'é€å±±ä¸œäº¤æ˜“',
    'é€æµ™æ±Ÿäº¤æ˜“',
    'é€æ±Ÿè‹çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“ï¼ˆç”µèƒ½é‡ï¼‰',  # æ–°å¢ç¼ºå¤±ç§‘ç›®
    'é€æµ™æ±Ÿçœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“ï¼ˆç”µèƒ½é‡ï¼‰',  # æ–°å¢ç¼ºå¤±ç§‘ç›®
    'çœå†…ç°è´§æ—¥å‰äº¤æ˜“',
    'çœå†…ç°è´§å®æ—¶äº¤æ˜“',
    'çœé—´ç°è´§æ—¥å‰äº¤æ˜“',
    'çœé—´ç°è´§æ—¥å†…äº¤æ˜“'
]
# æ–°å¢ï¼šç‰¹æ®Šç§‘ç›®ï¼ˆä»…æå–ç”µè´¹ï¼‰
SPECIAL_TRADES = [
    'ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨',
    'çœé—´çœå†…ä»·å·®è´¹ç”¨'
]
# æ–°å¢ï¼šæ— æ•ˆå…³é”®è¯è¿‡æ»¤ï¼ˆæ¶ˆé™¤hf_ã€å¿_ç­‰å¤šä½™åˆ—ï¼‰
INVALID_KEYWORDS = ['hf', 'HF', 'å¿', 'é•‡', 'ä¹¡', 'æ‘', '_', 'â€”']
# æ–°å¢ï¼šä¼˜åŒ–åœºç«™è¯†åˆ«ï¼ˆæ”¯æŒåŒå‘A/Bé£ç”µåœºï¼‰
STATION_PATTERNS = [
    r'å…¬å¸åç§°:\s*([^\s]+é£ç”µåœº)',  # ä¼˜å…ˆåŒ¹é…é£ç”µåœºåç§°
    r'æœºç»„\s*[:ï¼š]?\s*([^\s]+é£ç”µåœº)',  # é€‚é…åŒå‘A/Bé£ç”µåœºæ ¼å¼
    r'å…¬å¸åç§°:\s*([^\s]+æœ‰é™å…¬å¸)'  # åŸæœ‰è§„åˆ™å…œåº•
]

# ---------------------- æ ¸å¿ƒæå–å‡½æ•°ï¼ˆä¿ç•™åŸé€»è¾‘ï¼Œæ–°å¢ä¼˜åŒ–ï¼‰ ----------------------
def extract_station_name(pdf_lines):
    """ä¼˜åŒ–ï¼šé€‚é…åŒå‘A/Bé£ç”µåœºï¼Œç²¾å‡†æå–åœºç«™åç§°"""
    # ä¼˜å…ˆåŒ¹é…é£ç”µåœºåç§°ï¼ˆè§£å†³åŒå‘Bé£ç”µåœºæå–é—®é¢˜ï¼‰
    for pattern in STATION_PATTERNS:
        for line in pdf_lines:
            match = re.search(pattern, line)
            if match:
                station_name = match.group(1).strip()
                # æ ¼å¼ç»Ÿä¸€
                station_name = re.sub(r'å¤ªé˜³èƒ½å‘ç”µæœ‰é™å…¬å¸$', 'å…‰ä¼ç”µç«™', station_name)
                return station_name
    return "æœªçŸ¥åœºç«™"

def safe_convert_to_numeric(value, default=None):
    """ä¿ç•™åŸé€»è¾‘ï¼Œå…¼å®¹æ›´å¤šç©ºå€¼åœºæ™¯"""
    try:
        if pd.notna(value) and value is not None:
            str_val = str(value).strip()
            # æ–°å¢ï¼šå…¼å®¹æ›´å¤šç©ºå€¼æ ‡è¯†
            if str_val in ['/', 'NA', 'None', '', 'æ— ', 'â€”â€”', '0.00', '-', 'ç©º']:
                return default
            cleaned_value = str_val.replace(',', '').replace(' ', '').strip()
            return pd.to_numeric(cleaned_value)
        return default
    except (ValueError, TypeError):
        return default

def filter_invalid_lines(pdf_lines):
    """æ–°å¢ï¼šè¿‡æ»¤å«æ— æ•ˆå…³é”®è¯çš„è¡Œï¼Œæ¶ˆé™¤å¤šä½™åˆ—"""
    valid_lines = []
    for line in pdf_lines:
        line = line.strip()
        # è¿‡æ»¤ï¼šè¿‡çŸ­è¡Œã€å«æ— æ•ˆå…³é”®è¯ã€çº¯æ•°å­—è¡Œ
        if (len(line) >= 5 
            and not any(kw in line for kw in INVALID_KEYWORDS)
            and not line.replace('.', '').replace('-', '').isdigit()):
            valid_lines.append(line)
    return valid_lines

def extract_trade_data_by_column(trade_name, pdf_lines, is_special=False):
    """ä¼˜åŒ–ï¼šé€‚é…å¸¸è§„/ç‰¹æ®Šç§‘ç›®æå–ï¼Œè§£å†³ç§‘ç›®æ‹†åˆ†é—®é¢˜"""
    quantity = None
    price = None
    fee = None

    # æ–°å¢ï¼šç”¨2ä¸ªä»¥ä¸Šç©ºæ ¼åˆ†å‰²åˆ—ï¼ˆé¿å…ç§‘ç›®åå†…ç©ºæ ¼æ‹†åˆ†ï¼‰
    for idx, line in enumerate(pdf_lines):
        line_cols = [col.strip() for col in re.split(r'\s{2,}', line) if col.strip()]
        
        # å¸¸è§„ç§‘ç›®ï¼š5åˆ—ç»“æ„ï¼ˆç¼–ç +åç§°+ç”µé‡+ç”µä»·+ç”µè´¹ï¼‰
        if not is_special and len(line_cols) >= 5 and trade_name in line_cols[1]:
            quantity = safe_convert_to_numeric(line_cols[2])
            price = safe_convert_to_numeric(line_cols[3])
            fee = safe_convert_to_numeric(line_cols[4])
            break
        # ç‰¹æ®Šç§‘ç›®ï¼š3åˆ—ç»“æ„ï¼ˆç¼–ç +åç§°+ç”µè´¹ï¼‰
        elif is_special and len(line_cols) >= 3 and trade_name in line_cols[1]:
            fee = safe_convert_to_numeric(line_cols[2])
            break
    return [quantity, price, fee] if not is_special else [fee]

def extract_data_from_pdf(file_obj, file_name):
    """ä¿ç•™åŸç»“æ„ï¼Œæ–°å¢ï¼šæ”¯æŒç‰¹æ®Šç§‘ç›®ã€è¿‡æ»¤æ— æ•ˆè¡Œã€å®Œæ•´ç§‘ç›®æå–"""
    try:
        with pdfplumber.open(file_obj) as pdf:
            if not pdf.pages:
                raise ValueError("PDFæ— æœ‰æ•ˆé¡µé¢")
            
            all_text = ""
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    all_text += page_text + "\n"
        # æ–°å¢ï¼šè¿‡æ»¤æ— æ•ˆè¡Œï¼ˆè§£å†³å¤šä½™åˆ—é—®é¢˜ï¼‰
        pdf_lines = filter_invalid_lines(all_text.split('\n'))
        if not pdf_lines:
            raise ValueError("PDFä¸ºæ‰«æä»¶ï¼Œæ— å¯ç”¨æ–‡æœ¬")

        # 1. æå–åœºç«™åç§°ï¼ˆä¼˜åŒ–åï¼‰
        station_name = extract_station_name(pdf_lines)

        # 2. æå–æ¸…åˆ†æ—¥æœŸï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        date = None
        date_pattern = r'æ¸…åˆ†æ—¥æœŸ\s*(\d{4}-\d{2}-\d{2})'
        for line in pdf_lines:
            date_match = re.search(date_pattern, line)
            if date_match:
                date = date_match.group(1)
                break

        # 3. æå–åˆè®¡ç”µé‡å’Œåˆè®¡ç”µè´¹ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        total_quantity = None
        total_amount = None
        for line in pdf_lines:
            line_cols = [col.strip() for col in re.split(r'\s{2,}', line) if col.strip()]  # ä¼˜åŒ–åˆ—åˆ†å‰²
            if "åˆè®¡ç”µé‡" in line_cols and "åˆè®¡ç”µè´¹" in line_cols:
                if "åˆè®¡ç”µé‡" in line_cols:
                    qty_idx = line_cols.index("åˆè®¡ç”µé‡") + 1
                    if qty_idx < len(line_cols):
                        total_quantity = safe_convert_to_numeric(line_cols[qty_idx])
                if "åˆè®¡ç”µè´¹" in line_cols:
                    fee_idx = line_cols.index("åˆè®¡ç”µè´¹") + 1
                    if fee_idx < len(line_cols):
                        total_amount = safe_convert_to_numeric(line_cols[fee_idx])
                break

        # 4. æå–æ‰€æœ‰ç›®æ ‡ç§‘ç›®çš„æ•°æ®ï¼ˆæ–°å¢ï¼šåŒºåˆ†å¸¸è§„/ç‰¹æ®Šç§‘ç›®ï¼‰
        all_trade_data = []
        # æå–å¸¸è§„ç§‘ç›®ï¼ˆ3åˆ—ï¼šç”µé‡/ç”µä»·/ç”µè´¹ï¼‰
        for trade in NORMAL_TRADES:
            trade_data = extract_trade_data_by_column(trade, pdf_lines, is_special=False)
            all_trade_data.extend(trade_data)
        # æå–ç‰¹æ®Šç§‘ç›®ï¼ˆä»…1åˆ—ï¼šç”µè´¹ï¼‰
        for trade in SPECIAL_TRADES:
            trade_data = extract_trade_data_by_column(trade, pdf_lines, is_special=True)
            all_trade_data.extend(trade_data)

        return [station_name, date, total_quantity, total_amount] + all_trade_data

    except Exception as e:
        st.warning(f"å¤„ç†PDF {file_name} å‡ºé”™: {str(e)}")
        # æ–°å¢ï¼šé€‚é…ç‰¹æ®Šç§‘ç›®åçš„è¿”å›å€¼é•¿åº¦
        return ["æœªçŸ¥åœºç«™", None, None, None] + [None] * (len(NORMAL_TRADES)*3 + len(SPECIAL_TRADES))

def extract_data_from_excel(file_obj, file_name):
    """ä¿ç•™åŸExcelå¤„ç†é€»è¾‘ï¼Œæ–°å¢ï¼šé€‚é…æ–°ç§‘ç›®"""
    try:
        df = pd.read_excel(file_obj, dtype=object)
        station_name = "æœªçŸ¥åœºç«™"
        # ä»æ–‡ä»¶åæå–åœºç«™åï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        name_without_ext = file_name.split('.')[0]
        if "æ™¶ç››" in name_without_ext:
            station_name = "å¤§åº†æ™¶ç››å…‰ä¼ç”µç«™"
        
        # æå–æ—¥æœŸï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        date_match = re.search(r'\d{4}-\d{2}-\d{2}', name_without_ext)
        date = date_match.group() if date_match else None

        # æå–åˆè®¡æ•°æ®ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        total_quantity = safe_convert_to_numeric(df.iloc[0, 3] if len(df) > 0 else None)
        total_amount = safe_convert_to_numeric(df.iloc[0, 5] if len(df) > 0 else None)

        # æå–ç§‘ç›®æ•°æ®ï¼ˆæ–°å¢ï¼šé€‚é…å¸¸è§„/ç‰¹æ®Šç§‘ç›®ï¼‰
        all_trade_data = []
        # å¸¸è§„ç§‘ç›®ï¼šå¡«å……Noneï¼ˆ3åˆ—ï¼‰
        for _ in NORMAL_TRADES:
            all_trade_data.extend([None, None, None])
        # ç‰¹æ®Šç§‘ç›®ï¼šå¡«å……Noneï¼ˆ1åˆ—ï¼‰
        for _ in SPECIAL_TRADES:
            all_trade_data.append(None)

        return [station_name, date, total_quantity, total_amount] + all_trade_data

    except Exception as e:
        st.warning(f"å¤„ç†Excel {file_name} å‡ºé”™: {str(e)}")
        return ["æœªçŸ¥åœºç«™", None, None, None] + [None] * (len(NORMAL_TRADES)*3 + len(SPECIAL_TRADES))

def calculate_summary_row(data_df):
    """ä¼˜åŒ–ï¼šé€‚é…ç‰¹æ®Šç§‘ç›®æ±‡æ€»ï¼ˆä»…æ±‡æ€»ç”µè´¹ï¼‰"""
    # å¸¸è§„ç§‘ç›®ï¼šæ±‚å’Œç”µé‡/ç”µè´¹ï¼Œå¹³å‡ç”µä»·
    sum_cols = [col for col in data_df.columns if any(key in col for key in ['ç”µé‡', 'ç”µè´¹']) and not any(s in col for s in SPECIAL_TRADES)]
    avg_cols = [col for col in data_df.columns if 'ç”µä»·' in col]
    # ç‰¹æ®Šç§‘ç›®ï¼šä»…æ±‚å’Œç”µè´¹
    special_fee_cols = [col for col in data_df.columns if any(s in col for s in SPECIAL_TRADES) and 'ç”µè´¹' in col]

    summary_row = {'åœºç«™åç§°': 'æ€»è®¡', 'æ¸…åˆ†æ—¥æœŸ': ''}
    # å¸¸è§„ç§‘ç›®æ±‡æ€»
    for col in sum_cols:
        valid_vals = data_df[col].dropna()
        summary_row[col] = valid_vals.sum() if not valid_vals.empty else 0
    for col in avg_cols:
        valid_vals = data_df[col].dropna()
        summary_row[col] = round(valid_vals.mean(), 3) if not valid_vals.empty else None
    # ç‰¹æ®Šç§‘ç›®æ±‡æ€»
    for col in special_fee_cols:
        valid_vals = data_df[col].dropna()
        summary_row[col] = valid_vals.sum() if not valid_vals.empty else 0

    return pd.DataFrame([summary_row])

def to_excel_bytes(df, report_df):
    """ä¿ç•™åŸé€»è¾‘ï¼šè½¬ä¸ºExcelå­—èŠ‚æµ"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='ç»“ç®—æ•°æ®æ˜ç»†', index=False)
        report_df.to_excel(writer, sheet_name='å¤„ç†æŠ¥å‘Š', index=False)
    output.seek(0)
    return output

# ---------------------- Streamlit é¡µé¢å¸ƒå±€ä¸äº¤äº’ï¼ˆä¿ç•™æ‰€æœ‰åŸåŠŸèƒ½ï¼‰ ----------------------
def main():
    st.set_page_config(page_title="é»‘é¾™æ±Ÿæ—¥æ¸…åˆ†æ•°æ®æå–", layout="wide")
    
    # é¡µé¢æ ‡é¢˜ï¼ˆä¿ç•™åŸæ ·å¼ï¼‰
    st.title("ğŸ“Š é»‘é¾™æ±Ÿæ—¥æ¸…åˆ†ç»“ç®—å•æ•°æ®æå–å·¥å…·")
    st.divider()

    # 1. æ–‡ä»¶ä¸Šä¼ åŒºåŸŸï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
    st.subheader("ğŸ“ ä¸Šä¼ æ–‡ä»¶")
    uploaded_files = st.file_uploader(
        "æ”¯æŒPDF/Excelæ ¼å¼ï¼Œå¯æ‰¹é‡ä¸Šä¼ ",
        type=['pdf', 'xlsx'],
        accept_multiple_files=True
    )

    # 2. æ•°æ®å¤„ç†é€»è¾‘ï¼ˆä¿ç•™åŸæµç¨‹ï¼Œé€‚é…æ–°ç§‘ç›®ï¼‰
    if uploaded_files and st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary"):
        st.divider()
        st.subheader("âš™ï¸ å¤„ç†è¿›åº¦")
        
        all_data = []
        total_files = len(uploaded_files)
        processed_files = 0

        # æ‰¹é‡å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆä¿ç•™åŸè¿›åº¦æ¡ï¼‰
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, file in enumerate(uploaded_files):
            file_name = file.name
            status_text.text(f"æ­£åœ¨å¤„ç†ï¼š{file_name}")
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹è°ƒç”¨å¯¹åº”æå–å‡½æ•°ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
            if file_name.lower().endswith('.pdf'):
                data = extract_data_from_pdf(file, file_name)
            else:
                data = extract_data_from_excel(file, file_name)
            
            # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
            if data[1] is not None and any(isinstance(val, (float, int)) for val in data[2:] if val is not None):
                all_data.append(data)
                processed_files += 1
            
            # æ›´æ–°è¿›åº¦ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
            progress_bar.progress((idx + 1) / total_files)

        progress_bar.empty()
        status_text.text("å¤„ç†å®Œæˆï¼")

        # 3. ç»“æœå±•ç¤ºä¸å¯¼å‡ºï¼ˆé€‚é…æ–°ç§‘ç›®åˆ—ï¼‰
        if all_data:
            st.divider()
            st.subheader("ğŸ“ˆ æå–ç»“æœ")
            
            # æ„å»ºç»“æœåˆ—ï¼ˆæ–°å¢ï¼šåŒ…å«æ‰€æœ‰æ–°ç§‘ç›®ï¼Œç‰¹æ®Šç§‘ç›®ä»…ç”µè´¹åˆ—ï¼‰
            result_columns = [
                'åœºç«™åç§°', 'æ¸…åˆ†æ—¥æœŸ', 'åˆè®¡ç”µé‡(å…†ç“¦æ—¶)', 'åˆè®¡ç”µè´¹(å…ƒ)'
            ]
            # å¸¸è§„ç§‘ç›®åˆ—ï¼ˆ3åˆ—ï¼šç”µé‡/ç”µä»·/ç”µè´¹ï¼‰
            for trade in NORMAL_TRADES:
                # åˆ—åç®€åŒ–ï¼ˆé¿å…è¿‡é•¿ï¼‰
                trade_col_name = trade.replace('ï¼ˆç”µèƒ½é‡ï¼‰', '').replace('(ç”µèƒ½é‡ )', '').replace('çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“', 'çœé—´ç»¿ç”µäº¤æ˜“')
                result_columns.extend([
                    f'{trade_col_name}_ç”µé‡',
                    f'{trade_col_name}_ç”µä»·',
                    f'{trade_col_name}_ç”µè´¹'
                ])
            # ç‰¹æ®Šç§‘ç›®åˆ—ï¼ˆä»…ç”µè´¹åˆ—ï¼‰
            for trade in SPECIAL_TRADES:
                result_columns.append(f'{trade}_ç”µè´¹')

            # æ„å»ºDataFrameï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
            result_df = pd.DataFrame(all_data, columns=result_columns)
            num_cols = result_df.columns[2:]
            result_df[num_cols] = result_df[num_cols].apply(pd.to_numeric, errors='coerce')

            # æ’åºå¹¶æ ¼å¼åŒ–æ—¥æœŸï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
            result_df['æ¸…åˆ†æ—¥æœŸ'] = pd.to_datetime(result_df['æ¸…åˆ†æ—¥æœŸ'], errors='coerce')
            result_df = result_df.sort_values(['åœºç«™åç§°', 'æ¸…åˆ†æ—¥æœŸ']).reset_index(drop=True)
            result_df['æ¸…åˆ†æ—¥æœŸ'] = result_df['æ¸…åˆ†æ—¥æœŸ'].dt.strftime('%Y-%m-%d').fillna('')

            # æ·»åŠ æ±‡æ€»è¡Œï¼ˆä¼˜åŒ–åï¼‰
            summary_row = calculate_summary_row(result_df)
            result_df = pd.concat([result_df, summary_row], ignore_index=True)

            # ç”Ÿæˆå¤„ç†æŠ¥å‘Šï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
            failed_files = total_files - processed_files
            success_rate = f"{processed_files / total_files:.2%}" if total_files > 0 else "0%"
            stations = result_df['åœºç«™åç§°'].unique()
            station_count = len(stations) - 1 if 'æ€»è®¡' in stations else len(stations)
            valid_rows = len(result_df) - 1

            report_df = pd.DataFrame({
                'ç»Ÿè®¡é¡¹': ['æ–‡ä»¶æ€»æ•°', 'æˆåŠŸå¤„ç†æ•°', 'å¤±è´¥æ•°', 'å¤„ç†æˆåŠŸç‡', 'æ¶‰åŠåœºç«™æ•°', 'æœ‰æ•ˆæ•°æ®è¡Œæ•°'],
                'æ•°å€¼': [total_files, processed_files, failed_files,
                         success_rate, station_count, valid_rows]
            })

            # å±•ç¤ºç»“æœè¡¨æ ¼ï¼ˆä¿ç•™åŸæ ‡ç­¾é¡µï¼‰
            tab1, tab2 = st.tabs(["ç»“ç®—æ•°æ®æ˜ç»†", "å¤„ç†æŠ¥å‘Š"])
            with tab1:
                st.dataframe(result_df, use_container_width=True)
            with tab2:
                st.dataframe(report_df, use_container_width=True)

            # ç”Ÿæˆä¸‹è½½æ–‡ä»¶ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
            current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
            download_filename = f"é»‘é¾™æ±Ÿç»“ç®—æ•°æ®æå–_{current_time}.xlsx"
            excel_bytes = to_excel_bytes(result_df, report_df)

            # ä¸‹è½½æŒ‰é’®ï¼ˆä¿ç•™åŸæ ·å¼ï¼‰
            st.divider()
            st.download_button(
                label="ğŸ“¥ å¯¼å‡ºExcelæ–‡ä»¶",
                data=excel_bytes,
                file_name=download_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary"
            )

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
            st.info(
                f"""å¤„ç†å®Œæˆï¼
                - æ€»è®¡ä¸Šä¼  {total_files} ä¸ªæ–‡ä»¶ï¼ŒæˆåŠŸå¤„ç† {processed_files} ä¸ªï¼ˆæˆåŠŸç‡ {success_rate}ï¼‰
                - æ¶‰åŠ {station_count} ä¸ªåœºç«™ï¼Œ{valid_rows} è¡Œæœ‰æ•ˆæ•°æ®
                - å·²æå–æ‰€æœ‰ç§‘ç›®ï¼ˆå«é€æ±Ÿè‹/æµ™æ±Ÿç»¿ç”µäº¤æ˜“ã€é˜»å¡è´¹ç”¨ã€ä»·å·®è´¹ç”¨ï¼‰
                """
            )
        else:
            st.warning("âš ï¸ æœªæå–åˆ°æœ‰æ•ˆæ•°æ®ï¼è¯·æ£€æŸ¥ï¼š")
            st.markdown("""
                1. PDFæ˜¯å¦ä¸ºå¯å¤åˆ¶æ–‡æœ¬ï¼ˆéæ‰«æä»¶ï¼‰ï¼›
                2. æ–‡ä»¶æ˜¯å¦ä¸ºé»‘é¾™æ±Ÿæ—¥æ¸…åˆ†æ ¼å¼ï¼›
                3. Excelæ–‡ä»¶æ ¼å¼æ˜¯å¦åŒ¹é…ã€‚
            """)

    # æ— æ–‡ä»¶ä¸Šä¼ æ—¶çš„æç¤ºï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
    elif not uploaded_files and st.button("ğŸš€ å¼€å§‹å¤„ç†", disabled=True):
        st.warning("è¯·å…ˆä¸Šä¼ PDF/Excelæ–‡ä»¶ï¼")

if __name__ == "__main__":
    main()
