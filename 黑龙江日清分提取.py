import streamlit as st
import pandas as pd
import re
from datetime import datetime
import warnings
import pdfplumber
from io import BytesIO

# å¿½ç•¥æ ·å¼è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl.stylesheet")

# ---------------------- æ ¸å¿ƒæå–å‡½æ•°ï¼ˆä¿ç•™åŸé€»è¾‘ï¼Œé€‚é…Streamlitæ–‡ä»¶å¯¹è±¡ï¼‰ ----------------------
def extract_station_name(pdf_lines):
    """ä»PDFå†…å®¹æå–åœºç«™åç§°ï¼ˆä¼˜å…ˆå–å…¬å¸åç§°ï¼Œæ›´ç²¾å‡†ï¼‰"""
    for line in pdf_lines:
        if "å…¬å¸åç§°:" in line:
            station_name = re.sub(r'å…¬å¸åç§°:\s*', '', line).strip()
            station_name = re.sub(r'å¤ªé˜³èƒ½å‘ç”µæœ‰é™å…¬å¸$', 'å…‰ä¼ç”µç«™', station_name)
            return station_name
    return "æœªçŸ¥åœºç«™"

def safe_convert_to_numeric(value, default=None):
    """å®‰å…¨è½¬æ¢ä¸ºæ•°å€¼ï¼Œå…¼å®¹é€—å·åˆ†éš”çš„é‡‘é¢å’Œç©ºå€¼"""
    try:
        if pd.notna(value) and value is not None:
            str_val = str(value).strip()
            if str_val in ['/', 'NA', 'None', '', 'æ— ', 'â€”â€”']:
                return default
            cleaned_value = str_val.replace(',', '').replace(' ', '').strip()
            return pd.to_numeric(cleaned_value)
        return default
    except (ValueError, TypeError):
        return default

def extract_trade_data_by_column(trade_name, pdf_lines):
    """é€‚é…é»‘é¾™æ±ŸPDFæ ¼å¼ï¼šæŒ‰"ç»“ç®—ç±»å‹"åŒ¹é…ï¼Œæå–ç”µé‡/ç”µä»·/ç”µè´¹"""
    quantity = None
    price = None
    fee = None

    for idx, line in enumerate(pdf_lines):
        line_cols = [col.strip() for col in re.split(r'\s+', line) if col.strip()]
        if len(line_cols) >= 5 and trade_name in line_cols[1]:
            quantity = safe_convert_to_numeric(line_cols[2])
            price = safe_convert_to_numeric(line_cols[3])
            fee = safe_convert_to_numeric(line_cols[4])
            break
    return [quantity, price, fee]

def extract_data_from_pdf(file_obj, file_name):
    """é€‚é…Streamlitï¼šæ¥æ”¶æ–‡ä»¶å¯¹è±¡è€Œéè·¯å¾„"""
    try:
        with pdfplumber.open(file_obj) as pdf:
            if not pdf.pages:
                raise ValueError("PDFæ— æœ‰æ•ˆé¡µé¢")
            
            all_text = ""
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    all_text += page_text + "\n"
            pdf_lines = [line.strip() for line in all_text.split('\n') if line.strip()]
            if not pdf_lines:
                raise ValueError("PDFä¸ºæ‰«æä»¶ï¼Œæ— å¯ç”¨æ–‡æœ¬")

        # 1. æå–åœºç«™åç§°
        station_name = extract_station_name(pdf_lines)

        # 2. æå–æ¸…åˆ†æ—¥æœŸ
        date = None
        date_pattern = r'æ¸…åˆ†æ—¥æœŸ\s*(\d{4}-\d{2}-\d{2})'
        for line in pdf_lines:
            date_match = re.search(date_pattern, line)
            if date_match:
                date = date_match.group(1)
                break

        # 3. æå–åˆè®¡ç”µé‡å’Œåˆè®¡ç”µè´¹
        total_quantity = None
        total_amount = None
        for line in pdf_lines:
            line_cols = [col.strip() for col in re.split(r'\s+', line) if col.strip()]
            if "åˆè®¡ç”µé‡" in line_cols and "åˆè®¡ç”µè´¹" in line_cols:
                if "åˆè®¡ç”µé‡" in line_cols:
                    qty_idx = line_cols.index("åˆè®¡ç”µé‡") + 1
                    if qty_idx < len(line_cols):
                        total_quantity = safe_convert_to_numeric(line_cols[qty_idx])
                if "åˆè®¡ç”µè´¹" in line_cols:
                    fee_idx = line_cols.index("åˆè®¡ç”µè´¹") + 1
                    if fee_idx < len(line_cols):
                        total_amount = safe_convert_to_numeric(line_cols[fee_idx])
                break

        # 4. ç›®æ ‡ç»“ç®—ç§‘ç›®
        target_trades = [
            'ä¼˜å…ˆå‘ç”µäº¤æ˜“',
            'ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“',
            'çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“',
            'é€ä¸Šæµ·çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“(ç”µèƒ½é‡ )',
            'é€è¾½å®äº¤æ˜“',
            'é€ååŒ—äº¤æ˜“',
            'é€å±±ä¸œäº¤æ˜“',
            'é€æµ™æ±Ÿäº¤æ˜“',
            'çœå†…ç°è´§æ—¥å‰äº¤æ˜“',
            'çœå†…ç°è´§å®æ—¶äº¤æ˜“',
            'çœé—´ç°è´§æ—¥å‰äº¤æ˜“',
            'çœé—´ç°è´§æ—¥å†…äº¤æ˜“'
        ]

        # 5. æå–æ‰€æœ‰ç›®æ ‡ç§‘ç›®çš„æ•°æ®
        all_trade_data = []
        for trade in target_trades:
            trade_data = extract_trade_data_by_column(trade, pdf_lines)
            all_trade_data.extend(trade_data)

        return [station_name, date, total_quantity, total_amount] + all_trade_data

    except Exception as e:
        st.warning(f"å¤„ç†PDF {file_name} å‡ºé”™: {str(e)}")
        return ["æœªçŸ¥åœºç«™", None, None, None] + [None] * 36

def extract_data_from_excel(file_obj, file_name):
    """é€‚é…Streamlitï¼šæ¥æ”¶æ–‡ä»¶å¯¹è±¡è€Œéè·¯å¾„"""
    try:
        df = pd.read_excel(file_obj, dtype=object)
        station_name = "æœªçŸ¥åœºç«™"
        # ä»æ–‡ä»¶åæå–åœºç«™å
        name_without_ext = file_name.split('.')[0]
        if "æ™¶ç››" in name_without_ext:
            station_name = "å¤§åº†æ™¶ç››å…‰ä¼ç”µç«™"
        
        # æå–æ—¥æœŸ
        date_match = re.search(r'\d{4}-\d{2}-\d{2}', name_without_ext)
        date = date_match.group() if date_match else None

        # æå–åˆè®¡æ•°æ®
        total_quantity = safe_convert_to_numeric(df.iloc[0, 3] if len(df) > 0 else None)
        total_amount = safe_convert_to_numeric(df.iloc[0, 5] if len(df) > 0 else None)

        # ç›®æ ‡ç§‘ç›®
        target_trades = [
            'ä¼˜å…ˆå‘ç”µäº¤æ˜“', 'ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“', 'çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“',
            'é€ä¸Šæµ·çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“(ç”µèƒ½é‡ )', 'é€è¾½å®äº¤æ˜“', 'é€ååŒ—äº¤æ˜“',
            'é€å±±ä¸œäº¤æ˜“', 'é€æµ™æ±Ÿäº¤æ˜“', 'çœå†…ç°è´§æ—¥å‰äº¤æ˜“',
            'çœå†…ç°è´§å®æ—¶äº¤æ˜“', 'çœé—´ç°è´§æ—¥å‰äº¤æ˜“', 'çœé—´ç°è´§æ—¥å†…äº¤æ˜“'
        ]

        all_trade_data = []
        for _ in target_trades:
            all_trade_data.extend([None, None, None])

        return [station_name, date, total_quantity, total_amount] + all_trade_data

    except Exception as e:
        st.warning(f"å¤„ç†Excel {file_name} å‡ºé”™: {str(e)}")
        return ["æœªçŸ¥åœºç«™", None, None, None] + [None] * 36

def calculate_summary_row(data_df):
    """è®¡ç®—æ±‡æ€»è¡Œï¼ˆæ±‚å’Œç”µé‡/ç”µè´¹ï¼Œå¹³å‡ç”µä»·ï¼‰"""
    sum_cols = [col for col in data_df.columns if any(key in col for key in ['ç”µé‡', 'ç”µè´¹'])]
    avg_cols = [col for col in data_df.columns if 'ç”µä»·' in col]

    summary_row = {'åœºç«™åç§°': 'æ€»è®¡', 'æ¸…åˆ†æ—¥æœŸ': ''}
    for col in sum_cols:
        valid_vals = data_df[col].dropna()
        summary_row[col] = valid_vals.sum() if not valid_vals.empty else 0
    for col in avg_cols:
        valid_vals = data_df[col].dropna()
        summary_row[col] = round(valid_vals.mean(), 3) if not valid_vals.empty else None

    return pd.DataFrame([summary_row])

def to_excel_bytes(df, report_df):
    """å°†DataFrameè½¬ä¸ºExcelå­—èŠ‚æµï¼Œç”¨äºä¸‹è½½"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='ç»“ç®—æ•°æ®æ˜ç»†', index=False)
        report_df.to_excel(writer, sheet_name='å¤„ç†æŠ¥å‘Š', index=False)
    output.seek(0)
    return output

# ---------------------- Streamlit é¡µé¢å¸ƒå±€ä¸äº¤äº’ ----------------------
def main():
    st.set_page_config(page_title="é»‘é¾™æ±Ÿæ—¥æ¸…åˆ†æ•°æ®æå–", layout="wide")
    
    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ“Š é»‘é¾™æ±Ÿæ—¥æ¸…åˆ†ç»“ç®—å•æ•°æ®æå–å·¥å…·")
    st.divider()

    # 1. æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.subheader("ğŸ“ ä¸Šä¼ æ–‡ä»¶")
    uploaded_files = st.file_uploader(
        "æ”¯æŒPDF/Excelæ ¼å¼ï¼Œå¯æ‰¹é‡ä¸Šä¼ ",
        type=['pdf', 'xlsx'],
        accept_multiple_files=True
    )

    # 2. æ•°æ®å¤„ç†é€»è¾‘
    if uploaded_files and st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary"):
        st.divider()
        st.subheader("âš™ï¸ å¤„ç†è¿›åº¦")
        
        all_data = []
        total_files = len(uploaded_files)
        processed_files = 0

        # æ‰¹é‡å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, file in enumerate(uploaded_files):
            file_name = file.name
            status_text.text(f"æ­£åœ¨å¤„ç†ï¼š{file_name}")
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹è°ƒç”¨å¯¹åº”æå–å‡½æ•°
            if file_name.lower().endswith('.pdf'):
                data = extract_data_from_pdf(file, file_name)
            else:
                data = extract_data_from_excel(file, file_name)
            
            # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
            if data[1] is not None and any(isinstance(val, (float, int)) for val in data[2:] if val is not None):
                all_data.append(data)
                processed_files += 1
            
            # æ›´æ–°è¿›åº¦
            progress_bar.progress((idx + 1) / total_files)

        progress_bar.empty()
        status_text.text("å¤„ç†å®Œæˆï¼")

        # 3. ç»“æœå±•ç¤ºä¸å¯¼å‡º
        if all_data:
            st.divider()
            st.subheader("ğŸ“ˆ æå–ç»“æœ")
            
            # æ„å»ºç»“æœDataFrame
            result_columns = [
                'åœºç«™åç§°', 'æ¸…åˆ†æ—¥æœŸ', 'åˆè®¡ç”µé‡(å…†ç“¦æ—¶)', 'åˆè®¡ç”µè´¹(å…ƒ)',
                'ä¼˜å…ˆå‘ç”µäº¤æ˜“_ç”µé‡', 'ä¼˜å…ˆå‘ç”µäº¤æ˜“_ç”µä»·', 'ä¼˜å…ˆå‘ç”µäº¤æ˜“_ç”µè´¹',
                'ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µ_ç”µé‡', 'ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µ_ç”µä»·', 'ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µ_ç”µè´¹',
                'çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“_ç”µé‡', 'çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“_ç”µä»·', 'çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“_ç”µè´¹',
                'é€ä¸Šæµ·çœé—´ç»¿ç”µäº¤æ˜“_ç”µé‡', 'é€ä¸Šæµ·çœé—´ç»¿ç”µäº¤æ˜“_ç”µä»·', 'é€ä¸Šæµ·çœé—´ç»¿ç”µäº¤æ˜“_ç”µè´¹',
                'é€è¾½å®äº¤æ˜“_ç”µé‡', 'é€è¾½å®äº¤æ˜“_ç”µä»·', 'é€è¾½å®äº¤æ˜“_ç”µè´¹',
                'é€ååŒ—äº¤æ˜“_ç”µé‡', 'é€ååŒ—äº¤æ˜“_ç”µä»·', 'é€ååŒ—äº¤æ˜“_ç”µè´¹',
                'é€å±±ä¸œäº¤æ˜“_ç”µé‡', 'é€å±±ä¸œäº¤æ˜“_ç”µä»·', 'é€å±±ä¸œäº¤æ˜“_ç”µè´¹',
                'é€æµ™æ±Ÿäº¤æ˜“_ç”µé‡', 'é€æµ™æ±Ÿäº¤æ˜“_ç”µä»·', 'é€æµ™æ±Ÿäº¤æ˜“_ç”µè´¹',
                'çœå†…ç°è´§æ—¥å‰äº¤æ˜“_ç”µé‡', 'çœå†…ç°è´§æ—¥å‰äº¤æ˜“_ç”µä»·', 'çœå†…ç°è´§æ—¥å‰äº¤æ˜“_ç”µè´¹',
                'çœå†…ç°è´§å®æ—¶äº¤æ˜“_ç”µé‡', 'çœå†…ç°è´§å®æ—¶äº¤æ˜“_ç”µä»·', 'çœå†…ç°è´§å®æ—¶äº¤æ˜“_ç”µè´¹',
                'çœé—´ç°è´§æ—¥å‰äº¤æ˜“_ç”µé‡', 'çœé—´ç°è´§æ—¥å‰äº¤æ˜“_ç”µä»·', 'çœé—´ç°è´§æ—¥å‰äº¤æ˜“_ç”µè´¹',
                'çœé—´ç°è´§æ—¥å†…äº¤æ˜“_ç”µé‡', 'çœé—´ç°è´§æ—¥å†…äº¤æ˜“_ç”µä»·', 'çœé—´ç°è´§æ—¥å†…äº¤æ˜“_ç”µè´¹'
            ]

            result_df = pd.DataFrame(all_data, columns=result_columns)
            num_cols = result_df.columns[2:]
            result_df[num_cols] = result_df[num_cols].apply(pd.to_numeric, errors='coerce')

            # æ’åºå¹¶æ ¼å¼åŒ–æ—¥æœŸ
            result_df['æ¸…åˆ†æ—¥æœŸ'] = pd.to_datetime(result_df['æ¸…åˆ†æ—¥æœŸ'], errors='coerce')
            result_df = result_df.sort_values(['åœºç«™åç§°', 'æ¸…åˆ†æ—¥æœŸ']).reset_index(drop=True)
            result_df['æ¸…åˆ†æ—¥æœŸ'] = result_df['æ¸…åˆ†æ—¥æœŸ'].dt.strftime('%Y-%m-%d').fillna('')

            # æ·»åŠ æ±‡æ€»è¡Œ
            summary_row = calculate_summary_row(result_df)
            result_df = pd.concat([result_df, summary_row], ignore_index=True)

            # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
            failed_files = total_files - processed_files
            success_rate = f"{processed_files / total_files:.2%}" if total_files > 0 else "0%"
            stations = result_df['åœºç«™åç§°'].unique()
            station_count = len(stations) - 1 if 'æ€»è®¡' in stations else len(stations)
            valid_rows = len(result_df) - 1

            report_df = pd.DataFrame({
                'ç»Ÿè®¡é¡¹': ['æ–‡ä»¶æ€»æ•°', 'æˆåŠŸå¤„ç†æ•°', 'å¤±è´¥æ•°', 'å¤„ç†æˆåŠŸç‡', 'æ¶‰åŠåœºç«™æ•°', 'æœ‰æ•ˆæ•°æ®è¡Œæ•°'],
                'æ•°å€¼': [total_files, processed_files, failed_files,
                         success_rate, station_count, valid_rows]
            })

            # å±•ç¤ºç»“æœè¡¨æ ¼
            tab1, tab2 = st.tabs(["ç»“ç®—æ•°æ®æ˜ç»†", "å¤„ç†æŠ¥å‘Š"])
            with tab1:
                st.dataframe(result_df, use_container_width=True)
            with tab2:
                st.dataframe(report_df, use_container_width=True)

            # ç”Ÿæˆä¸‹è½½æ–‡ä»¶
            current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
            download_filename = f"é»‘é¾™æ±Ÿç»“ç®—æ•°æ®æå–_{current_time}.xlsx"
            excel_bytes = to_excel_bytes(result_df, report_df)

            # ä¸‹è½½æŒ‰é’®
            st.divider()
            st.download_button(
                label="ğŸ“¥ å¯¼å‡ºExcelæ–‡ä»¶",
                data=excel_bytes,
                file_name=download_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary"
            )

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            st.info(
                f"""å¤„ç†å®Œæˆï¼
                - æ€»è®¡ä¸Šä¼  {total_files} ä¸ªæ–‡ä»¶ï¼ŒæˆåŠŸå¤„ç† {processed_files} ä¸ªï¼ˆæˆåŠŸç‡ {success_rate}ï¼‰
                - æ¶‰åŠ {station_count} ä¸ªåœºç«™ï¼Œ{valid_rows} è¡Œæœ‰æ•ˆæ•°æ®
                """
            )
        else:
            st.warning("âš ï¸ æœªæå–åˆ°æœ‰æ•ˆæ•°æ®ï¼è¯·æ£€æŸ¥ï¼š")
            st.markdown("""
                1. PDFæ˜¯å¦ä¸ºå¯å¤åˆ¶æ–‡æœ¬ï¼ˆéæ‰«æä»¶ï¼‰ï¼›
                2. æ–‡ä»¶æ˜¯å¦ä¸ºé»‘é¾™æ±Ÿæ—¥æ¸…åˆ†æ ¼å¼ï¼›
                3. Excelæ–‡ä»¶æ ¼å¼æ˜¯å¦åŒ¹é…ã€‚
            """)

    # æ— æ–‡ä»¶ä¸Šä¼ æ—¶çš„æç¤º
    elif not uploaded_files and st.button("ğŸš€ å¼€å§‹å¤„ç†", disabled=True):
        st.warning("è¯·å…ˆä¸Šä¼ PDF/Excelæ–‡ä»¶ï¼")

if __name__ == "__main__":
    main()
