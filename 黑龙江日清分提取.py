import streamlit as st
import pandas as pd
import re
from datetime import datetime
import warnings
import pdfplumber
from io import BytesIO

# å¿½ç•¥æ ·å¼è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl.stylesheet")

# ---------------------- æ ¸å¿ƒé…ç½® ----------------------
# ç§‘ç›®ç¼–ç åˆ°åç§°çš„å®Œæ•´æ˜ å°„
TRADE_CODE_MAP = {
    "101010101": "ä¼˜å…ˆå‘ç”µäº¤æ˜“",
    "101020101": "ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“", 
    "101020301": "çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“",
    "101040322": "é€ä¸Šæµ·çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“",
    "102020101": "é€è¾½å®äº¤æ˜“",
    "102020301": "é€ååŒ—äº¤æ˜“", 
    "102010101": "é€å±±ä¸œäº¤æ˜“",
    "102010201": "é€æµ™æ±Ÿäº¤æ˜“",
    "202030001": "é€æ±Ÿè‹çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“",
    "202030002": "é€æµ™æ±Ÿçœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“",
    "101080101": "çœå†…ç°è´§æ—¥å‰äº¤æ˜“",
    "101080201": "çœå†…ç°è´§å®æ—¶äº¤æ˜“",
    "101080301": "çœé—´ç°è´§æ—¥å‰äº¤æ˜“",
    "101080401": "çœé—´ç°è´§æ—¥å†…äº¤æ˜“",
    "201010101": "ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨",
    "201020101": "çœé—´çœå†…ä»·å·®è´¹ç”¨"
}

ALL_TRADES = list(TRADE_CODE_MAP.values())
SPECIAL_TRADES = ["ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨", "çœé—´çœå†…ä»·å·®è´¹ç”¨"]
REGULAR_TRADES = [trade for trade in ALL_TRADES if trade not in SPECIAL_TRADES]

# ---------------------- æ ¸å¿ƒæå–å‡½æ•°ï¼ˆå®Œå…¨é‡å†™ï¼‰ ----------------------
def safe_convert_to_numeric(value):
    """å®‰å…¨è½¬æ¢ä¸ºæ•°å€¼"""
    if value is None or pd.isna(value) or value == '':
        return None
    try:
        if isinstance(value, str):
            # ç§»é™¤åƒåˆ†ä½é€—å·å’Œå…¶ä»–éæ•°å­—å­—ç¬¦
            cleaned = re.sub(r'[^\d.-]', '', value)
            if cleaned and cleaned not in ['-', '.', '']:
                return float(cleaned)
        return float(value)
    except (ValueError, TypeError):
        return None

def extract_station_and_date(pdf_text):
    """æå–åœºç«™åç§°å’Œæ—¥æœŸ - æ”¹è¿›ç‰ˆ"""
    lines = pdf_text.split('\n')
    
    station_name = "æœªçŸ¥åœºç«™"
    date = None
    
    # æå–åœºç«™åç§°
    for i, line in enumerate(lines):
        line_clean = line.strip()
        
        # æ–¹æ³•1: ä»å…¬å¸åç§°æå–
        if "å…¬å¸åç§°" in line_clean:
            match = re.search(r'å…¬å¸åç§°[:ï¼š]\s*(.+?æœ‰é™å…¬å¸)', line_clean)
            if match:
                base_company = match.group(1).strip()
                
                # æŸ¥æ‰¾æœºç»„ä¿¡æ¯åˆ¤æ–­A/Båœºç«™
                station_type = "æœªçŸ¥åœºç«™"
                for j in range(max(0, i-3), min(len(lines), i+10)):
                    if "æœºç»„" in lines[j]:
                        if "B" in lines[j].upper() or "2" in lines[j] or "äºŒ" in lines[j]:
                            station_type = "åŒå‘Bé£ç”µåœº"
                        elif "A" in lines[j].upper() or "1" in lines[j] or "ä¸€" in lines[j]:
                            station_type = "åŒå‘Aé£ç”µåœº"
                        break
                
                station_name = f"{base_company}ï¼ˆ{station_type}ï¼‰"
                break
        
        # æ–¹æ³•2: ä»åŒ…å«é£ç”µåœºçš„è¡Œæå–
        if "é£ç”µåœº" in line_clean and station_name == "æœªçŸ¥åœºç«™":
            match = re.search(r'([^ï¼Œã€‚ï¼ï¼Ÿ]+é£ç”µåœº)', line_clean)
            if match:
                station_name = match.group(1).strip()
    
    # æå–æ—¥æœŸ
    for line in lines:
        patterns = [
            r'æ¸…åˆ†æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2})',
            r'æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2})',
            r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, line)
            if match:
                date_str = match.group(1)
                date_str = date_str.replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
                date = date_str
                break
        if date:
            break
    
    return station_name, date

def extract_data_using_pdfplumber_tables(file_obj):
    """ä½¿ç”¨pdfplumberçš„è¡¨æ ¼æå–åŠŸèƒ½ - è¿™æ˜¯å…³é”®ä¿®å¤"""
    try:
        with pdfplumber.open(file_obj) as pdf:
            # å°è¯•æå–æ‰€æœ‰é¡µé¢çš„è¡¨æ ¼
            all_tables = []
            for page in pdf.pages:
                tables = page.extract_tables()
                if tables:
                    for table in tables:
                        # æ¸…ç†è¡¨æ ¼æ•°æ®
                        cleaned_table = []
                        for row in table:
                            cleaned_row = [cell.strip() if cell else "" for cell in row]
                            cleaned_table.append(cleaned_row)
                        all_tables.append(cleaned_table)
            
            return all_tables
    except Exception as e:
        st.error(f"è¡¨æ ¼æå–å¤±è´¥: {e}")
        return []

def parse_trade_table_data(tables):
    """è§£æäº¤æ˜“è¡¨æ ¼æ•°æ®"""
    trade_data = {}
    
    # åˆå§‹åŒ–æ‰€æœ‰ç§‘ç›®
    for trade in ALL_TRADES:
        if trade in SPECIAL_TRADES:
            trade_data[trade] = {'fee': None}
        else:
            trade_data[trade] = {'quantity': None, 'price': None, 'fee': None}
    
    for table in tables:
        if len(table) < 2:  # è‡³å°‘è¦æœ‰è¡¨å¤´å’Œæ•°æ®è¡Œ
            continue
            
        # æŸ¥æ‰¾è¡¨å¤´è¡Œï¼Œè¯†åˆ«åˆ—ç´¢å¼•
        header_row = -1
        code_col = -1
        name_col = -1
        qty_col = -1
        price_col = -1
        fee_col = -1
        
        for i, row in enumerate(table):
            row_str = ' '.join([str(cell) for cell in row if cell])
            if "ç§‘ç›®ç¼–ç " in row_str or "ç¼–ç " in row_str:
                header_row = i
                # ç¡®å®šå„åˆ—ä½ç½®
                for j, cell in enumerate(row):
                    if cell and ("ç§‘ç›®ç¼–ç " in str(cell) or "ç¼–ç " in str(cell)):
                        code_col = j
                    elif cell and ("ç§‘ç›®åç§°" in str(cell) or "åç§°" in str(cell)):
                        name_col = j
                    elif cell and ("ç”µé‡" in str(cell)):
                        qty_col = j
                    elif cell and ("ç”µä»·" in str(cell)):
                        price_col = j
                    elif cell and ("ç”µè´¹" in str(cell)):
                        fee_col = j
                break
        
        if header_row == -1:
            continue
            
        # è§£ææ•°æ®è¡Œ
        for i in range(header_row + 1, len(table)):
            row = table[i]
            if len(row) <= max(code_col, name_col, qty_col, price_col, fee_col):
                continue
                
            # æå–ç§‘ç›®ç¼–ç 
            trade_code = str(row[code_col]) if code_col < len(row) else ""
            trade_name = None
            
            # é€šè¿‡ç¼–ç è·å–ç§‘ç›®åç§°
            if trade_code in TRADE_CODE_MAP:
                trade_name = TRADE_CODE_MAP[trade_code]
            else:
                # å°è¯•é€šè¿‡åç§°åŒ¹é…
                name_cell = str(row[name_col]) if name_col < len(row) else ""
                for code, name in TRADE_CODE_MAP.items():
                    if name in name_cell:
                        trade_name = name
                        break
            
            if not trade_name:
                continue
                
            # æå–æ•°æ®
            is_special = trade_name in SPECIAL_TRADES
            
            if is_special:
                # ç‰¹æ®Šç§‘ç›®åªæœ‰ç”µè´¹
                fee_val = str(row[fee_col]) if fee_col < len(row) else ""
                trade_data[trade_name]['fee'] = safe_convert_to_numeric(fee_val)
            else:
                # å¸¸è§„ç§‘ç›®æœ‰ç”µé‡ã€ç”µä»·ã€ç”µè´¹
                qty_val = str(row[qty_col]) if qty_col < len(row) else ""
                price_val = str(row[price_col]) if price_col < len(row) else ""
                fee_val = str(row[fee_col]) if fee_col < len(row) else ""
                
                trade_data[trade_name]['quantity'] = safe_convert_to_numeric(qty_val)
                trade_data[trade_name]['price'] = safe_convert_to_numeric(price_val)
                trade_data[trade_name]['fee'] = safe_convert_to_numeric(fee_val)
    
    return trade_data

def extract_data_using_text_analysis(pdf_text):
    """å¤‡ç”¨æ–¹æ³•ï¼šé€šè¿‡æ–‡æœ¬åˆ†ææå–æ•°æ®"""
    trade_data = {}
    
    # åˆå§‹åŒ–æ‰€æœ‰ç§‘ç›®
    for trade in ALL_TRADES:
        if trade in SPECIAL_TRADES:
            trade_data[trade] = {'fee': None}
        else:
            trade_data[trade] = {'quantity': None, 'price': None, 'fee': None}
    
    lines = pdf_text.split('\n')
    
    # æŸ¥æ‰¾äº¤æ˜“æ•°æ®åŒºåŸŸ
    data_start = -1
    for i, line in enumerate(lines):
        if "ç§‘ç›®ç¼–ç " in line and "ç§‘ç›®åç§°" in line:
            data_start = i
            break
    
    if data_start == -1:
        return trade_data
    
    # è§£ææ•°æ®è¡Œ
    for i in range(data_start + 1, len(lines)):
        line = lines[i].strip()
        if not line or "åˆè®¡" in line or "æ€»è®¡" in line:
            continue
            
        # æŸ¥æ‰¾ç§‘ç›®ç¼–ç 
        code_match = re.search(r'\b(\d{9})\b', line)
        if not code_match:
            continue
            
        code = code_match.group(1)
        if code not in TRADE_CODE_MAP:
            continue
            
        trade_name = TRADE_CODE_MAP[code]
        is_special = trade_name in SPECIAL_TRADES
        
        # æå–æ•°å­—ï¼ˆè·³è¿‡ç§‘ç›®ç¼–ç ï¼‰
        numbers = []
        line_parts = line.split()
        
        # æ‰¾åˆ°ç¼–ç ä½ç½®ï¼Œä»åé¢å¼€å§‹æå–æ•°å­—
        code_index = -1
        for idx, part in enumerate(line_parts):
            if code in part:
                code_index = idx
                break
        
        if code_index >= 0:
            # æå–ç¼–ç åé¢çš„æ•°å­—
            for j in range(code_index + 1, len(line_parts)):
                part = line_parts[j]
                num_match = re.search(r'-?[\d,]+\.?\d*', part)
                if num_match:
                    numbers.append(safe_convert_to_numeric(num_match.group()))
        
        # åˆ†é…æ•°æ®
        if is_special:
            if numbers:
                trade_data[trade_name]['fee'] = numbers[0]
        else:
            if len(numbers) >= 3:
                trade_data[trade_name]['quantity'] = numbers[0]
                trade_data[trade_name]['price'] = numbers[1]
                trade_data[trade_name]['fee'] = numbers[2]
            elif len(numbers) == 2:
                trade_data[trade_name]['quantity'] = numbers[0]
                trade_data[trade_name]['fee'] = numbers[1]
            elif len(numbers) == 1:
                trade_data[trade_name]['fee'] = numbers[0]
    
    return trade_data

def extract_total_data(pdf_text):
    """æå–åˆè®¡æ•°æ®"""
    total_quantity, total_amount = None, None
    
    lines = pdf_text.split('\n')
    
    for line in lines:
        line_clean = line.replace(' ', '')
        
        # æŸ¥æ‰¾åˆè®¡ç”µé‡
        if "åˆè®¡ç”µé‡" in line_clean:
            match = re.search(r'åˆè®¡ç”µé‡[^\d]*([\d,]+\.?\d*)', line_clean)
            if match:
                total_quantity = safe_convert_to_numeric(match.group(1))
        
        # æŸ¥æ‰¾åˆè®¡ç”µè´¹
        if "åˆè®¡ç”µè´¹" in line_clean:
            match = re.search(r'åˆè®¡ç”µè´¹[^\d]*([\d,]+\.?\d*)', line_clean)
            if match:
                total_amount = safe_convert_to_numeric(match.group(1))
    
    return total_quantity, total_amount

def extract_data_from_pdf(file_obj, file_name):
    """ä»PDFæå–æ•°æ® - ç»¼åˆæ–¹æ³•"""
    try:
        # é¦–å…ˆæå–æ–‡æœ¬å†…å®¹ç”¨äºåŸºæœ¬ä¿¡æ¯æå–
        with pdfplumber.open(file_obj) as pdf:
            all_text = ""
            for page in pdf.pages:
                text = page.extract_text()
                if text:
                    all_text += text + "\n"
        
        if not all_text or len(all_text.strip()) < 50:
            raise ValueError("PDFä¸ºç©ºæˆ–æ–‡æœ¬å†…å®¹å¤ªå°‘")
        
        # æå–åŸºæœ¬ä¿¡æ¯å’Œåˆè®¡æ•°æ®
        station_name, date = extract_station_and_date(all_text)
        total_quantity, total_amount = extract_total_data(all_text)
        
        # ä»æ–‡ä»¶åæå–æ—¥æœŸï¼ˆå¤‡ç”¨ï¼‰
        if not date:
            date_match = re.search(r'(\d{4}-\d{2}-\d{2})', file_name)
            if date_match:
                date = date_match.group(1)
        
        # é‡ç½®æ–‡ä»¶æŒ‡é’ˆï¼Œé‡æ–°è¯»å–ç”¨äºè¡¨æ ¼æå–
        file_obj.seek(0)
        
        # æ–¹æ³•1: ä½¿ç”¨è¡¨æ ¼æå–ï¼ˆä¼˜å…ˆï¼‰
        tables = extract_data_using_pdfplumber_tables(file_obj)
        trade_data = parse_trade_table_data(tables)
        
        # æ–¹æ³•2: å¦‚æœè¡¨æ ¼æå–å¤±è´¥ï¼Œä½¿ç”¨æ–‡æœ¬åˆ†æ
        if not any(trade_data[trade].get('fee') for trade in ALL_TRADES):
            trade_data = extract_data_using_text_analysis(all_text)
        
        # æ„å»ºç»“æœåˆ—è¡¨
        result = [station_name, date, total_quantity, total_amount]
        
        # æ·»åŠ å¸¸è§„ç§‘ç›®æ•°æ®
        for trade in REGULAR_TRADES:
            data = trade_data.get(trade, {'quantity': None, 'price': None, 'fee': None})
            result.extend([data['quantity'], data['price'], data['fee']])
        
        # æ·»åŠ ç‰¹æ®Šç§‘ç›®æ•°æ®
        for trade in SPECIAL_TRADES:
            data = trade_data.get(trade, {'fee': None})
            result.append(data['fee'])
        
        return result
        
    except Exception as e:
        st.error(f"å¤„ç†PDF {file_name} å‡ºé”™: {str(e)}")
        # è¿”å›æ­£ç¡®é•¿åº¦çš„ç©ºæ•°æ®
        return ["æœªçŸ¥åœºç«™", None, None, None] + [None] * (len(REGULAR_TRADES) * 3 + len(SPECIAL_TRADES))

# ---------------------- Streamlit åº”ç”¨ ----------------------
def main():
    st.set_page_config(page_title="é»‘é¾™æ±Ÿæ—¥æ¸…åˆ†æ•°æ®æå–å·¥å…·", layout="wide")
    
    st.title("ğŸ“Š é»‘é¾™æ±Ÿæ—¥æ¸…åˆ†ç»“ç®—å•æ•°æ®æå–å·¥å…·ï¼ˆç»ˆæä¿®å¤ç‰ˆï¼‰")
    st.markdown("**ä¿®å¤é‡ç‚¹ï¼šè¡¨æ ¼ç»“æ„è¯†åˆ«ã€åŒå‘Bé£ç”µåœºè¯†åˆ«ã€ç§‘ç›®æ•°æ®æå–**")
    st.divider()
    
    # æ˜¾ç¤ºç§‘ç›®ä¿¡æ¯
    with st.expander("ğŸ“‹ æ”¯æŒçš„ç§‘ç›®åˆ—è¡¨"):
        st.write("**å¸¸è§„ç§‘ç›®ï¼ˆç”µé‡ã€ç”µä»·ã€ç”µè´¹ï¼‰ï¼š**")
        for trade in REGULAR_TRADES:
            st.write(f"- {trade}")
        
        st.write("**ç‰¹æ®Šç§‘ç›®ï¼ˆä»…ç”µè´¹ï¼‰ï¼š**")
        for trade in SPECIAL_TRADES:
            st.write(f"- {trade}")
    
    st.subheader("ğŸ“ ä¸Šä¼ æ–‡ä»¶")
    uploaded_files = st.file_uploader(
        "æ”¯æŒPDFæ ¼å¼ï¼Œå¯æ‰¹é‡ä¸Šä¼ ",
        type=['pdf'],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        if st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary"):
            st.divider()
            st.subheader("âš™ï¸ å¤„ç†è¿›åº¦")
            
            all_data = []
            progress_bar = st.progress(0)
            
            for idx, file in enumerate(uploaded_files):
                progress_bar.progress((idx + 1) / len(uploaded_files))
                
                try:
                    data = extract_data_from_pdf(file, file.name)
                    if data[1] is not None:  # æœ‰æ—¥æœŸè§†ä¸ºæˆåŠŸ
                        all_data.append(data)
                        st.success(f"âœ“ {file.name} å¤„ç†æˆåŠŸ")
                    else:
                        st.warning(f"âš  {file.name} ç¼ºå°‘æ—¥æœŸä¿¡æ¯")
                except Exception as e:
                    st.error(f"âœ— {file.name} å¤„ç†å¤±è´¥: {str(e)}")
            
            progress_bar.empty()
            
            if all_data:
                # æ„å»ºç»“æœDataFrame
                result_columns = ['åœºç«™åç§°', 'æ¸…åˆ†æ—¥æœŸ', 'åˆè®¡ç”µé‡(å…†ç“¦æ—¶)', 'åˆè®¡ç”µè´¹(å…ƒ)']
                
                for trade in REGULAR_TRADES:
                    trade_short = trade.replace('çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“', 'çœé—´ç»¿ç”µäº¤æ˜“')
                    result_columns.extend([f'{trade_short}_ç”µé‡', f'{trade_short}_ç”µä»·', f'{trade_short}_ç”µè´¹'])
                
                for trade in SPECIAL_TRADES:
                    result_columns.append(f'{trade}_ç”µè´¹')
                
                result_df = pd.DataFrame(all_data, columns=result_columns)
                
                # æ˜¾ç¤ºç»“æœ
                st.subheader("ğŸ“ˆ æå–ç»“æœ")
                st.dataframe(result_df, use_container_width=True)
                
                # ç»Ÿè®¡ä¿¡æ¯
                st.info(f"**ç»Ÿè®¡ä¿¡æ¯ï¼š** å…±å¤„ç† {len(all_data)} ä¸ªæ–‡ä»¶ï¼Œæ¶‰åŠ {result_df['åœºç«™åç§°'].nunique()} ä¸ªåœºç«™")
                
                # æ£€æŸ¥åŒå‘Bé£ç”µåœºæ˜¯å¦å­˜åœ¨
                has_b_station = any('åŒå‘B' in str(name) for name in result_df['åœºç«™åç§°'])
                if not has_b_station:
                    st.warning("âš ï¸ æœªæ£€æµ‹åˆ°åŒå‘Bé£ç”µåœºæ•°æ®ï¼Œè¯·æ£€æŸ¥PDFä¸­æœºç»„ä¿¡æ¯")
                
                # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
                data_columns = result_columns[4:]  # è·³è¿‡å‰4åˆ—åŸºæœ¬ä¿¡æ¯
                non_null_count = result_df[data_columns].notna().sum().sum()
                total_cells = len(result_df) * len(data_columns)
                st.info(f"**æ•°æ®å®Œæ•´æ€§ï¼š** {non_null_count}/{total_cells} ä¸ªæ•°æ®å•å…ƒæ ¼æœ‰å€¼ ({non_null_count/total_cells*100:.1f}%)")
                
                # ä¸‹è½½åŠŸèƒ½
                current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    result_df.to_excel(writer, index=False)
                output.seek(0)
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½Excelæ–‡ä»¶",
                    data=output,
                    file_name=f"é»‘é¾™æ±Ÿç»“ç®—æ•°æ®_ç»ˆæä¿®å¤ç‰ˆ_{current_time}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary"
                )
                
                st.success("âœ… å¤„ç†å®Œæˆï¼")
    
    else:
        st.info("ğŸ‘† è¯·ä¸Šä¼ PDFæ–‡ä»¶å¼€å§‹å¤„ç†")

if __name__ == "__main__":
    main()
