import streamlit as st
import pandas as pd
import re
from datetime import datetime
import warnings
import pdfplumber
from io import BytesIO

# å¿½ç•¥æ ·å¼è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl.stylesheet")

# ---------------------- æ ¸å¿ƒé…ç½®ï¼ˆå¯æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´ï¼‰ ----------------------
# ç‰¹æ®Šç§‘ç›®ï¼šæ— ç”µé‡/ç”µä»·ï¼Œä»…éœ€æå–ç”µè´¹ï¼ˆä¸ç”Ÿæˆç”µé‡/ç”µä»·åˆ—ï¼‰
SPECIAL_TRADE_KEYWORDS = ['é˜»å¡è´¹ç”¨', 'ä»·å·®è´¹ç”¨']
# æ— æ•ˆè¡Œè¿‡æ»¤å…³é”®è¯ï¼ˆå½»åº•æ’é™¤å«è¿™äº›å­—ç¬¦çš„è¡Œï¼‰
INVALID_LINE_KEYWORDS = ['hf', 'HF', 'å¿', 'é•‡', 'ä¹¡', 'æ‘', '_', 'â€”']
# äº¤æ˜“è¡¨å¤´å…³é”®è¯ï¼ˆæ”¾å®½åŒ¹é…ï¼Œåªè¦åŒ…å«ç¼–ç å’Œç±»å‹å³å¯ï¼‰
TRADE_HEADER_KEYWORDS = ['ç§‘ç›®ç¼–ç ', 'ç»“ç®—ç±»å‹']

# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° ----------------------
def safe_convert_to_numeric(value, default=None):
    """å®‰å…¨è½¬æ¢ä¸ºæ•°å€¼ï¼Œå…¼å®¹é€—å·åˆ†éš”çš„é‡‘é¢å’Œç©ºå€¼"""
    try:
        if pd.notna(value) and value is not None:
            str_val = str(value).strip()
            if str_val in ['/', 'NA', 'None', '', 'æ— ', 'â€”â€”', '0.00', '-']:
                return default
            cleaned_value = str_val.replace(',', '').replace(' ', '').strip()
            return pd.to_numeric(cleaned_value)
        return default
    except (ValueError, TypeError):
        return default

def filter_invalid_lines(pdf_lines):
    """è¿‡æ»¤å«æ— æ•ˆå…³é”®è¯çš„è¡Œï¼Œå‡å°‘å¹²æ‰°"""
    valid_lines = []
    for line in pdf_lines:
        line = line.replace('\\t', ' ').strip()
        # è¿‡æ»¤è¿‡çŸ­è¡Œï¼ˆå°‘äº2å­—ç¬¦ï¼‰å’Œå«æ— æ•ˆå…³é”®è¯çš„è¡Œ
        if len(line) >= 2 and not any(kw in line for kw in INVALID_LINE_KEYWORDS):
            valid_lines.append(line)
    return valid_lines

def extract_company_name(pdf_lines):
    """ç²¾å‡†æå–å…¬å¸åç§°"""
    for line in pdf_lines:
        if "å…¬å¸åç§°:" in line or "å…¬å¸åç§°ï¼š" in line:
            # åªä¿ç•™ä¸­æ–‡ã€æ•°å­—ã€æ‹¬å·å’Œâ€œæœ‰é™å…¬å¸â€åç¼€
            company_match = re.search(r'[\u4e00-\u9fa5a-zA-Z0-9()ï¼ˆï¼‰]+æœ‰é™å…¬å¸', line)
            if company_match:
                return company_match.group().strip()
    return "æœªçŸ¥å…¬å¸"

def extract_clear_date(pdf_lines):
    """ç²¾å‡†æå–æ¸…åˆ†æ—¥æœŸ"""
    date_pattern = r'æ¸…åˆ†æ—¥æœŸ\s*[:ï¼š]?\s*(\d{4}-\d{2}-\d{2})'
    for line in pdf_lines:
        date_match = re.search(date_pattern, line)
        if date_match:
            return date_match.group(1)
    return None

# ---------------------- æ ¸å¿ƒæå–é€»è¾‘ï¼ˆå…¨ç§‘ç›®è¦†ç›–+é¡ºåºä¿ç•™ï¼‰ ----------------------
def classify_trade_type(trade_name):
    """åˆ¤æ–­ç§‘ç›®ç±»å‹ï¼šå¸¸è§„ç§‘ç›®ï¼ˆ3åˆ—ï¼‰/ç‰¹æ®Šç§‘ç›®ï¼ˆ1åˆ—ï¼‰"""
    return 'special' if any(kw in trade_name for kw in SPECIAL_TRADE_KEYWORDS) else 'normal'

def extract_trade_info(line_cols):
    """æ ¹æ®ç§‘ç›®ç±»å‹æå–æ•°æ®ï¼šå¸¸è§„ç§‘ç›®ï¼ˆç”µé‡+ç”µä»·+ç”µè´¹ï¼‰/ç‰¹æ®Šç§‘ç›®ï¼ˆä»…ç”µè´¹ï¼‰"""
    trade_code = line_cols[0].strip()
    trade_name = line_cols[1].strip()
    trade_type = classify_trade_type(trade_name)
    
    if trade_type == 'normal':
        # å¸¸è§„ç§‘ç›®ï¼šç¬¬3åˆ—ç”µé‡ï¼Œç¬¬4åˆ—ç”µä»·ï¼Œç¬¬5åˆ—ç”µè´¹ï¼ˆå…è®¸éƒ¨åˆ†ä¸ºç©ºï¼‰
        quantity = safe_convert_to_numeric(line_cols[2] if len(line_cols)>=3 else None)
        price = safe_convert_to_numeric(line_cols[3] if len(line_cols)>=4 else None)
        fee = safe_convert_to_numeric(line_cols[4] if len(line_cols)>=5 else None)
        return trade_code, trade_name, trade_type, {'ç”µé‡': quantity, 'ç”µä»·': price, 'ç”µè´¹': fee}
    else:
        # ç‰¹æ®Šç§‘ç›®ï¼šç¬¬2åˆ—æˆ–ç¬¬3åˆ—ç”µè´¹ï¼ˆé€‚é…3åˆ—ç»“æ„ï¼‰
        fee_col_idx = 2 if len(line_cols)>=3 else 1
        fee = safe_convert_to_numeric(line_cols[fee_col_idx])
        return trade_code, trade_name, trade_type, {'ç”µè´¹': fee}

def extract_station_and_trades(pdf_lines):
    """
    æå–æ‰€æœ‰åœºç«™å’Œç§‘ç›®æ•°æ®
    1. æŒ‰PDFä»ä¸Šåˆ°ä¸‹é¡ºåºä¿ç•™ç§‘ç›®
    2. é€‚é…å¸¸è§„/ç‰¹æ®Šç§‘ç›®ç»“æ„
    3. ä¸¥æ ¼ä¿ç•™å•ä¸ªæ–‡ä»¶å†…çš„ç§‘ç›®é¡ºåº
    """
    # åˆå§‹åŒ–å˜é‡
    station_pattern = r'æœºç»„\s+([^:ï¼š\s]{2,15}é£ç”µåœº)'  # æ”¾å®½åœºç«™åé•¿åº¦ï¼ˆ2-15å­—ï¼‰
    current_station = None
    current_station_meter_qty = None
    in_trade_area = False  # æ˜¯å¦è¿›å…¥äº¤æ˜“æ•°æ®åŒºåŸŸ
    all_stations = []  # å­˜å‚¨æ‰€æœ‰åœºç«™æ•°æ®ï¼ˆå«ç§‘ç›®ï¼‰
    file_total_quantity = None  # æ–‡ä»¶çº§åˆè®¡ç”µé‡
    file_total_fee = None  # æ–‡ä»¶çº§åˆè®¡ç”µè´¹

    # ç¬¬ä¸€æ­¥ï¼šå…ˆæå–æ–‡ä»¶çº§åˆè®¡æ•°æ®å’Œè¿‡æ»¤æ— æ•ˆè¡Œ
    filtered_lines = filter_invalid_lines(pdf_lines)
    for line in filtered_lines:
        line_cols = [col.strip() for col in re.split(r'\s{1,}', line) if col.strip()]
        # æå–æ–‡ä»¶çº§åˆè®¡ç”µé‡å’Œç”µè´¹
        if len(line_cols) >=4 and "åˆè®¡ç”µé‡" in line_cols and "åˆè®¡ç”µè´¹" in line_cols:
            qty_idx = line_cols.index("åˆè®¡ç”µé‡") + 1 if "åˆè®¡ç”µé‡" in line_cols else -1
            fee_idx = line_cols.index("åˆè®¡ç”µè´¹") + 1 if "åˆè®¡ç”µè´¹" in line_cols else -1
            if qty_idx != -1 and qty_idx < len(line_cols):
                file_total_quantity = safe_convert_to_numeric(line_cols[qty_idx])
            if fee_idx != -1 and fee_idx < len(line_cols):
                file_total_fee = safe_convert_to_numeric(line_cols[fee_idx])

    # ç¬¬äºŒæ­¥ï¼šæå–åœºç«™å’Œç§‘ç›®æ•°æ®ï¼ˆæŒ‰é¡ºåºï¼‰
    current_station_trades = []  # å½“å‰åœºç«™çš„ç§‘ç›®åˆ—è¡¨ï¼ˆä¿ç•™é¡ºåºï¼‰
    for line in filtered_lines:
        line_cols = [col.strip() for col in re.split(r'\s{1,}', line) if col.strip()]
        line_len = len(line_cols)

        # 1. è¯†åˆ«åœºç«™åˆ‡æ¢ï¼ˆä¿å­˜ä¸Šä¸€ä¸ªåœºç«™æ•°æ®ï¼‰
        station_match = re.search(station_pattern, line)
        if station_match:
            if current_station and current_station_trades:
                # ä¿å­˜å½“å‰åœºç«™æ•°æ®
                all_stations.append({
                    'åœºç«™åç§°': current_station,
                    'è®¡é‡ç”µé‡': current_station_meter_qty,
                    'ç§‘ç›®åˆ—è¡¨': current_station_trades.copy()  # æ·±æ‹·è´ï¼Œé¿å…å¼•ç”¨é—®é¢˜
                })
            # åˆå§‹åŒ–æ–°åœºç«™
            current_station = station_match.group(1)
            current_station_meter_qty = None
            current_station_trades = []
            in_trade_area = False
            continue

        # 2. æå–å½“å‰åœºç«™çš„è®¡é‡ç”µé‡ï¼ˆé€‚é…â€œè®¡é‡ç”µé‡ï¼šXXXâ€æˆ–â€œè®¡é‡ç”µé‡ XXXâ€ï¼‰
        if current_station and "è®¡é‡ç”µé‡" in line:
            meter_match = re.search(r'è®¡é‡ç”µé‡\s*[:ï¼š]?\s*(\S+)', line)
            if meter_match:
                current_station_meter_qty = safe_convert_to_numeric(meter_match.group(1))
            continue

        # 3. è¯†åˆ«äº¤æ˜“æ•°æ®åŒºåŸŸï¼ˆåªè¦åŒ…å«è¡¨å¤´å…³é”®è¯å³è¿›å…¥ï¼‰
        if not in_trade_area and all(kw in line_cols for kw in TRADE_HEADER_KEYWORDS):
            in_trade_area = True
            continue

        # 4. æå–ç§‘ç›®æ•°æ®ï¼ˆåŒºåˆ†å¸¸è§„/ç‰¹æ®Šç§‘ç›®ï¼‰
        if in_trade_area and current_station and line_len >=2:
            # ç§‘ç›®ç¼–ç å¿…é¡»ä¸ºæ•°å­—æˆ–ç‰¹å®šæ ¼å¼ï¼ˆæ’é™¤çº¯æ–‡æœ¬è¡Œï¼‰
            if line_cols[0].isdigit() or line_cols[0].startswith(('10', '20', '30')):
                try:
                    trade_code, trade_name, trade_type, trade_data = extract_trade_info(line_cols)
                    # è¿‡æ»¤æ— æ•ˆç§‘ç›®åï¼ˆé•¿åº¦1-20å­—ï¼Œæ’é™¤çº¯æ•°å­—/ç¬¦å·ï¼‰
                    if 1 <= len(trade_name) <=20 and not trade_name.isdigit():
                        current_station_trades.append({
                            'ç¼–ç ': trade_code,
                            'åç§°': trade_name,
                            'ç±»å‹': trade_type,
                            'æ•°æ®': trade_data
                        })
                except Exception:
                    continue

    # ä¿å­˜æœ€åä¸€ä¸ªåœºç«™æ•°æ®
    if current_station and current_station_trades:
        all_stations.append({
            'åœºç«™åç§°': current_station,
            'è®¡é‡ç”µé‡': current_station_meter_qty,
            'ç§‘ç›®åˆ—è¡¨': current_station_trades.copy()
        })

    return all_stations, file_total_quantity, file_total_fee

def extract_data_from_pdf(file_obj, file_name):
    """ä»PDFæå–å®Œæ•´æ•°æ®ï¼ˆåœºç«™+ç§‘ç›®+é¡ºåºä¿ç•™ï¼‰"""
    try:
        with pdfplumber.open(file_obj) as pdf:
            if not pdf.pages:
                raise ValueError("PDFæ— æœ‰æ•ˆé¡µé¢")
            
            # è¯»å–æ‰€æœ‰é¡µé¢æ–‡æœ¬ï¼ˆä¿ç•™åŸå§‹é¡ºåºï¼‰
            all_text = ""
            for page in pdf.pages:
                page_text = page.extract_text()  # ä¸ç”¨simpleï¼Œé¿å…ä¸¢å¤±ç»“æ„
                if page_text:
                    all_text += page_text + "\n"
            pdf_lines = [line.strip() for line in all_text.split('\n') if line.strip()]
            if not pdf_lines:
                raise ValueError("PDFä¸ºæ‰«æä»¶ï¼Œæ— å¯ç”¨æ–‡æœ¬")

        # æå–åŸºç¡€ä¿¡æ¯
        company_name = extract_company_name(pdf_lines)
        clear_date = extract_clear_date(pdf_lines)
        # æå–åœºç«™å’Œç§‘ç›®æ•°æ®
        all_stations, file_total_quantity, file_total_fee = extract_station_and_trades(pdf_lines)

        # æ•´ç†è¾“å‡ºæ ¼å¼
        output_data = []
        global_trade_order = []  # å•ä¸ªæ–‡ä»¶å†…çš„ç§‘ç›®é¡ºåºï¼ˆå…¨å±€å¤ç”¨ï¼‰
        # å…ˆæ”¶é›†å•ä¸ªæ–‡ä»¶å†…çš„ç§‘ç›®é¡ºåºï¼ˆæŒ‰æå–é¡ºåºï¼‰
        for station in all_stations:
            for trade in station['ç§‘ç›®åˆ—è¡¨']:
                if trade['åç§°'] not in global_trade_order:
                    global_trade_order.append(trade['åç§°'])
        
        # æ„å»ºæ¯ä¸ªåœºç«™çš„æ•°æ®è¡Œ
        for station in all_stations:
            station_row = {
                'å…¬å¸åç§°': company_name,
                'åœºç«™åç§°': station['åœºç«™åç§°'],
                'æ¸…åˆ†æ—¥æœŸ': clear_date,
                'æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)': file_total_quantity,
                'æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)': file_total_fee,
                'åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)': station['è®¡é‡ç”µé‡']
            }
            # æŒ‰é¡ºåºæ·»åŠ ç§‘ç›®æ•°æ®
            for trade_name in global_trade_order:
                # æ‰¾åˆ°å½“å‰ç§‘ç›®çš„æ•°æ®
                trade_data = next((t['æ•°æ®'] for t in station['ç§‘ç›®åˆ—è¡¨'] if t['åç§°'] == trade_name), None)
                if trade_data:
                    trade_type = next((t['ç±»å‹'] for t in station['ç§‘ç›®åˆ—è¡¨'] if t['åç§°'] == trade_name), 'normal')
                    if trade_type == 'normal':
                        # å¸¸è§„ç§‘ç›®ï¼šæ·»åŠ ç”µé‡ã€ç”µä»·ã€ç”µè´¹
                        station_row[f'{trade_name}_ç”µé‡'] = trade_data.get('ç”µé‡')
                        station_row[f'{trade_name}_ç”µä»·'] = trade_data.get('ç”µä»·')
                        station_row[f'{trade_name}_ç”µè´¹'] = trade_data.get('ç”µè´¹')
                    else:
                        # ç‰¹æ®Šç§‘ç›®ï¼šä»…æ·»åŠ ç”µè´¹
                        station_row[f'{trade_name}_ç”µè´¹'] = trade_data.get('ç”µè´¹')
            output_data.append(station_row)
        
        return output_data, global_trade_order

    except Exception as e:
        st.warning(f"å¤„ç†PDF {file_name} å‡ºé”™: {str(e)}")
        return [], []

# ---------------------- Excelå¤„ç†ï¼ˆä¿æŒå…¼å®¹ï¼‰ ----------------------
def extract_data_from_excel(file_obj, file_name):
    """Excelæ–‡ä»¶å¤„ç†ï¼ˆé€‚é…åŠ¨æ€ç§‘ç›®ï¼‰"""
    try:
        df = pd.read_excel(file_obj, dtype=object)
        company_name = "æœªçŸ¥å…¬å¸"
        # ä»æ–‡ä»¶åæå–å…¬å¸å
        name_without_ext = file_name.split('.')[0]
        if "æ™¶ç››" in name_without_ext:
            company_name = "å¤§åº†æ™¶ç››å…‰ä¼ç”µç«™"
        
        # æå–æ—¥æœŸ
        date_match = re.search(r'\d{4}-\d{2}-\d{2}', name_without_ext)
        clear_date = date_match.group() if date_match else None

        # æå–åˆè®¡æ•°æ®
        total_quantity = safe_convert_to_numeric(df.iloc[0, 3] if len(df) > 0 else None)
        total_fee = safe_convert_to_numeric(df.iloc[0, 5] if len(df) > 0 else None)

        # å¸¸è§„Excelç§‘ç›®ï¼ˆæŒ‰é¡ºåºï¼‰
        excel_trades = [
            'ä¼˜å…ˆå‘ç”µäº¤æ˜“', 'ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“', 'çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“'
        ]
        # æ„å»ºæ•°æ®è¡Œ
        station_row = {
            'å…¬å¸åç§°': company_name,
            'åœºç«™åç§°': company_name.replace('æœ‰é™å…¬å¸', 'åœºç«™'),
            'æ¸…åˆ†æ—¥æœŸ': clear_date,
            'æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)': total_quantity,
            'æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)': total_fee,
            'åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)': total_quantity
        }
        # æ·»åŠ ç§‘ç›®æ•°æ®
        for trade in excel_trades:
            station_row[f'{trade}_ç”µé‡'] = None
            station_row[f'{trade}_ç”µä»·'] = None
            station_row[f'{trade}_ç”µè´¹'] = None
        
        return [station_row], excel_trades

    except Exception as e:
        st.warning(f"å¤„ç†Excel {file_name} å‡ºé”™: {str(e)}")
        return [], []

# ---------------------- æ•°æ®æ±‡æ€»ä¸å¯¼å‡ºï¼ˆåŠ¨æ€åˆ—é€‚é…ï¼‰ ----------------------
def build_result_columns(global_trade_order):
    """æ ¹æ®ç§‘ç›®é¡ºåºå’Œç±»å‹ï¼ŒåŠ¨æ€æ„å»ºç»“æœåˆ—ï¼ˆç‰¹æ®Šç§‘ç›®ä»…ç”µè´¹åˆ—ï¼‰"""
    base_cols = [
        'å…¬å¸åç§°', 'åœºç«™åç§°', 'æ¸…åˆ†æ—¥æœŸ',
        'æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)', 'æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)', 'åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)'
    ]
    trade_cols = []
    for trade_name in global_trade_order:
        trade_type = 'special' if any(kw in trade_name for kw in SPECIAL_TRADE_KEYWORDS) else 'normal'
        if trade_type == 'normal':
            trade_cols.extend([f'{trade_name}_ç”µé‡', f'{trade_name}_ç”µä»·', f'{trade_name}_ç”µè´¹'])
        else:
            trade_cols.append(f'{trade_name}_ç”µè´¹')
    return base_cols + trade_cols

def calculate_summary_row(result_df, global_trade_order):
    """è®¡ç®—æ±‡æ€»è¡Œï¼ˆé€‚é…å¸¸è§„/ç‰¹æ®Šç§‘ç›®ï¼‰"""
    summary_row = {
        'å…¬å¸åç§°': 'æ€»è®¡',
        'åœºç«™åç§°': 'æ€»è®¡',
        'æ¸…åˆ†æ—¥æœŸ': '',
        'æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)': result_df['æ–‡ä»¶åˆè®¡ç”µé‡(å…†ç“¦æ—¶)'].dropna().sum(),
        'æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)': result_df['æ–‡ä»¶åˆè®¡ç”µè´¹(å…ƒ)'].dropna().sum(),
        'åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)': result_df['åœºç«™è®¡é‡ç”µé‡(å…†ç“¦æ—¶)'].dropna().sum()
    }
    # æŒ‰é¡ºåºæ±‡æ€»ç§‘ç›®æ•°æ®
    for trade_name in global_trade_order:
        trade_type = 'special' if any(kw in trade_name for kw in SPECIAL_TRADE_KEYWORDS) else 'normal'
        if trade_type == 'normal':
            # å¸¸è§„ç§‘ç›®ï¼šç”µé‡/ç”µè´¹æ±‚å’Œï¼Œç”µä»·æ±‚å¹³å‡
            summary_row[f'{trade_name}_ç”µé‡'] = result_df[f'{trade_name}_ç”µé‡'].dropna().sum()
            summary_row[f'{trade_name}_ç”µè´¹'] = result_df[f'{trade_name}_ç”µè´¹'].dropna().sum()
            price_vals = result_df[f'{trade_name}_ç”µä»·'].dropna()
            price_vals = price_vals[price_vals > 0.01]
            summary_row[f'{trade_name}_ç”µä»·'] = round(price_vals.mean(), 3) if not price_vals.empty else None
        else:
            # ç‰¹æ®Šç§‘ç›®ï¼šä»…ç”µè´¹æ±‚å’Œ
            summary_row[f'{trade_name}_ç”µè´¹'] = result_df[f'{trade_name}_ç”µè´¹'].dropna().sum()
    return pd.DataFrame([summary_row])

def to_excel_bytes(df, report_df):
    """Excelå¯¼å‡ºï¼ˆä¿ç•™åˆ—é¡ºåºï¼‰"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='ç»“ç®—æ•°æ®æ˜ç»†', index=False)
        report_df.to_excel(writer, sheet_name='å¤„ç†æŠ¥å‘Š', index=False)
    output.seek(0)
    return output

# ---------------------- Streamlit é¡µé¢å¸ƒå±€ ----------------------
def main():
    st.set_page_config(page_title="é»‘é¾™æ±Ÿæ—¥æ¸…åˆ†æ•°æ®æå–ï¼ˆå…¨ç§‘ç›®ç‰ˆï¼‰", layout="wide")
    
    # é¡µé¢æ ‡é¢˜ä¸è¯´æ˜
    st.title("ğŸ“Š é»‘é¾™æ±Ÿæ—¥æ¸…åˆ†ç»“ç®—å•æ•°æ®æå–å·¥å…·ï¼ˆå…¨ç§‘ç›®+ç‰¹æ®Šåœºæ™¯é€‚é…ï¼‰")
    st.divider()
    st.subheader("ğŸ” åŠŸèƒ½è¯´æ˜")
    st.markdown("""
    - **å…¨ç§‘ç›®è¦†ç›–**ï¼šè‡ªåŠ¨æå–â€œé€æ±Ÿè‹/æµ™æ±Ÿç»¿ç”µäº¤æ˜“â€â€œé˜»å¡è´¹ç”¨â€â€œä»·å·®è´¹ç”¨â€ç­‰æ‰€æœ‰ç§‘ç›®
    - **ç‰¹æ®Šç§‘ç›®é€‚é…**ï¼šâ€œé˜»å¡è´¹ç”¨â€â€œä»·å·®è´¹ç”¨â€ä»…ç”Ÿæˆç”µè´¹åˆ—ï¼Œæ— å¤šä½™ç”µé‡/ç”µä»·åˆ—
    - **é¡ºåºä¸¥æ ¼ä¿ç•™**ï¼šæŒ‰PDFä»ä¸Šåˆ°ä¸‹çš„åŸå§‹é¡ºåºæå–ç§‘ç›®ï¼Œä¸æ‰“ä¹±
    - **æ— æ•ˆåˆ—è¿‡æ»¤**ï¼šå½»åº•æ’é™¤â€œhfâ€â€œå¿â€ç­‰æ— å…³å­—ç¬¦ï¼Œæ— å¤šä½™åˆ—
    """)

    # 1. æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.subheader("ğŸ“ ä¸Šä¼ æ–‡ä»¶")
    uploaded_files = st.file_uploader(
        "æ”¯æŒPDF/Excelæ‰¹é‡ä¸Šä¼ ï¼ˆPDFä¼˜å…ˆï¼Œè‡ªåŠ¨é€‚é…æ‰€æœ‰ç§‘ç›®ï¼‰",
        type=['pdf', 'xlsx'],
        accept_multiple_files=True
    )

    # 2. æ•°æ®å¤„ç†é€»è¾‘
    if uploaded_files and st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary"):
        st.divider()
        st.subheader("âš™ï¸ å¤„ç†è¿›åº¦")
        
        all_output_data = []
        global_trade_order = []  # å…¨å±€ç§‘ç›®é¡ºåºï¼ˆæŒ‰æ–‡ä»¶å¤„ç†é¡ºåºè¿½åŠ ï¼Œä¿ç•™å•ä¸ªæ–‡ä»¶å†…é¡ºåºï¼‰
        total_files = len(uploaded_files)
        processed_files = 0

        # æ‰¹é‡å¤„ç†æ–‡ä»¶ï¼ˆæŒ‰ä¸Šä¼ é¡ºåºï¼‰
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, file in enumerate(uploaded_files):
            file_name = file.name
            status_text.text(f"æ­£åœ¨å¤„ç†ï¼š{file_name}ï¼ˆ{idx+1}/{total_files}ï¼‰")
            
            # æŒ‰æ–‡ä»¶ç±»å‹æå–
            if file_name.lower().endswith('.pdf'):
                file_output, file_trade_order = extract_data_from_pdf(file, file_name)
            else:
                file_output, file_trade_order = extract_data_from_excel(file, file_name)
            
            # ç´¯ç§¯æ•°æ®ï¼ˆå…³é”®ï¼šä¿ç•™å•ä¸ªæ–‡ä»¶å†…çš„ç§‘ç›®é¡ºåºï¼Œå…¨å±€æŒ‰æ–‡ä»¶é¡ºåºè¿½åŠ ï¼‰
            if file_output:
                all_output_data.extend(file_output)
                # è¿½åŠ ç§‘ç›®é¡ºåºï¼ˆä¸é‡å¤ï¼‰
                for trade in file_trade_order:
                    if trade not in global_trade_order:
                        global_trade_order.append(trade)
                processed_files += 1
            
            # æ›´æ–°è¿›åº¦
            progress_bar.progress((idx + 1) / total_files)

        progress_bar.empty()
        status_text.text("å¤„ç†å®Œæˆï¼")

        # 3. ç»“æœå±•ç¤ºä¸å¯¼å‡º
        if all_output_data and global_trade_order:
            st.divider()
            st.subheader("ğŸ“ˆ æå–ç»“æœï¼ˆæŒ‰PDFåŸå§‹é¡ºåºï¼‰")
            
            # åŠ¨æ€æ„å»ºç»“æœåˆ—ï¼ˆé€‚é…å¸¸è§„/ç‰¹æ®Šç§‘ç›®ï¼‰
            result_columns = build_result_columns(global_trade_order)
            # æ„å»ºDataFrame
            result_df = pd.DataFrame(all_output_data)
            # è¡¥å……ç¼ºå¤±åˆ—ï¼ˆä¸åŒæ–‡ä»¶ç§‘ç›®å·®å¼‚ï¼‰
            for col in result_columns:
                if col not in result_df.columns:
                    result_df[col] = None
            # ä¸¥æ ¼æŒ‰é¡ºåºæ’åˆ—åˆ—
            result_df = result_df[result_columns]
            # æ•°å€¼åˆ—æ ¼å¼åŒ–
            numeric_cols = [col for col in result_columns if any(key in col for key in ['ç”µé‡', 'ç”µä»·', 'ç”µè´¹'])]
            result_df[numeric_cols] = result_df[numeric_cols].apply(pd.to_numeric, errors='coerce')

            # æ’åºï¼ˆå…¬å¸â†’åœºç«™â†’æ—¥æœŸï¼‰
            result_df['æ¸…åˆ†æ—¥æœŸ'] = pd.to_datetime(result_df['æ¸…åˆ†æ—¥æœŸ'], errors='coerce')
            result_df = result_df.sort_values(['å…¬å¸åç§°', 'åœºç«™åç§°', 'æ¸…åˆ†æ—¥æœŸ']).reset_index(drop=True)
            result_df['æ¸…åˆ†æ—¥æœŸ'] = result_df['æ¸…åˆ†æ—¥æœŸ'].dt.strftime('%Y-%m-%d').fillna('')

            # æ·»åŠ æ±‡æ€»è¡Œ
            summary_row = calculate_summary_row(result_df, global_trade_order)
            result_df = pd.concat([result_df, summary_row], ignore_index=True)

            # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
            failed_files = total_files - processed_files
            success_rate = f"{processed_files / total_files:.2%}" if total_files > 0 else "0%"
            stations = result_df['åœºç«™åç§°'].unique()
            station_count = len(stations) - 1 if 'æ€»è®¡' in stations else len(stations)
            valid_rows = len(result_df) - 1
            trade_count = len(global_trade_order)

            report_df = pd.DataFrame({
                'ç»Ÿè®¡é¡¹': ['æ–‡ä»¶æ€»æ•°', 'æˆåŠŸå¤„ç†æ•°', 'å¤±è´¥æ•°', 'å¤„ç†æˆåŠŸç‡', 'æ¶‰åŠåœºç«™æ•°', 'æœ‰æ•ˆæ•°æ®è¡Œæ•°', 'æå–ç§‘ç›®æ•°'],
                'æ•°å€¼': [total_files, processed_files, failed_files,
                         success_rate, station_count, valid_rows, trade_count]
            })

            # å±•ç¤ºç»“æœï¼ˆåˆ†æ ‡ç­¾é¡µï¼‰
            tab1, tab2 = st.tabs(["ç»“ç®—æ•°æ®æ˜ç»†", "å¤„ç†æŠ¥å‘Š"])
            with tab1:
                st.dataframe(result_df, use_container_width=True, height=600)
                # æ˜¾ç¤ºç§‘ç›®é¡ºåºè¯´æ˜
                st.caption(f"ç§‘ç›®æå–é¡ºåºï¼ˆæŒ‰PDFåŸå§‹é¡ºåºï¼‰ï¼š{', '.join(global_trade_order)}")
            with tab2:
                st.dataframe(report_df, use_container_width=True)

            # å¯¼å‡ºExcel
            current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
            download_filename = f"é»‘é¾™æ±Ÿç»“ç®—æ•°æ®æå–_å…¨ç§‘ç›®ç‰ˆ_{current_time}.xlsx"
            excel_bytes = to_excel_bytes(result_df, report_df)

            st.divider()
            st.download_button(
                label="ğŸ“¥ å¯¼å‡ºå…¨ç§‘ç›®ç‰ˆExcel",
                data=excel_bytes,
                file_name=download_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary"
            )

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            st.success(
                f"""âœ… å¤„ç†å®Œæˆï¼
                - å…±å¤„ç† {total_files} ä¸ªæ–‡ä»¶ï¼ŒæˆåŠŸ {processed_files} ä¸ªï¼ˆæˆåŠŸç‡ {success_rate}ï¼‰
                - æå– {trade_count} ä¸ªç§‘ç›®ï¼ˆå«ç‰¹æ®Šç§‘ç›®ï¼‰ï¼Œæ¶‰åŠ {station_count} ä¸ªåœºç«™ï¼Œ{valid_rows} è¡Œæœ‰æ•ˆæ•°æ®
                - ç‰¹æ®Šç§‘ç›®â€œé˜»å¡è´¹ç”¨â€â€œä»·å·®è´¹ç”¨â€ä»…ä¿ç•™ç”µè´¹åˆ—ï¼Œæ— å¤šä½™åˆ—
                """
            )
        else:
            st.warning("âš ï¸ æœªæå–åˆ°æœ‰æ•ˆæ•°æ®ï¼è¯·æ£€æŸ¥PDFæ˜¯å¦ä¸ºå¯å¤åˆ¶æ–‡æœ¬ï¼Œä¸”åŒ…å«â€œæœºç»„ æŸæŸé£ç”µåœºâ€æ ‡è¯†ã€‚")

    # æ— æ–‡ä»¶ä¸Šä¼ æ—¶çš„æç¤º
    elif not uploaded_files and st.button("ğŸš€ å¼€å§‹å¤„ç†", disabled=True):
        st.warning("è¯·å…ˆä¸Šä¼ PDF/Excelæ–‡ä»¶ï¼")

if __name__ == "__main__":
    main()
