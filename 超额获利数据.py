import streamlit as st
import pandas as pd
import re
from io import BytesIO
import datetime
import plotly.express as px

# -------------------------- é¡µé¢é…ç½® --------------------------
st.set_page_config(
    page_title="å…‰ä¼/é£ç”µæ•°æ®ç®¡ç†å·¥å…·ï¼ˆå®å‘+æŒä»“ï¼‰",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# -------------------------- åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ï¼ˆæ ¸å¿ƒä¿®æ­£ï¼šæ›¿ä»£å…¨å±€å˜é‡ï¼‰ --------------------------
if "generated_data" not in st.session_state:
    st.session_state.generated_data = {}  # å®å‘æ•°æ®ï¼š{åœºç«™å: æœˆåº¦å®å‘æ€»é‡MWh}
if "hold_data" not in st.session_state:
    st.session_state.hold_data = {}        # æŒä»“æ•°æ®ï¼š{åœºç«™å: æœˆåº¦å‡€æŒæœ‰ç”µé‡MWh}
if "extracted_stations" not in st.session_state:
    st.session_state.extracted_stations = []  # å·²æå–çš„åœºç«™åˆ—è¡¨
if "merged_gen_df" not in st.session_state:
    st.session_state.merged_gen_df = pd.DataFrame()  # å®å‘åˆå¹¶æ•°æ®

# -------------------------- ä¾§è¾¹æ åˆ†ç±»é…ç½® --------------------------
st.sidebar.title("âš™ï¸ åŠŸèƒ½é…ç½®")

# 1. åœºç«™å®å‘é…ç½®
with st.sidebar.expander("ğŸ“Š åœºç«™å®å‘é…ç½®", expanded=True):
    st.sidebar.subheader("1. æ•°æ®ä¸Šä¼ ")
    uploaded_generated_files = st.sidebar.file_uploader(
        "ä¸Šä¼ åœºç«™å®å‘Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
        type=["xlsx", "xls", "xlsm"],
        accept_multiple_files=True,
        key="generated_upload"
    )

    st.sidebar.subheader("2. åˆ—ç´¢å¼•é…ç½®")
    time_col_idx = st.sidebar.number_input("æ—¶é—´åˆ—ç´¢å¼•ï¼ˆEåˆ—=4ï¼‰", value=4, min_value=0, key="time_idx")
    power_col_idx_wind = st.sidebar.number_input("é£ç”µåœºåŠŸç‡åˆ—ç´¢å¼•ï¼ˆJåˆ—=9ï¼‰", value=9, min_value=0, key="wind_power_idx")
    power_col_idx_pv = st.sidebar.number_input("å…‰ä¼åœºåŠŸç‡åˆ—ç´¢å¼•ï¼ˆFåˆ—=5ï¼‰", value=5, min_value=0, key="pv_power_idx")

    st.sidebar.subheader("3. åŸºç¡€å‚æ•°")
    pv_stations = st.sidebar.text_input("å…‰ä¼åœºç«™åå•ï¼ˆé€—å·åˆ†éš”ï¼‰", value="æµ æ°´æ¸”å…‰,è¥„åŒ—å†œå…‰", key="pv_list")
    power_conversion = st.sidebar.number_input("åŠŸç‡è½¬æ¢ç³»æ•°ï¼ˆkWâ†’MWï¼‰", value=1000, key="power_conv")
    skip_rows = st.sidebar.number_input("è·³è¿‡è¡¨å¤´è¡Œæ•°", value=1, min_value=0, key="skip_rows")
    file_keyword = st.sidebar.text_input("å®å‘æ–‡ä»¶ç­›é€‰å…³é”®è¯", value="å†å²è¶‹åŠ¿", key="generated_keyword")

# 2. ä¸­é•¿æœŸæŒä»“é…ç½®
with st.sidebar.expander("ğŸ“¦ ä¸­é•¿æœŸæŒä»“é…ç½®", expanded=True):
    st.sidebar.subheader("1. æŒä»“æ•°æ®ä¸Šä¼ ")
    uploaded_hold_files = st.sidebar.file_uploader(
        "ä¸Šä¼ åœºç«™æŒä»“Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
        type=["xlsx", "xls", "xlsm"],
        accept_multiple_files=True,
        key="hold_upload"
    )

    st.sidebar.subheader("2. æŒä»“æ•°æ®å…³è”")
    # ä¸‹æ‹‰é€‰æ‹©æŒä»“æ–‡ä»¶å¯¹åº”çš„åœºç«™ï¼ˆæ”¯æŒå¤šé€‰å…³è”ï¼‰
    selected_stations = st.sidebar.multiselect(
        "é€‰æ‹©æŒä»“æ–‡ä»¶å¯¹åº”çš„åœºç«™ï¼ˆå¯å¤šé€‰ï¼‰",
        options=st.session_state.extracted_stations,
        key="hold_station_select"
    )
    # æ‰‹åŠ¨è¾“å…¥æœªæå–çš„åœºç«™
    manual_station = st.sidebar.text_input(
        "æ‰‹åŠ¨è¡¥å……åœºç«™åï¼ˆé€—å·åˆ†éš”ï¼‰",
        placeholder="ä¾‹å¦‚ï¼šæ–°åœºç«™1,æ–°åœºç«™2",
        key="hold_station_manual"
    )
    # åˆå¹¶é€‰æ‹©å’Œæ‰‹åŠ¨è¾“å…¥çš„åœºç«™
    target_stations = selected_stations + [s.strip() for s in manual_station.split(",") if s.strip()]

    st.sidebar.subheader("3. æŒä»“åˆ—é…ç½®")
    hold_col_idx = st.sidebar.number_input("å‡€æŒæœ‰ç”µé‡åˆ—ç´¢å¼•ï¼ˆDåˆ—=3ï¼‰", value=3, min_value=0, key="hold_col_idx")
    hold_skip_rows = st.sidebar.number_input("æŒä»“è¡¨æ ¼è·³è¿‡è¡¨å¤´è¡Œæ•°", value=1, min_value=0, key="hold_skip_rows")

# å¤„ç†å…‰ä¼åœºç«™åå•
pv_stations_list = [s.strip() for s in pv_stations.split(",") if s.strip()]

# -------------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° --------------------------
# 1. å®å‘æ•°æ®æ¸…æ´—
@st.cache_data(show_spinner="æ¸…æ´—å®å‘åŠŸç‡æ•°æ®ä¸­...", hash_funcs={BytesIO: lambda x: x.getvalue()})
def clean_power_data(value):
    if pd.isna(value):
        return None
    value_str = str(value).strip()
    if not re.search(r'\d', value_str):
        return None
    num_match = re.search(r'(\d+\.?\d*)', value_str)
    if num_match:
        try:
            return float(num_match.group(1))
        except:
            return None
    return None

# 2. æå–åœºç«™å
def extract_station_name(file_name):
    name_without_ext = file_name.split(".")[0]
    station_name = name_without_ext.split("-")[0].strip()
    return station_name

# 3. æå–å®å‘æ•°æ®ï¼ˆä¼˜åŒ–ç¼“å­˜keyï¼‰
@st.cache_data(show_spinner="æå–å®å‘Excelæ•°æ®ä¸­...", hash_funcs={BytesIO: lambda x: x.getvalue()})
def extract_generated_data(uploaded_file, time_idx, power_idx, skip_r, conv):
    try:
        file_name = uploaded_file.name
        suffix = file_name.split(".")[-1].lower()
        engine = "openpyxl" if suffix in ["xlsx", "xlsm"] else "xlrd"
        
        df = pd.read_excel(
            BytesIO(uploaded_file.getvalue()),
            header=None,
            usecols=[time_idx, power_idx],
            skiprows=skip_r,
            engine=engine,
            nrows=None
        )
        
        df.columns = ["æ—¶é—´_åŸå§‹", "åŠŸç‡_åŸå§‹"]
        df["åŠŸç‡(kW)"] = df["åŠŸç‡_åŸå§‹"].apply(clean_power_data)
        df["æ—¶é—´"] = pd.to_datetime(df["æ—¶é—´_åŸå§‹"], errors="coerce")
        
        # è°ƒè¯•ä¿¡æ¯
        time_fail = df[df["æ—¶é—´"].isna()]
        power_fail = df[df["åŠŸç‡(kW)"].isna() & df["æ—¶é—´"].notna()]
        if not time_fail.empty:
            st.warning(f"âš ï¸ å®å‘æ–‡ä»¶[{file_name}]ï¼šæ—¶é—´è§£æå¤±è´¥{len(time_fail)}æ¡ï¼ˆå‰5æ¡ï¼‰")
            st.dataframe(time_fail[["æ—¶é—´_åŸå§‹", "åŠŸç‡_åŸå§‹"]].head(5), use_container_width=True)
        if not power_fail.empty:
            st.warning(f"âš ï¸ å®å‘æ–‡ä»¶[{file_name}]ï¼šåŠŸç‡æ¸…æ´—å¤±è´¥{len(power_fail)}æ¡ï¼ˆå‰5æ¡ï¼‰")
            st.dataframe(power_fail[["æ—¶é—´", "åŠŸç‡_åŸå§‹"]].head(5), use_container_width=True)
        
        df = df.dropna(subset=["æ—¶é—´", "åŠŸç‡(kW)"])
        if df.empty:
            st.warning(f"âš ï¸ å®å‘æ–‡ä»¶[{file_name}]æ— æœ‰æ•ˆæ•°æ®")
            return pd.DataFrame(), file_name, ""
        
        df = df.sort_values("æ—¶é—´").reset_index(drop=True)
        station_name = extract_station_name(file_name)
        df[station_name] = df["åŠŸç‡(kW)"] / conv
        df_result = df[["æ—¶é—´", station_name]].reset_index(drop=True)
        return df_result, file_name, station_name
    except Exception as e:
        st.error(f"å¤„ç†å®å‘æ–‡ä»¶[{file_name}]å¤±è´¥ï¼š{str(e)}")
        return pd.DataFrame(), file_name, ""

# 4. æå–æŒä»“æ•°æ®ï¼ˆæ”¯æŒæ‰¹é‡å…³è”ï¼‰
@st.cache_data(show_spinner="æå–æŒä»“Excelæ•°æ®ä¸­...", hash_funcs={BytesIO: lambda x: x.getvalue()})
def extract_hold_data(uploaded_file, hold_col_idx, skip_r):
    """æå–æŒä»“è¡¨æ ¼çš„Dåˆ—ï¼ˆå‡€æŒæœ‰ç”µé‡ï¼‰ï¼Œè¿”å›è¯¥æ–‡ä»¶çš„æ€»å‡€æŒæœ‰ç”µé‡"""
    try:
        file_name = uploaded_file.name
        suffix = file_name.split(".")[-1].lower()
        engine = "openpyxl" if suffix in ["xlsx", "xlsm"] else "xlrd"
        
        df = pd.read_excel(
            BytesIO(uploaded_file.getvalue()),
            header=None,
            usecols=[hold_col_idx],
            skiprows=skip_r,
            engine=engine,
            nrows=None
        )
        
        df.columns = ["å‡€æŒæœ‰ç”µé‡"]
        df["å‡€æŒæœ‰ç”µé‡"] = pd.to_numeric(df["å‡€æŒæœ‰ç”µé‡"], errors="coerce").fillna(0)
        total_hold = round(df["å‡€æŒæœ‰ç”µé‡"].sum(), 2)
        
        st.success(f"âœ… æŒä»“æ–‡ä»¶[{file_name}]å¤„ç†å®Œæˆï¼šå½“æœˆæ€»å‡€æŒæœ‰ç”µé‡={total_hold} MWh")
        return total_hold
    except Exception as e:
        st.error(f"å¤„ç†æŒä»“æ–‡ä»¶[{file_name}]å¤±è´¥ï¼š{str(e)}")
        return 0.0

# 5. 24æ—¶æ®µå®å‘æ±‡æ€»ï¼ˆé‡æ„æœˆåº¦æ€»è®¡è¡Œï¼‰
@st.cache_data(show_spinner="è®¡ç®—24æ—¶æ®µå®å‘æ±‡æ€»ä¸­...")
def calculate_24h_generated(merged_df):
    df = merged_df.copy()
    # å®¹é”™ï¼šç©ºæ•°æ®ç›´æ¥è¿”å›ç©ºè¡¨
    if df.empty:
        st.warning("âš ï¸ å®å‘æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—24æ—¶æ®µæ±‡æ€»")
        return pd.DataFrame(), 0, []
    
    # è®¡ç®—æ—¶é—´é—´éš”
    time_diff = df["æ—¶é—´"].diff().dropna()
    avg_interval_min = time_diff.dt.total_seconds().mean() / 60 if not time_diff.empty else 15
    interval_h = avg_interval_min / 60
    st.info(f"â±ï¸ å®å‘æ•°æ®é‡‡é›†é—´éš”ï¼š{avg_interval_min:.0f}åˆ†é’Ÿï¼ˆæ¢ç®—ç³»æ•°ï¼š{interval_h}å°æ—¶/æ¡ï¼‰")
    
    # æå–å°æ—¶æ—¶æ®µ
    df["å°æ—¶æ—¶æ®µ"] = df["æ—¶é—´"].dt.hour
    stations = [col for col in df.columns if col not in ["æ—¶é—´", "å°æ—¶æ—¶æ®µ"]]
    
    # æŒ‰å°æ—¶æ±‡æ€»
    generated_rows = []
    for hour in range(24):
        hour_df = df[df["å°æ—¶æ—¶æ®µ"] == hour].copy()
        row = {"å°æ—¶æ—¶æ®µ": f"{hour:02d}:00"}
        for station in stations:
            total_gen = (hour_df[station] * interval_h).sum()
            row[station] = round(total_gen, 2)
        generated_rows.append(row)
    
    # ç”Ÿæˆæ±‡æ€»è¡¨
    generated_df = pd.DataFrame(generated_rows).fillna(0)
    
    # è®¡ç®—æœˆåº¦å®å‘æ€»é‡å¹¶æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state.generated_data = {}
    total_row = {"å°æ—¶æ—¶æ®µ": "æœˆåº¦å®å‘æ€»é‡"}
    for station in stations:
        total_month_gen = round(generated_df[station].sum(), 2)
        st.session_state.generated_data[station] = total_month_gen
        total_row[station] = total_month_gen
    
    # è¿½åŠ æœˆåº¦æ€»è®¡è¡Œï¼ˆé‡æ„ï¼šé¿å…ç´¢å¼•æ··ä¹±ï¼‰
    generated_df = pd.concat([generated_df, pd.DataFrame([total_row])], ignore_index=True)
    
    return generated_df, interval_h, stations

# -------------------------- æ‰¹é‡å¤„ç†å®å‘æ•°æ® --------------------------
def batch_process_generated(uploaded_files_list):
    # ç­›é€‰æ–‡ä»¶
    target_files = [f for f in uploaded_files_list if file_keyword in f.name or file_keyword.lower() in f.name.lower()]
    if not target_files:
        st.error(f"âŒ æœªæ‰¾åˆ°åŒ…å«ã€Œ{file_keyword}ã€çš„å®å‘æ–‡ä»¶")
        return pd.DataFrame(), []
    
    # æ˜¾ç¤ºå¾…å¤„ç†æ–‡ä»¶
    st.info(f"âœ… æ‰¾åˆ° {len(target_files)} ä¸ªå¾…å¤„ç†å®å‘æ–‡ä»¶ï¼š")
    file_list = []
    extracted_stations = []
    for i, f in enumerate(target_files, 1):
        station = extract_station_name(f.name)
        extracted_stations.append(station)
        station_type = "ğŸ“¸ å…‰ä¼" if station in pv_stations_list else "ğŸ’¨ é£ç”µ"
        file_list.append(f"{i}. {station_type} {station}ï¼ˆæ–‡ä»¶ï¼š{f.name}ï¼‰")
    st.code("\n".join(file_list))
    
    # æ‰¹é‡æå–
    all_station_dfs = {}
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, file in enumerate(target_files):
        status_text.text(f"æ­£åœ¨å¤„ç†å®å‘æ–‡ä»¶ï¼š{file.name}ï¼ˆ{idx+1}/{len(target_files)}ï¼‰")
        station_name = extract_station_name(file.name)
        power_idx = power_col_idx_pv if station_name in pv_stations_list else power_col_idx_wind
        file_data, file_name, station = extract_generated_data(file, time_col_idx, power_idx, skip_rows, power_conversion)
        
        if not file_data.empty and station:
            all_station_dfs[station] = file_data
            st.success(f"âœ… åœºç«™[{station}]ï¼šæå–åˆ° {len(file_data)} æ¡å®å‘æ•°æ®")
        progress_bar.progress((idx + 1) / len(target_files))
    
    # åˆå¹¶æ•°æ®ï¼ˆå®¹é”™ï¼šç©ºæ•°æ®å¤„ç†ï¼‰
    if not all_station_dfs:
        st.error("âŒ æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆå®å‘æ•°æ®")
        return pd.DataFrame(), []
    
    df_list = list(all_station_dfs.values())
    merged_df = df_list[0]
    for df in df_list[1:]:
        merged_df = pd.merge(merged_df, df, on="æ—¶é—´", how="outer")
    
    merged_df["æ—¶é—´"] = merged_df["æ—¶é—´"].dt.floor("min")
    merged_df = merged_df.sort_values("æ—¶é—´").reset_index(drop=True)
    
    # æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state.extracted_stations = extracted_stations
    st.session_state.merged_gen_df = merged_df
    
    progress_bar.empty()
    status_text.empty()
    return merged_df, extracted_stations

# -------------------------- æ•°æ®å…³è”å±•ç¤º --------------------------
def show_related_data():
    st.markdown("---")
    st.subheader("ğŸ”— åœºç«™å®å‘ä¸ä¸­é•¿æœŸæŒä»“å…³è”ç»“æœ")
    
    # å®¹é”™æç¤º
    if not st.session_state.generated_data and not st.session_state.hold_data:
        st.warning("âš ï¸ æš‚æ— å®å‘æˆ–æŒä»“æ•°æ®ï¼Œè¯·å…ˆå¤„ç†å¯¹åº”æ–‡ä»¶")
        return
    
    # ç”Ÿæˆå…³è”è¡¨
    related_data = []
    # åˆå¹¶æ‰€æœ‰æ¶‰åŠçš„åœºç«™
    all_stations = list(set(list(st.session_state.generated_data.keys()) + list(st.session_state.hold_data.keys())))
    
    for station in all_stations:
        gen_total = st.session_state.generated_data.get(station, 0.0)
        hold_total = st.session_state.hold_data.get(station, 0.0)
        # å®¹é”™ï¼šé™¤ä»¥0å¤„ç†
        coverage = round((hold_total / gen_total * 100) if gen_total > 0 else 0, 2)
        
        related_data.append({
            "åœºç«™å": station,
            "å½“æœˆå®å‘æ€»é‡ï¼ˆMWhï¼‰": gen_total,
            "å½“æœˆä¸­é•¿æœŸæŒä»“ï¼ˆMWhï¼‰": hold_total,
            "æŒä»“è¦†ç›–åº¦": f"{coverage}%",
            "å®å‘-æŒä»“å·®å€¼ï¼ˆMWhï¼‰": round(gen_total - hold_total, 2)
        })
    
    related_df = pd.DataFrame(related_data)
    st.dataframe(related_df, use_container_width=True)
    
    # å¯è§†åŒ–ï¼ˆå®¹é”™ï¼šç©ºæ•°æ®ä¸ç»˜å›¾ï¼‰
    if not related_df.empty:
        fig = px.bar(
            related_df,
            x="åœºç«™å",
            y=["å½“æœˆå®å‘æ€»é‡ï¼ˆMWhï¼‰", "å½“æœˆä¸­é•¿æœŸæŒä»“ï¼ˆMWhï¼‰"],
            barmode="group",
            title="å„åœºç«™å®å‘æ€»é‡ä¸ä¸­é•¿æœŸæŒä»“å¯¹æ¯”",
            template="plotly_white",
            color_discrete_map={
                "å½“æœˆå®å‘æ€»é‡ï¼ˆMWhï¼‰": "#1f77b4",
                "å½“æœˆä¸­é•¿æœŸæŒä»“ï¼ˆMWhï¼‰": "#ff7f0e"
            }
        )
        fig.update_layout(
            xaxis_title="åœºç«™å",
            yaxis_title="ç”µé‡ï¼ˆMWhï¼‰",
            width=1000,
            height=600
        )
        st.plotly_chart(fig, use_container_width=True)

# -------------------------- ä¸‹è½½å‡½æ•° --------------------------
def to_excel(df, sheet_name="æ•°æ®"):
    if df.empty:
        st.warning("âš ï¸ æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”ŸæˆExcel")
        return BytesIO()
    output = BytesIO()
    writer = pd.ExcelWriter(output, engine="openpyxl")
    df.to_excel(writer, index=False, sheet_name=sheet_name)
    writer.close()
    output.seek(0)
    return output

# -------------------------- ä¸»ç•Œé¢ --------------------------
st.title("ğŸ“Š å…‰ä¼/é£ç”µæ•°æ®ç®¡ç†å·¥å…·ï¼ˆå®å‘+æŒä»“å…³è”ç‰ˆï¼‰")
st.markdown("---")

# 1. å¤„ç†å®å‘æ•°æ®
if uploaded_generated_files:
    if st.button("ğŸš€ å¼€å§‹å¤„ç†åœºç«™å®å‘æ•°æ®", type="primary", key="process_generated"):
        with st.spinner("æ‰¹é‡å¤„ç†å®å‘æ–‡ä»¶ä¸­..."):
            merged_gen_df, stations = batch_process_generated(uploaded_generated_files)
            
            if not merged_gen_df.empty:
                # å®å‘æ•°æ®é¢„è§ˆ
                st.markdown("---")
                st.subheader("ğŸ“ˆ åœºç«™å®å‘åŸå§‹æ•°æ®é¢„è§ˆ")
                min_time = merged_gen_df["æ—¶é—´"].min().strftime("%Y-%m-%d %H:%M") if not merged_gen_df.empty else "æ— "
                max_time = merged_gen_df["æ—¶é—´"].max().strftime("%Y-%m-%d %H:%M") if not merged_gen_df.empty else "æ— "
                st.success(f"âœ… å®å‘æ•°æ®æ—¶é—´èŒƒå›´ï¼š{min_time} ~ {max_time}ï¼ˆå…±{len(merged_gen_df)}æ¡ï¼‰")
                
                tab1, tab2 = st.tabs(["å…¨éƒ¨å®å‘æ•°æ®", "å…‰ä¼åœºç«™å®å‘æ•°æ®"])
                with tab1:
                    st.markdown("**å‰20æ¡ï¼ˆæ—©æœŸæ•°æ®ï¼‰**")
                    st.dataframe(merged_gen_df.head(20), use_container_width=True)
                    st.markdown("**å20æ¡ï¼ˆåæœŸæ•°æ®ï¼‰**")
                    st.dataframe(merged_gen_df.tail(20), use_container_width=True)
                with tab2:
                    pv_cols = [col for col in merged_gen_df.columns if col in pv_stations_list]
                    if pv_cols:
                        pv_df = merged_gen_df[["æ—¶é—´"] + pv_cols].dropna(subset=pv_cols, how="all").sort_values("æ—¶é—´")
                        st.markdown("**å…‰ä¼æ•°æ®å‰20æ¡**")
                        st.dataframe(pv_df.head(20), use_container_width=True)
                        st.markdown("**å…‰ä¼æ•°æ®å20æ¡**")
                        st.dataframe(pv_df.tail(20), use_container_width=True)
                    else:
                        st.info("æš‚æ— å…‰ä¼åœºç«™å®å‘æ•°æ®")
                
                # 24æ—¶æ®µæ±‡æ€»
                st.markdown("---")
                st.subheader("ğŸ”‹ åœºç«™24æ—¶æ®µæœˆåº¦å®å‘æ±‡æ€»ï¼ˆå•ä½ï¼šMWhï¼‰")
                gen_24h_df, interval_h, stations = calculate_24h_generated(merged_gen_df)
                if not gen_24h_df.empty:
                    st.dataframe(gen_24h_df, use_container_width=True)
                
                # ä¸‹è½½
                st.markdown("---")
                st.subheader("ğŸ“¥ å®å‘æ•°æ®ä¸‹è½½")
                current_month = datetime.datetime.now().strftime("%Y%m")
                gen_raw_excel = to_excel(merged_gen_df, "å®å‘åŸå§‹æ•°æ®")
                gen_24h_excel = to_excel(gen_24h_df, "24æ—¶æ®µå®å‘æ±‡æ€»")
                
                st.download_button(
                    label="ä¸‹è½½å®å‘åŸå§‹æ•´åˆæ•°æ®",
                    data=gen_raw_excel,
                    file_name=f"åœºç«™å®å‘åŸå§‹æ•°æ®_{current_month}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="download_gen_raw",
                    disabled=merged_gen_df.empty
                )
                st.download_button(
                    label="ä¸‹è½½24æ—¶æ®µå®å‘æ±‡æ€»æ•°æ®",
                    data=gen_24h_excel,
                    file_name=f"åœºç«™24æ—¶æ®µå®å‘æ±‡æ€»_{current_month}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="download_gen_24h",
                    disabled=gen_24h_df.empty
                )

# 2. å¤„ç†æŒä»“æ•°æ®
if uploaded_hold_files and target_stations:
    if st.button("ğŸ“¦ å¼€å§‹å¤„ç†ä¸­é•¿æœŸæŒä»“æ•°æ®", type="primary", key="process_hold"):
        with st.spinner("å¤„ç†æŒä»“æ–‡ä»¶å¹¶å…³è”åœºç«™..."):
            # è®¡ç®—æ‰€æœ‰æŒä»“æ–‡ä»¶çš„æ€»ç”µé‡
            total_hold_all = 0.0
            for file in uploaded_hold_files:
                total_hold = extract_hold_data(file, hold_col_idx, hold_skip_rows)
                total_hold_all += total_hold
            
            # æŒ‰åœºç«™åˆ†é…ï¼ˆå‡åˆ†ï¼Œæˆ–å¯è‡ªå®šä¹‰åˆ†é…é€»è¾‘ï¼‰
            hold_per_station = round(total_hold_all / len(target_stations), 2) if target_stations else 0.0
            for station in target_stations:
                st.session_state.hold_data[station] = hold_per_station
                st.success(f"âœ… æŒä»“æ•°æ®å…³è”åˆ°åœºç«™[{station}]ï¼š{hold_per_station} MWh")
            
            st.success(f"âœ… æ‰€æœ‰æŒä»“æ–‡ä»¶å¤„ç†å®Œæˆï¼æ€»å‡€æŒæœ‰ç”µé‡={total_hold_all} MWhï¼Œå·²åˆ†é…åˆ°{len(target_stations)}ä¸ªåœºç«™")

# 3. å±•ç¤ºå…³è”ç»“æœ
show_related_data()

# 4. é‡ç½®æ•°æ®æŒ‰é’®ï¼ˆæ–°å¢ï¼šè§£å†³æ•°æ®æ®‹ç•™é—®é¢˜ï¼‰
st.markdown("---")
if st.button("ğŸ—‘ï¸ é‡ç½®æ‰€æœ‰æ•°æ®ï¼ˆå®å‘+æŒä»“ï¼‰", type="secondary"):
    st.session_state.generated_data = {}
    st.session_state.hold_data = {}
    st.session_state.extracted_stations = []
    st.session_state.merged_gen_df = pd.DataFrame()
    st.success("âœ… æ‰€æœ‰æ•°æ®å·²é‡ç½®ï¼")

# -------------------------- ä¾§è¾¹æ è¯´æ˜ --------------------------
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“ ä½¿ç”¨æŒ‡å¼•")
st.sidebar.markdown("""
1. å®å‘å¤„ç†ï¼šä¸Šä¼ æ–‡ä»¶â†’ç¡®è®¤é…ç½®â†’ç‚¹å‡»å¤„ç†â†’ç”Ÿæˆ24æ—¶æ®µæ±‡æ€»
2. æŒä»“å¤„ç†ï¼šä¸Šä¼ æ–‡ä»¶â†’é€‰æ‹©/è¾“å…¥å…³è”åœºç«™â†’ç‚¹å‡»å¤„ç†â†’è‡ªåŠ¨åˆ†é…æ•°æ®
3. å…³è”æŸ¥çœ‹ï¼šè‡ªåŠ¨å±•ç¤ºå®å‘-æŒä»“å¯¹æ¯”è¡¨+å›¾è¡¨
4. æ•°æ®é‡ç½®ï¼šè‹¥æ•°æ®å¼‚å¸¸ï¼Œç‚¹å‡»ã€Œé‡ç½®æ‰€æœ‰æ•°æ®ã€é‡æ–°å¤„ç†
""")

st.sidebar.markdown("### â„¹ï¸ æ³¨æ„äº‹é¡¹")
st.sidebar.markdown("""
- åœºç«™åéœ€ä¸€è‡´ï¼ˆå¤§å°å†™æ•æ„Ÿï¼‰
- æŒä»“æ•°æ®é»˜è®¤å‡åˆ†è‡³æ‰€é€‰åœºç«™ï¼ˆå¯è‡ªå®šä¹‰åˆ†é…é€»è¾‘ï¼‰
- æ‰€æœ‰æ•°æ®å­˜å‚¨åœ¨ä¼šè¯ä¸­ï¼Œåˆ·æ–°é¡µé¢ä¸ä¸¢å¤±ï¼ˆå…³é—­é¡µé¢é‡ç½®ï¼‰
- æ”¯æŒ.xlsx/.xls/.xlsmæ ¼å¼ï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨.xlsx
""")
