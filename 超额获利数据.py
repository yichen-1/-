import streamlit as st
import os
import pandas as pd
import re
from pathlib import Path
from io import BytesIO

# -------------------------- é¡µé¢é…ç½® --------------------------
st.set_page_config(
    page_title="å…‰ä¼/é£ç”µåŠŸç‡æ•°æ®æå–å·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# -------------------------- å›ºå®šé…ç½®ï¼ˆå¯åœ¨ç½‘é¡µä¾§è¾¹æ ä¿®æ”¹ï¼‰ --------------------------
st.sidebar.header("âš™ï¸ é…ç½®é¡¹")
target_dir = st.sidebar.text_input(
    "ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„",
    value=r"C:\Users\2æ–¤ç¾Šè‚‰\Desktop\ååˆ\æ¹–åŒ—\è¶…é¢è·åˆ©å›æ”¶\11æœˆ",
    placeholder="ç²˜è´´æ–‡ä»¶å¤¹ç»å¯¹è·¯å¾„"
)
file_keyword = st.sidebar.text_input("æ–‡ä»¶ç­›é€‰å…³é”®è¯", value="å†å²è¶‹åŠ¿")
time_col_idx = st.sidebar.number_input("æ—¶é—´åˆ—ç´¢å¼•ï¼ˆEåˆ—=4ï¼‰", value=4, min_value=0)
power_col_idx_wind = st.sidebar.number_input("é£ç”µåœºåŠŸç‡åˆ—ç´¢å¼•ï¼ˆJåˆ—=9ï¼‰", value=9, min_value=0)
power_col_idx_pv = st.sidebar.number_input("å…‰ä¼åœºåŠŸç‡åˆ—ç´¢å¼•ï¼ˆFåˆ—=5ï¼‰", value=5, min_value=0)
pv_stations = st.sidebar.text_input("å…‰ä¼åœºç«™åå•ï¼ˆé€—å·åˆ†éš”ï¼‰", value="æµ æ°´æ¸”å…‰,è¥„åŒ—å†œå…‰")
power_conversion = st.sidebar.number_input("åŠŸç‡è½¬æ¢ç³»æ•°ï¼ˆkWâ†’MWï¼‰", value=1000)
skip_rows = st.sidebar.number_input("è·³è¿‡è¡¨å¤´è¡Œæ•°", value=1, min_value=0)

# å¤„ç†å…‰ä¼åœºç«™åå•ä¸ºåˆ—è¡¨
pv_stations_list = [s.strip() for s in pv_stations.split(",") if s.strip()]

# -------------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° --------------------------
@st.cache_data(show_spinner="æ¸…æ´—åŠŸç‡æ•°æ®ä¸­...")
def clean_power_data(value):
    """æ¸…æ´—åŠŸç‡åˆ—æ•°æ®ï¼šæå–æ•°å€¼ï¼Œè¿‡æ»¤æ–‡æœ¬/ç‰¹æ®Šå­—ç¬¦"""
    if pd.isna(value):
        return None
    value_str = str(value).strip()
    if re.match(r'^[^\d.]+$', value_str):
        return None
    num_match = re.search(r'(\d+\.?\d*)', value_str)
    if num_match:
        try:
            return float(num_match.group(1))
        except:
            return None
    return None

def extract_station_name(file_name):
    """ä»æ–‡ä»¶åæå–åœºç«™å"""
    name_without_ext = os.path.splitext(file_name)[0]
    station_name = name_without_ext.split("-")[0].strip()
    return station_name

@st.cache_data(show_spinner="æå–Excelæ•°æ®ä¸­...")
def extract_excel_data(file_path, time_idx, power_idx, skip_r, conv):
    """æå–å•ä¸ªExcelæ–‡ä»¶æ•°æ®"""
    try:
        suffix = file_path.suffix.lower()
        engine = "openpyxl" if suffix in [".xlsx", ".xlsm"] else "xlrd"
        
        df = pd.read_excel(
            file_path,
            header=None,
            usecols=[time_idx, power_idx],
            skiprows=skip_r,
            engine=engine
        )
        
        df.columns = ["æ—¶é—´", "åŠŸç‡(kW)"]
        df["åŠŸç‡(kW)"] = df["åŠŸç‡(kW)"].apply(clean_power_data)
        df["æ—¶é—´"] = pd.to_datetime(df["æ—¶é—´"], errors="coerce")
        df = df.dropna(subset=["æ—¶é—´", "åŠŸç‡(kW)"])
        
        if df.empty:
            return pd.DataFrame()
        
        station_name = extract_station_name(file_path.name)
        df[station_name] = df["åŠŸç‡(kW)"] / conv
        df_result = df[["æ—¶é—´", station_name]].reset_index(drop=True)
        return df_result
    except Exception as e:
        st.error(f"å¤„ç† {file_path.name} å¤±è´¥ï¼š{str(e)}")
        return pd.DataFrame()

# -------------------------- æ‰¹é‡å¤„ç†å‡½æ•° --------------------------
def batch_extract_data():
    # 1. éªŒè¯æ–‡ä»¶å¤¹
    if not os.path.exists(target_dir):
        st.error("âŒ ç›®æ ‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼è¯·æ ¸å¯¹è·¯å¾„")
        return None, {}
    
    # 2. ç­›é€‰æ–‡ä»¶
    excel_exts = [".xlsx", ".xls", ".xlsm"]
    excel_files = [f for f in Path(target_dir).glob("*") if f.is_file() and f.suffix.lower() in excel_exts]
    target_files = [f for f in excel_files if file_keyword in f.name or file_keyword.lower() in f.name.lower()]
    
    if not target_files:
        st.error(f"âŒ æœªæ‰¾åˆ°åŒ…å«ã€Œ{file_keyword}ã€çš„Excelæ–‡ä»¶")
        return None, {}
    
    # 3. æ˜¾ç¤ºå¾…å¤„ç†æ–‡ä»¶
    st.info(f"âœ… æ‰¾åˆ° {len(target_files)} ä¸ªå¾…å¤„ç†æ–‡ä»¶ï¼š")
    file_list = []
    for i, f in enumerate(target_files, 1):
        station = extract_station_name(f.name)
        station_type = "ğŸ“¸ å…‰ä¼" if station in pv_stations_list else "ğŸ’¨ é£ç”µ"
        file_list.append(f"{i}. {station_type} {f.name}")
    st.code("\n".join(file_list))
    
    # 4. æ‰¹é‡æå–
    all_station_dfs = {}
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, file in enumerate(target_files):
        status_text.text(f"æ­£åœ¨å¤„ç†ï¼š{file.name}ï¼ˆ{idx+1}/{len(target_files)}ï¼‰")
        station_name = extract_station_name(file.name)
        
        # é€‰æ‹©åŠŸç‡åˆ—ç´¢å¼•
        if station_name in pv_stations_list:
            power_idx = power_col_idx_pv
        else:
            power_idx = power_col_idx_wind
        
        file_data = extract_excel_data(file, time_col_idx, power_idx, skip_rows, power_conversion)
        if not file_data.empty:
            all_station_dfs[station_name] = file_data
            st.success(f"âœ… {station_name}ï¼šæå–åˆ° {len(file_data)} æ¡æœ‰æ•ˆæ•°æ®")
        progress_bar.progress((idx + 1) / len(target_files))
    
    status_text.text("å¤„ç†å®Œæˆï¼å¼€å§‹åˆå¹¶æ•°æ®...")
    
    # 5. åˆå¹¶æ•°æ®
    if not all_station_dfs:
        st.error("âŒ æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®")
        return None, {}
    
    df_list = list(all_station_dfs.values())
    merged_df = df_list[0]
    for df in df_list[1:]:
        merged_df = pd.merge(merged_df, df, on="æ—¶é—´", how="outer")
    
    merged_df["æ—¶é—´"] = merged_df["æ—¶é—´"].dt.floor("min")
    merged_df = merged_df.sort_values("æ—¶é—´").reset_index(drop=True)
    
    # 6. ç»Ÿè®¡æ•°æ®
    st.success("ğŸ“Š æ•°æ®åˆå¹¶å®Œæˆï¼")
    st.info(f"""
    ç»Ÿè®¡ä¿¡æ¯ï¼š
    - æ€»æ—¶é—´ç‚¹æ•°ï¼š{len(merged_df)}
    - åŒ…å«åœºç«™ï¼š{', '.join(merged_df.columns[1:])}
    """)
    
    # æ˜¾ç¤ºå„åœºç«™æ•°æ®é‡
    st.subheader("å„åœºç«™æœ‰æ•ˆæ•°æ®é‡")
    stat_data = []
    for station in all_station_dfs.keys():
        valid_count = merged_df[station].notna().sum()
        stat_data.append({"åœºç«™å": station, "æœ‰æ•ˆæ•°æ®æ¡æ•°": valid_count})
    st.dataframe(pd.DataFrame(stat_data), use_container_width=True)
    
    progress_bar.empty()
    status_text.empty()
    
    return merged_df, all_station_dfs

# -------------------------- ä¸‹è½½å‡½æ•° --------------------------
def to_excel(df):
    """å°†DataFrameè½¬ä¸ºExcelå­—èŠ‚æµ"""
    output = BytesIO()
    writer = pd.ExcelWriter(output, engine="openpyxl")
    df.to_excel(writer, index=False, sheet_name="åŠŸç‡æ•°æ®")
    writer.close()
    output.seek(0)
    return output

# -------------------------- ç½‘é¡µä¸»ç•Œé¢ --------------------------
st.title("ğŸ“Š å…‰ä¼/é£ç”µåŠŸç‡æ•°æ®æå–å·¥å…·")
st.markdown("---")

# æ‰§è¡ŒæŒ‰é’®
if st.button("ğŸš€ å¼€å§‹æå–æ•°æ®", type="primary"):
    with st.spinner("æ­£åœ¨æ‰¹é‡å¤„ç†æ–‡ä»¶..."):
        result_df, station_dfs = batch_extract_data()
        
        if result_df is not None and not result_df.empty:
            # æ•°æ®é¢„è§ˆ
            st.markdown("---")
            st.subheader("ğŸ“ˆ æ•°æ®é¢„è§ˆ")
            
            # åˆ‡æ¢é¢„è§ˆæ ‡ç­¾
            tab1, tab2 = st.tabs(["å…¨éƒ¨æ•°æ®", "å…‰ä¼åœºç«™æ•°æ®"])
            with tab1:
                st.dataframe(result_df.head(20), use_container_width=True)
            with tab2:
                # ç­›é€‰å…‰ä¼åœºç«™æ•°æ®
                pv_cols = [col for col in result_df.columns if col in pv_stations_list]
                if pv_cols:
                    pv_df = result_df[["æ—¶é—´"] + pv_cols].dropna(subset=pv_cols, how="all")
                    st.dataframe(pv_df.head(20), use_container_width=True)
                else:
                    st.info("æš‚æ— å…‰ä¼åœºç«™æ•°æ®")
            
            # ä¸‹è½½æŒ‰é’®
            st.markdown("---")
            st.subheader("ğŸ“¥ ä¸‹è½½ç»“æœ")
            excel_data = to_excel(result_df)
            st.download_button(
                label="ä¸‹è½½æ•´åˆæ•°æ®ï¼ˆExcelï¼‰",
                data=excel_data,
                file_name="æ•´åˆæ•°æ®_å†å²è¶‹åŠ¿.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

# ä¾§è¾¹æ è¯´æ˜
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“ ä½¿ç”¨è¯´æ˜")
st.sidebar.markdown("""
1. ç²˜è´´ç›®æ ‡æ–‡ä»¶å¤¹ç»å¯¹è·¯å¾„ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰
2. ç¡®è®¤åˆ—ç´¢å¼•é…ç½®ï¼š
   - æ—¶é—´åˆ—ï¼šEåˆ—=4ï¼ˆç´¢å¼•ä»0å¼€å§‹ï¼‰
   - é£ç”µåŠŸç‡åˆ—ï¼šJåˆ—=9
   - å…‰ä¼åŠŸç‡åˆ—ï¼šFåˆ—=5
3. ç‚¹å‡»ã€Œå¼€å§‹æå–æ•°æ®ã€
4. é¢„è§ˆæ•°æ®åä¸‹è½½Excelæ–‡ä»¶
""")

st.sidebar.markdown("### â„¹ï¸ æ³¨æ„äº‹é¡¹")
st.sidebar.markdown("""
- æ”¯æŒ.xlsx/.xls/.xlsmæ ¼å¼
- è‡ªåŠ¨åŒºåˆ†å…‰ä¼/é£ç”µåœºç«™åˆ—ç´¢å¼•
- æ•°æ®æŒ‰æ—¶é—´å¯¹é½ï¼ŒNaNè¡¨ç¤ºæ— æ•°æ®
""")
