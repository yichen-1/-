import streamlit as st
import pandas as pd
import re
from io import BytesIO
import datetime

# -------------------------- é¡µé¢é…ç½® --------------------------
st.set_page_config(
    page_title="å…‰ä¼/é£ç”µåŠŸç‡æ•°æ®æå–å·¥å…·ï¼ˆå¯¼å…¥ç‰ˆï¼‰",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# -------------------------- ä¾§è¾¹æ é…ç½®ï¼ˆä¿ç•™æ ¸å¿ƒå‚æ•°ï¼‰ --------------------------
st.sidebar.header("âš™ï¸ é…ç½®é¡¹")
# ç§»é™¤æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ”¹ä¸ºæ–‡ä»¶ä¸Šä¼ 
st.sidebar.subheader("ğŸ“ ä¸Šä¼ Excelæ–‡ä»¶")
uploaded_files = st.sidebar.file_uploader(
    "é€‰æ‹©æœˆåº¦Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
    type=["xlsx", "xls", "xlsm"],
    accept_multiple_files=True
)

# æ ¸å¿ƒå‚æ•°é…ç½®ï¼ˆä¸å˜ï¼‰
file_keyword = st.sidebar.text_input("æ–‡ä»¶ç­›é€‰å…³é”®è¯ï¼ˆä»…æ˜¾ç¤ºå«è¯¥å…³é”®è¯çš„æ–‡ä»¶ï¼‰", value="å†å²è¶‹åŠ¿")
time_col_idx = st.sidebar.number_input("æ—¶é—´åˆ—ç´¢å¼•ï¼ˆEåˆ—=4ï¼‰", value=4, min_value=0)
power_col_idx_wind = st.sidebar.number_input("é£ç”µåœºåŠŸç‡åˆ—ç´¢å¼•ï¼ˆJåˆ—=9ï¼‰", value=9, min_value=0)
power_col_idx_pv = st.sidebar.number_input("å…‰ä¼åœºåŠŸç‡åˆ—ç´¢å¼•ï¼ˆFåˆ—=5ï¼‰", value=5, min_value=0)
pv_stations = st.sidebar.text_input("å…‰ä¼åœºç«™åå•ï¼ˆé€—å·åˆ†éš”ï¼‰", value="æµ æ°´æ¸”å…‰,è¥„åŒ—å†œå…‰")
power_conversion = st.sidebar.number_input("åŠŸç‡è½¬æ¢ç³»æ•°ï¼ˆkWâ†’MWï¼‰", value=1000)
skip_rows = st.sidebar.number_input("è·³è¿‡è¡¨å¤´è¡Œæ•°", value=1, min_value=0)

# å¤„ç†å…‰ä¼åœºç«™åå•ä¸ºåˆ—è¡¨
pv_stations_list = [s.strip() for s in pv_stations.split(",") if s.strip()]

# -------------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° --------------------------
@st.cache_data(show_spinner="æ¸…æ´—åŠŸç‡æ•°æ®ä¸­...")
def clean_power_data(value):
    """æ¸…æ´—åŠŸç‡åˆ—æ•°æ®ï¼šæå–æ•°å€¼ï¼Œè¿‡æ»¤æ–‡æœ¬/ç‰¹æ®Šå­—ç¬¦"""
    if pd.isna(value):
        return None
    value_str = str(value).strip()
    if re.match(r'^[^\d.]+$', value_str):
        return None
    num_match = re.search(r'(\d+\.?\d*)', value_str)
    if num_match:
        try:
            return float(num_match.group(1))
        except:
            return None
    return None

def extract_station_name(file_name):
    """ä»æ–‡ä»¶åæå–åœºç«™å"""
    name_without_ext = file_name.split(".")[0]  # å¤„ç†ä¸Šä¼ æ–‡ä»¶çš„æ–‡ä»¶åï¼ˆæ— è·¯å¾„ï¼‰
    station_name = name_without_ext.split("-")[0].strip()
    return station_name

@st.cache_data(show_spinner="æå–Excelæ•°æ®ä¸­...")
def extract_excel_data(uploaded_file, time_idx, power_idx, skip_r, conv):
    """æå–å•ä¸ªä¸Šä¼ Excelæ–‡ä»¶çš„æ•°æ®ï¼ˆé€‚é…BytesIOæµï¼‰"""
    try:
        # è¯†åˆ«æ–‡ä»¶æ ¼å¼ï¼Œé€‰æ‹©å¼•æ“
        file_name = uploaded_file.name
        suffix = file_name.split(".")[-1].lower()
        engine = "openpyxl" if suffix in ["xlsx", "xlsm"] else "xlrd"
        
        # è¯»å–ä¸Šä¼ çš„æ–‡ä»¶æµ
        df = pd.read_excel(
            BytesIO(uploaded_file.getvalue()),  # è½¬æ¢ä¸ºå­—èŠ‚æµ
            header=None,
            usecols=[time_idx, power_idx],
            skiprows=skip_r,
            engine=engine
        )
        
        # æ•°æ®æ¸…æ´—
        df.columns = ["æ—¶é—´", "åŠŸç‡(kW)"]
        df["åŠŸç‡(kW)"] = df["åŠŸç‡(kW)"].apply(clean_power_data)
        df["æ—¶é—´"] = pd.to_datetime(df["æ—¶é—´"], errors="coerce")
        df = df.dropna(subset=["æ—¶é—´", "åŠŸç‡(kW)"])
        
        if df.empty:
            return pd.DataFrame(), file_name
        
        # æå–åœºç«™åå¹¶è½¬æ¢å•ä½
        station_name = extract_station_name(file_name)
        df[station_name] = df["åŠŸç‡(kW)"] / conv
        df_result = df[["æ—¶é—´", station_name]].reset_index(drop=True)
        return df_result, file_name
    except Exception as e:
        st.error(f"å¤„ç† {uploaded_file.name} å¤±è´¥ï¼š{str(e)}")
        return pd.DataFrame(), uploaded_file.name

# -------------------------- æ‰¹é‡å¤„ç†å‡½æ•°ï¼ˆé€‚é…ä¸Šä¼ æ–‡ä»¶ï¼‰ --------------------------
def batch_extract_data(uploaded_files_list):
    # 1. ç­›é€‰å«å…³é”®è¯çš„æ–‡ä»¶
    target_files = []
    for file in uploaded_files_list:
        if file_keyword in file.name or file_keyword.lower() in file.name.lower():
            target_files.append(file)
        else:
            st.warning(f"âš ï¸ {file.name} ä¸å«å…³é”®è¯ã€Œ{file_keyword}ã€ï¼Œå·²è·³è¿‡")
    
    if not target_files:
        st.error(f"âŒ æœªæ‰¾åˆ°åŒ…å«ã€Œ{file_keyword}ã€çš„ä¸Šä¼ æ–‡ä»¶")
        return None, {}
    
    # 2. æ˜¾ç¤ºå¾…å¤„ç†æ–‡ä»¶
    st.info(f"âœ… æ‰¾åˆ° {len(target_files)} ä¸ªå¾…å¤„ç†æ–‡ä»¶ï¼š")
    file_list = []
    for i, f in enumerate(target_files, 1):
        station = extract_station_name(f.name)
        station_type = "ğŸ“¸ å…‰ä¼" if station in pv_stations_list else "ğŸ’¨ é£ç”µ"
        file_list.append(f"{i}. {station_type} {f.name}")
    st.code("\n".join(file_list))
    
    # 3. æ‰¹é‡æå–
    all_station_dfs = {}
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, file in enumerate(target_files):
        status_text.text(f"æ­£åœ¨å¤„ç†ï¼š{file.name}ï¼ˆ{idx+1}/{len(target_files)}ï¼‰")
        station_name = extract_station_name(file.name)
        
        # é€‰æ‹©åŠŸç‡åˆ—ç´¢å¼•
        if station_name in pv_stations_list:
            power_idx = power_col_idx_pv
        else:
            power_idx = power_col_idx_wind
        
        file_data, file_name = extract_excel_data(file, time_col_idx, power_idx, skip_rows, power_conversion)
        if not file_data.empty:
            all_station_dfs[station_name] = file_data
            st.success(f"âœ… {station_name}ï¼šæå–åˆ° {len(file_data)} æ¡æœ‰æ•ˆæ•°æ®")
        progress_bar.progress((idx + 1) / len(target_files))
    
    status_text.text("å¤„ç†å®Œæˆï¼å¼€å§‹åˆå¹¶æ•°æ®...")
    
    # 4. åˆå¹¶æ•°æ®
    if not all_station_dfs:
        st.error("âŒ æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®")
        return None, {}
    
    df_list = list(all_station_dfs.values())
    merged_df = df_list[0]
    for df in df_list[1:]:
        merged_df = pd.merge(merged_df, df, on="æ—¶é—´", how="outer")
    
    merged_df["æ—¶é—´"] = merged_df["æ—¶é—´"].dt.floor("min")
    merged_df = merged_df.sort_values("æ—¶é—´").reset_index(drop=True)
    
    # 5. ç»Ÿè®¡æ•°æ®
    st.success("ğŸ“Š æ•°æ®åˆå¹¶å®Œæˆï¼")
    st.info(f"""
    ç»Ÿè®¡ä¿¡æ¯ï¼š
    - æ€»æ—¶é—´ç‚¹æ•°ï¼š{len(merged_df)}
    - åŒ…å«åœºç«™ï¼š{', '.join(merged_df.columns[1:])}
    - å¤„ç†æ—¶é—´ï¼š{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    """)
    
    # æ˜¾ç¤ºå„åœºç«™æ•°æ®é‡
    st.subheader("å„åœºç«™æœ‰æ•ˆæ•°æ®é‡")
    stat_data = []
    for station in all_station_dfs.keys():
        valid_count = merged_df[station].notna().sum()
        stat_data.append({"åœºç«™å": station, "æœ‰æ•ˆæ•°æ®æ¡æ•°": valid_count})
    st.dataframe(pd.DataFrame(stat_data), use_container_width=True)
    
    progress_bar.empty()
    status_text.empty()
    
    return merged_df, all_station_dfs

# -------------------------- ä¸‹è½½å‡½æ•° --------------------------
def to_excel(df):
    """å°†DataFrameè½¬ä¸ºExcelå­—èŠ‚æµ"""
    output = BytesIO()
    writer = pd.ExcelWriter(output, engine="openpyxl")
    df.to_excel(writer, index=False, sheet_name="åŠŸç‡æ•°æ®")
    writer.close()
    output.seek(0)
    return output

# -------------------------- ç½‘é¡µä¸»ç•Œé¢ --------------------------
st.title("ğŸ“Š å…‰ä¼/é£ç”µåŠŸç‡æ•°æ®æå–å·¥å…·ï¼ˆæœˆåº¦å¯¼å…¥ç‰ˆï¼‰")
st.markdown("---")

# æç¤ºä¿¡æ¯
st.info("""
### ğŸ“ ä½¿ç”¨æŒ‡å¼•
1. åœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼ æœ¬æœˆçš„Excelæ•°æ®æ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ï¼‰
2. ç¡®è®¤åˆ—ç´¢å¼•/å…‰ä¼åœºç«™ç­‰é…ç½®ï¼ˆé¦–æ¬¡é…ç½®åæ— éœ€ä¿®æ”¹ï¼‰
3. ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹æå–æ•°æ®
4. é¢„è§ˆæ•°æ®åä¸‹è½½æ•´åˆæ–‡ä»¶
""")

# æ‰§è¡ŒæŒ‰é’®ï¼ˆä»…å½“æœ‰æ–‡ä»¶ä¸Šä¼ æ—¶å¯ç”¨ï¼‰
if uploaded_files:
    if st.button("ğŸš€ å¼€å§‹æå–æ•°æ®", type="primary"):
        with st.spinner("æ­£åœ¨æ‰¹é‡å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶..."):
            result_df, station_dfs = batch_extract_data(uploaded_files)
            
            if result_df is not None and not result_df.empty:
                # æ•°æ®é¢„è§ˆ
                st.markdown("---")
                st.subheader("ğŸ“ˆ æ•°æ®é¢„è§ˆ")
                
                # åˆ‡æ¢é¢„è§ˆæ ‡ç­¾
                tab1, tab2 = st.tabs(["å…¨éƒ¨æ•°æ®", "å…‰ä¼åœºç«™æ•°æ®"])
                with tab1:
                    st.dataframe(result_df.head(50), use_container_width=True)
                with tab2:
                    # ç­›é€‰å…‰ä¼åœºç«™æ•°æ®
                    pv_cols = [col for col in result_df.columns if col in pv_stations_list]
                    if pv_cols:
                        pv_df = result_df[["æ—¶é—´"] + pv_cols].dropna(subset=pv_cols, how="all")
                        st.dataframe(pv_df.head(50), use_container_width=True)
                    else:
                        st.info("æš‚æ— å…‰ä¼åœºç«™æ•°æ®")
                
                # ä¸‹è½½æŒ‰é’®
                st.markdown("---")
                st.subheader("ğŸ“¥ ä¸‹è½½ç»“æœ")
                # ç”Ÿæˆå¸¦å¹´æœˆçš„æ–‡ä»¶åï¼ˆé€‚é…æœˆåº¦æ•°æ®ï¼‰
                current_month = datetime.datetime.now().strftime("%Y%m")
                excel_data = to_excel(result_df)
                st.download_button(
                    label="ä¸‹è½½æ•´åˆæ•°æ®ï¼ˆExcelï¼‰",
                    data=excel_data,
                    file_name=f"æ•´åˆæ•°æ®_å†å²è¶‹åŠ¿_{current_month}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
else:
    st.warning("âš ï¸ è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼ Excelæ•°æ®æ–‡ä»¶ï¼")

# ä¾§è¾¹æ è¯´æ˜
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“ ä½¿ç”¨è¯´æ˜")
st.sidebar.markdown("""
1. ä¸Šä¼ æœ¬æœˆçš„å†å²è¶‹åŠ¿Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ï¼‰
2. ç¡®è®¤åˆ—ç´¢å¼•é…ç½®ï¼š
   - æ—¶é—´åˆ—ï¼šEåˆ—=4ï¼ˆç´¢å¼•ä»0å¼€å§‹ï¼‰
   - é£ç”µåŠŸç‡åˆ—ï¼šJåˆ—=9
   - å…‰ä¼åŠŸç‡åˆ—ï¼šFåˆ—=5
3. ç‚¹å‡»ã€Œå¼€å§‹æå–æ•°æ®ã€
4. é¢„è§ˆæ•°æ®åä¸‹è½½æœˆåº¦æ•´åˆæ–‡ä»¶
""")

st.sidebar.markdown("### â„¹ï¸ æ³¨æ„äº‹é¡¹")
st.sidebar.markdown("""
- æ”¯æŒ.xlsx/.xls/.xlsmæ ¼å¼
- è‡ªåŠ¨åŒºåˆ†å…‰ä¼/é£ç”µåœºç«™åˆ—ç´¢å¼•
- æ•°æ®æŒ‰æ—¶é—´å¯¹é½ï¼ŒNaNè¡¨ç¤ºæ— æ•°æ®
- ä¸‹è½½æ–‡ä»¶åè‡ªåŠ¨å¸¦å¹´æœˆï¼Œæ–¹ä¾¿å½’æ¡£
""")
