import streamlit as st
import pandas as pd
import os
import zipfile
import re
from datetime import datetime, date, time
from openpyxl.styles import Alignment, PatternFill
from io import BytesIO
import shutil

# ---------------------- å…¨å±€é…ç½® ----------------------
STORAGE_DIR = os.path.join(os.path.expanduser('~'), 'power_analysis_storage')
CONTRACT_DIR = os.path.join(STORAGE_DIR, 'monthly_contracts')
os.makedirs(CONTRACT_DIR, exist_ok=True)

st.set_page_config(
    page_title="è¿ç»­ç«ä»·è°ƒæ•´ç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ---------------------- å·¥å…·å‡½æ•° ----------------------
def clean_unit_name(unit_name):
    if pd.isna(unit_name) or unit_name == '':
        return ""
    unit_str = str(unit_name).strip()
    cleaned_str = re.sub(r'(\(.*?\)|ï¼ˆ.*?ï¼‰)', '', unit_str).strip()
    return cleaned_str

def truncate_to_two_decimal(x):
    if pd.isna(x):
        return None
    try:
        return float(int(float(x) * 100)) / 100
    except:
        return None

def format_worksheet(worksheet):
    alignment = Alignment(horizontal='center', vertical='center')
    for row in worksheet.iter_rows():
        for cell in row:
            cell.alignment = alignment
    for col in worksheet.columns:
        worksheet.column_dimensions[col[0].column_letter].width = 30

def extract_key_columns(df):
    key_columns = {
        'æ—¥æœŸ': None,
        'æ—¶æ®µ': None,
        'æ—¶æ®µåç§°': None,
        'ç”µé‡': None,
        'ç”µä»·': None
    }
    for col in df.columns:
        col_str = str(col).strip().lower()
        if 'æ—¥æœŸ' in col_str:
            key_columns['æ—¥æœŸ'] = col
        elif 'æ—¶æ®µ' in col_str and 'åç§°' not in col_str:
            key_columns['æ—¶æ®µ'] = col
        elif 'æ—¶æ®µåç§°' in col_str:
            key_columns['æ—¶æ®µåç§°'] = col
        elif 'ç”µé‡' in col_str:
            key_columns['ç”µé‡'] = col
        elif 'ç”µä»·' in col_str:
            key_columns['ç”µä»·'] = col
    if key_columns['ç”µé‡'] is None and key_columns['ç”µä»·'] is None:
        return pd.DataFrame()
    selected_cols = [col for col in key_columns.values() if col is not None]
    return df[selected_cols].copy()

def is_valid_excel_bytes(excel_bytes):
    try:
        with zipfile.ZipFile(BytesIO(excel_bytes), 'r') as zf:
            return '[Content_Types].xml' in zf.namelist()
    except:
        return False

# ---------------------- æŒä¹…åŒ–ç›¸å…³å‡½æ•° ----------------------
def save_monthly_contract_file(uploaded_file, month):
    safe_filename = re.sub(r'[^\w\.-]', '_', uploaded_file.name)
    save_path = os.path.join(CONTRACT_DIR, f"{month}_{safe_filename}")
    with open(save_path, 'wb') as f:
        f.write(uploaded_file.getbuffer())
    return save_path

def get_uploaded_months():
    months = set()
    for filename in os.listdir(CONTRACT_DIR):
        if filename.startswith(('2025-', '2024-')) and (filename.endswith('.xlsx') or filename.endswith('.xls')):
            month_part = filename.split('_')[0]
            if len(month_part) == 7 and '-' in month_part:
                months.add(month_part)
    return sorted(list(months))

def get_files_by_month(month):
    files = []
    for filename in os.listdir(CONTRACT_DIR):
        if filename.startswith(f"{month}_") and (filename.endswith('.xlsx') or filename.endswith('.xls')):
            file_path = os.path.join(CONTRACT_DIR, filename)
            if os.path.isfile(file_path):
                files.append(file_path)
    return files

def load_contract_files(selected_months):
    contract_files = []
    for month in selected_months:
        month_files = get_files_by_month(month)
        for file_path in month_files:
            with open(file_path, 'rb') as f:
                bytes_io = BytesIO(f.read())
                bytes_io.name = os.path.basename(file_path)
                contract_files.append(bytes_io)
    return contract_files

# ---------------------- æ ¸å¿ƒä¸šåŠ¡å‡½æ•° ----------------------
def generate_integrated_file_streamlit(source_excel_files, unit_station_mapping):
    unit_data = {unit: [] for unit in unit_station_mapping.keys()}
    
    for file_idx, uploaded_file in enumerate(source_excel_files):
        try:
            xls = pd.ExcelFile(uploaded_file, engine='openpyxl')
            for sheet in xls.sheet_names:
                df = xls.parse(sheet)
                if df.empty or df.shape[1] < 1:
                    continue
                
                key_df = extract_key_columns(df)
                if key_df.empty:
                    continue
                
                for idx, row in df.iterrows():
                    try:
                        raw_unit = row.iloc[0]
                        cleaned_unit = clean_unit_name(raw_unit)
                        if cleaned_unit not in unit_station_mapping:
                            continue
                        key_row = key_df.iloc[idx:idx+1].copy()
                        if not key_row.empty:
                            key_row['æ•°æ®æ¥æº'] = f"æ–‡ä»¶ï¼š{uploaded_file.name} | å·¥ä½œè¡¨ï¼š{sheet} | åŸå§‹å•å…ƒï¼š{raw_unit}"
                            unit_data[cleaned_unit].append(key_row)
                    except Exception as e:
                        continue
        except Exception as e:
            continue
    
    output_io = BytesIO()
    with pd.ExcelWriter(output_io, engine='openpyxl', mode='w') as writer:
        for cleaned_unit, station_name in unit_station_mapping.items():
            data_list = unit_data.get(cleaned_unit, [])
            if not data_list:
                pd.DataFrame({"æç¤º": [f"æ— æœ‰æ•ˆæ•°æ®ï¼š{cleaned_unit}"]}).to_excel(
                    writer, sheet_name=station_name, index=False
                )
                format_worksheet(writer.sheets[station_name])
                continue
            
            merged_df = pd.concat(data_list, ignore_index=True)
            if 'æ—¥æœŸ' in merged_df.columns:
                merged_df['æ—¥æœŸ'] = pd.to_datetime(merged_df['æ—¥æœŸ'], errors='coerce')
                merged_df = merged_df.sort_values(by=['æ—¥æœŸ', 'æ—¶æ®µ']).reset_index(drop=True)
            
            for col in merged_df.columns:
                if 'ç”µé‡' in col or 'ç”µä»·' in col:
                    merged_df[col] = merged_df[col].apply(truncate_to_two_decimal)
            
            merged_df.to_excel(writer, sheet_name=station_name, index=False)
            format_worksheet(writer.sheets[station_name])
    
    output_io.seek(0)
    return output_io

def process_power_forecast_streamlit(forecast_file):
    output_io = BytesIO()
    try:
        xls = pd.ExcelFile(forecast_file, engine='openpyxl')
        sheet_names = xls.sheet_names
        today = date.today()
        
        with pd.ExcelWriter(output_io, engine='openpyxl') as writer:
            for sheet_name in sheet_names:
                if sheet_name == 'å¡«å†™è¯´æ˜':
                    continue
                try:
                    df = xls.parse(sheet_name)
                except Exception as e:
                    continue
                
                if df.empty or df.shape[0] < 4 or df.shape[1] < 2:
                    continue
                
                time_column = df.iloc[:, 0]
                data_columns = df.columns[1:]
                times = []
                for t in time_column:
                    if isinstance(t, str):
                        try:
                            times.append(pd.to_datetime(t).time())
                        except:
                            times.append(None)
                    elif isinstance(t, (datetime, pd.Timestamp)):
                        times.append(t.time())
                    elif isinstance(t, time):
                        times.append(t)
                    else:
                        times.append(None)
                
                valid_times_mask = [t is not None for t in times]
                times = [t for t in times if t is not None]
                df = df[valid_times_mask].reset_index(drop=True)
                
                if not times:
                    continue
                
                processed_data = []
                for col in data_columns:
                    try:
                        col_date = pd.to_datetime(col).date()
                        if col_date >= today:
                            col_data = df[col]
                            averaged_data = []
                            for i in range(0, len(col_data), 4):
                                segment = col_data[i:i+4]
                                if not segment.isna().all():
                                    avg_val = segment.mean()
                                    averaged_data.append(truncate_to_two_decimal(avg_val))
                                else:
                                    averaged_data.append(None)
                            if any(pd.notna(averaged_data)):
                                row = [col_date] + averaged_data
                                processed_data.append(row)
                    except Exception as e:
                        continue
                
                if not processed_data:
                    continue
                
                time_points = [time(hour=i) for i in range(24)]
                columns = ['æ—¶é—´'] + [row[0] for row in processed_data]
                processed_df = pd.DataFrame(columns=columns)
                processed_df['æ—¶é—´'] = [t.strftime('%H:%M:%S') for t in time_points]
                
                for i, row in enumerate(processed_data):
                    col_name = row[0]
                    for j in range(min(24, len(row[1:]))):
                        processed_df.loc[j, col_name] = row[j+1]
                
                processed_df = processed_df.dropna(axis=1, how='all')
                processed_df.to_excel(writer, sheet_name=sheet_name, index=False)
                format_worksheet(writer.sheets[sheet_name])
    
    except Exception as e:
        pass
    
    output_io.seek(0)
    return output_io

def process_price_quantity_streamlit(price_quantity_file):
    output_io = BytesIO()
    try:
        xls_input = pd.ExcelFile(price_quantity_file, engine='openpyxl')
        sheet_names = xls_input.sheet_names
        
        with pd.ExcelWriter(output_io, engine='openpyxl') as writer:
            for sheet_name in sheet_names:
                try:
                    df = xls_input.parse(sheet_name)
                except Exception as e:
                    continue
                
                if df.empty:
                    continue
                
                date_col = next((col for col in df.columns if 'æ—¥æœŸ' in str(col)), None)
                quantity_cols = [col for col in df.columns if 'ç”µé‡' in str(col)]
                price_cols = [col for col in df.columns if 'ç”µä»·' in str(col)]
                
                if not date_col or not quantity_cols:
                    continue
                
                dates = []
                quantity_data = []
                price_data = []
                for idx, row in df.iterrows():
                    try:
                        current_date = pd.to_datetime(row[date_col]).date()
                        dates.append(current_date)
                        quantities = [truncate_to_two_decimal(row[col]) for col in quantity_cols]
                        quantity_data.append(quantities)
                        prices = [truncate_to_two_decimal(row[col]) for col in price_cols]
                        price_data.append(prices)
                    except Exception as e:
                        continue
                
                if not dates or not quantity_data:
                    continue
                
                processed_data = []
                for i, (date, quantities, prices) in enumerate(zip(dates, quantity_data, price_data)):
                    row_data = [date] + quantities + prices
                    processed_data.append(row_data)
                
                output_cols = ['æ—¥æœŸ'] + quantity_cols + price_cols
                processed_df = pd.DataFrame(processed_data, columns=output_cols)
                processed_df.to_excel(writer, sheet_name=sheet_name, index=False)
                format_worksheet(writer.sheets[sheet_name])
    
    except Exception as e:
        pass
    
    output_io.seek(0)
    return output_io

# ---------------------- å…³é”®æ”¹é€ ï¼šæŒ‰åœºç«™æ¥æ”¶å‚æ•° ----------------------
def calculate_difference_streamlit(forecast_file, price_quantity_file, station_params):
    """
    æŒ‰åœºç«™è®¡ç®—å·®å€¼ï¼šstation_paramsä¸ºå­—å…¸ï¼Œæ ¼å¼å¦‚ä¸‹
    {
        "åœºç«™å1": {"online": 0.8, "prefer": 0.725, "limit": 0.7},
        "åœºç«™å2": {"online": 0.8, "prefer": 0.775, "limit": 0.8},
        ...
    }
    """
    # åŠ¨æ€è®¡ç®—æ¯ä¸ªåœºç«™çš„æœ€ç»ˆç³»æ•°
    station_coefficient = {}
    for station_name, params in station_params.items():
        station_coefficient[station_name] = (
            params["online"] * params["prefer"] * params["limit"]
        )
    
    result_data = {}
    try:
        forecast_xls = pd.ExcelFile(forecast_file, engine='openpyxl')
        price_quantity_xls = pd.ExcelFile(price_quantity_file, engine='openpyxl')
        
        forecast_sheet_names = forecast_xls.sheet_names
        price_quantity_sheet_names = price_quantity_xls.sheet_names

        for sheet_name in forecast_sheet_names:
            if sheet_name == 'å¡«å†™è¯´æ˜':
                continue
            if sheet_name not in price_quantity_sheet_names:
                continue
            if sheet_name not in station_coefficient:  # è·³è¿‡æœªé…ç½®å‚æ•°çš„åœºç«™
                continue

            try:
                forecast_df = forecast_xls.parse(sheet_name)
                price_quantity_df = price_quantity_xls.parse(sheet_name)
            except Exception as e:
                continue

            if forecast_df.empty or len(forecast_df.columns) < 2:
                continue
            
            current_coeff = station_coefficient[sheet_name]  # æŒ‰åœºç«™å–ç³»æ•°
            time_col = forecast_df.iloc[:, 0]
            forecast_cols = forecast_df.columns[1:]
            quantity_cols = [col for col in price_quantity_df.columns if 'ç”µé‡' in str(col)]
            price_cols = [col for col in price_quantity_df.columns if 'ç”µä»·' in str(col)]
            
            if not quantity_cols:
                continue
            quantity_col = quantity_cols[0]
            price_col = price_cols[0] if price_cols else None

            processed_data = []
            for idx, row in forecast_df.iterrows():
                if idx >= len(price_quantity_df):
                    continue

                current_time = row[0]
                row_data = [current_time]
                current_price = truncate_to_two_decimal(price_quantity_df.iloc[idx][price_col]) if (price_col and pd.notna(price_quantity_df.iloc[idx][price_col])) else None
                
                for col in forecast_cols:
                    forecast_val = row[col]
                    row_data.append(forecast_val)
                    
                    try:
                        quantity_val = price_quantity_df.iloc[idx][quantity_col]
                        if pd.notna(forecast_val) and pd.notna(quantity_val):
                            corrected_forecast = float(forecast_val) * current_coeff
                            diff_val = truncate_to_two_decimal(corrected_forecast - float(quantity_val))
                            if diff_val < 0:
                                max_negative = -float(quantity_val)
                                diff_val = max(diff_val, max_negative)
                            row_data.append(diff_val)
                        else:
                            row_data.append(None)
                    except Exception as e:
                        row_data.append(None)
                
                row_data.append(current_price)
                processed_data.append(row_data)

            new_cols = ['æ—¶é—´']
            for col in forecast_cols:
                new_cols.extend([col, f'{col} (ä¿®æ­£åå·®é¢)'])
            new_cols.append('å¯¹åº”æ—¶æ®µç”µä»·')
            
            processed_df = pd.DataFrame(processed_data, columns=new_cols)
            if 'å¯¹åº”æ—¶æ®µç”µä»·' in processed_df.columns:
                processed_df['å¯¹åº”æ—¶æ®µç”µä»·'] = processed_df['å¯¹åº”æ—¶æ®µç”µä»·'].apply(truncate_to_two_decimal)
            
            result_data[sheet_name] = processed_df.copy()
    
    except Exception as e:
        st.error(f"è®¡ç®—å·®å€¼å‡ºé”™ï¼š{str(e)}")
    
    return result_data, station_coefficient

# ---------------------- ä¸»é¡µé¢é€»è¾‘ ----------------------
def main():
    # 1. å®šä¹‰æ‰€æœ‰åœºç«™åŠé»˜è®¤å‚æ•°ï¼ˆæ ¸å¿ƒï¼šç»Ÿä¸€ç®¡ç†åœºç«™åˆ—è¡¨å’Œé»˜è®¤å€¼ï¼‰
    DEFAULT_STATION_PARAMS = {
        "é£å‚¨ä¸€æœŸ": {"online": 0.8, "prefer": 0.725, "limit": 0.7},    # é£ç”µé»˜è®¤
        "é£å‚¨äºŒæœŸ": {"online": 0.8, "prefer": 0.725, "limit": 0.7},    # é£ç”µé»˜è®¤
        "æ —æºª": {"online": 0.8, "prefer": 0.725, "limit": 0.7},        # é£ç”µé»˜è®¤
        "å³ªå±±ä¸€æœŸ": {"online": 0.8, "prefer": 0.725, "limit": 0.7},    # é£ç”µé»˜è®¤
        "åœ£å¢ƒå±±": {"online": 0.8, "prefer": 0.725, "limit": 0.7},      # é£ç”µé»˜è®¤
        "è¥„åŒ—å†œå…‰": {"online": 0.8, "prefer": 0.775, "limit": 0.8},    # å…‰ä¼é»˜è®¤
        "æµ æ°´æ¸”å…‰": {"online": 0.8, "prefer": 0.775, "limit": 0.8}     # å…‰ä¼é»˜è®¤
    }
    # äº¤æ˜“å•å…ƒ-åœºç«™æ˜ å°„ï¼ˆä¸é»˜è®¤å‚æ•°åœºç«™åå¯¹åº”ï¼‰
    UNIT_TO_STATION = {
        "è¥„é˜³ååˆå³ªå±±æ³‰æ°´é£ç”µ": "å³ªå±±ä¸€æœŸ",
        "è†é—¨ååˆåœ£å¢ƒå±±é£ç”µ": "åœ£å¢ƒå±±",
        "è¥„é˜³èšåˆå…‰ä¼": "è¥„åŒ—å†œå…‰",
        "ä¸‰ç‹é£ç”µ": "é£å‚¨ä¸€æœŸ",  # åŒ¹é…æ¸…æ´—åçš„å•å…ƒå
        "è†é—¨ååˆæ —æºªé£ç”µ": "æ —æºª",
        "è¥„å·ååˆä¸‰ç‹é£å…‰å‚¨èƒ½ç”µç«™é£ç”µäºŒæœŸ": "é£å‚¨äºŒæœŸ",
        "æµ æ°´èšåˆå…³å£å…‰ä¼": "æµ æ°´æ¸”å…‰"
    }

    # 2. ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.title("ğŸ“‹ ç³»ç»ŸåŠŸèƒ½èœå•")
        
        with st.expander("ğŸ”§ è¿ç»­ç«ä»·è°ƒæ•´", expanded=False):
            st.header("ğŸ“ æ–‡ä»¶ç®¡ç†")
            
            # 2.1 æ‰¹é‡ä¸Šä¼ åˆçº¦æ–‡ä»¶
            st.subheader("1. æ‰¹é‡ä¸Šä¼ æœˆåº¦åˆçº¦æ–‡ä»¶")
            new_contract_files = st.file_uploader(
                "é€‰æ‹©åˆçº¦æ–‡ä»¶ï¼ˆæ”¯æŒæ‰¹é‡ä¸Šä¼ ï¼‰",
                type=["xlsx", "xls"],
                accept_multiple_files=True,
                key="new_contract"
            )
            selected_month = st.text_input(
                "æ–‡ä»¶å¯¹åº”æœˆä»½ï¼ˆæ ¼å¼ï¼š2025-11ï¼‰",
                value=datetime.now().strftime("%Y-%m"),
                key="contract_month"
            )
            
            if st.button("ä¿å­˜æœˆåº¦æ–‡ä»¶", key="save_contract"):
                if not new_contract_files:
                    st.warning("âš ï¸ è¯·å…ˆé€‰æ‹©è¦ä¸Šä¼ çš„åˆçº¦æ–‡ä»¶ï¼")
                elif not selected_month:
                    st.warning("âš ï¸ è¯·è¾“å…¥å¯¹åº”çš„æœˆä»½ï¼ˆæ ¼å¼ï¼š2025-11ï¼‰ï¼")
                else:
                    with st.spinner("æ‰¹é‡ä¿å­˜æ–‡ä»¶ä¸­..."):
                        saved_files = []
                        failed_files = []
                        for file in new_contract_files:
                            try:
                                save_path = save_monthly_contract_file(file, selected_month)
                                saved_files.append(os.path.basename(save_path))
                            except Exception as e:
                                failed_files.append(f"{file.name} - {str(e)}")
                        if saved_files:
                            st.success(f"âœ… æˆåŠŸä¿å­˜ {len(saved_files)} ä¸ªæ–‡ä»¶ï¼š")
                            for fname in saved_files:
                                st.write(f"  - {fname}")
                        if failed_files:
                            st.error(f"âŒ ä¿å­˜å¤±è´¥ {len(failed_files)} ä¸ªæ–‡ä»¶ï¼š")
                            for fname in failed_files:
                                st.write(f"  - {fname}")
            
            # 2.2 é€‰æ‹©åˆ†ææœˆä»½
            st.subheader("2. é€‰æ‹©åˆ†ææœˆä»½")
            uploaded_months = get_uploaded_months()
            if uploaded_months:
                selected_months = st.multiselect(
                    "å‹¾é€‰è¦åˆ†æçš„æœˆä»½",
                    options=uploaded_months,
                    default=uploaded_months,
                    key="selected_months"
                )
                st.write("ğŸ“‹ å„æœˆä»½æ–‡ä»¶ç»Ÿè®¡ï¼š")
                for month in uploaded_months:
                    file_count = len(get_files_by_month(month))
                    st.write(f"  â€¢ {month}ï¼š{file_count} ä¸ªæ–‡ä»¶")
            else:
                selected_months = []
                st.info("æš‚æ— å·²ä¸Šä¼ çš„æœˆåº¦åˆçº¦æ–‡ä»¶ï¼Œè¯·å…ˆä¸Šä¼ ")
            
            # 2.3 ä¸Šä¼ åŠŸç‡é¢„æµ‹æ–‡ä»¶
            st.subheader("3. åŠŸç‡é¢„æµ‹æ–‡ä»¶")
            forecast_file = st.file_uploader(
                "ä¸Šä¼ åŠŸç‡é¢„æµ‹æ–‡ä»¶ï¼ˆ2025åŠŸç‡é¢„æµ‹.xlsxï¼‰",
                type=["xlsx", "xls"],
                key="forecast"
            )
            
            # ---------------------- æ ¸å¿ƒæ”¹é€ ï¼šæŒ‰åœºç«™é…ç½®å‚æ•° ----------------------
            st.subheader("4. æŒ‰åœºç«™å‚æ•°é…ç½®")
            st.markdown("ğŸ’¡ æ¯ä¸ªåœºç«™å¯ç‹¬ç«‹è®¾ç½®ã€Œä¸Šç½‘ç”µé‡æŠ˜ç®—ç³»æ•°ã€ä¼˜å‘ä¼˜è´­æ¯”ä¾‹ã€é™ç”µç‡ã€")
            
            # å­˜å‚¨ç”¨æˆ·é…ç½®çš„åœºç«™å‚æ•°ï¼ˆç”¨session_stateä¿å­˜ï¼Œé¿å…åˆ·æ–°ä¸¢å¤±ï¼‰
            if "station_params" not in st.session_state:
                st.session_state["station_params"] = DEFAULT_STATION_PARAMS.copy()
            
            # ä¸ºæ¯ä¸ªåœºç«™ç”Ÿæˆç‹¬ç«‹çš„æŠ˜å é¢æ¿å’Œå‚æ•°è¾“å…¥æ¡†
            for station_name in DEFAULT_STATION_PARAMS.keys():
                with st.expander(f"ğŸ“ {station_name}", expanded=False):
                    # è¯»å–å½“å‰å‚æ•°ï¼ˆé»˜è®¤å€¼æˆ–ç”¨æˆ·å·²ä¿®æ”¹çš„å€¼ï¼‰
                    current_params = st.session_state["station_params"][station_name]
                    
                    # 1. ä¸Šç½‘ç”µé‡æŠ˜ç®—ç³»æ•°ï¼ˆå‚è€ƒæ‘˜è¦1/3çš„å¸‚åœºåŒ–æ”¿ç­–ï¼‰
                    online_coeff = st.number_input(
                        "ä¸Šç½‘ç”µé‡æŠ˜ç®—ç³»æ•°",
                        min_value=0.0,
                        max_value=1.0,
                        value=current_params["online"],
                        step=0.001,
                        key=f"{station_name}_online"
                    )
                    
                    # 2. ä¼˜å‘ä¼˜è´­æ¯”ä¾‹ï¼ˆå‚è€ƒæ‘˜è¦1å®å¤ä¼˜å…ˆå‘ç”µè®¡åˆ’ã€æ‘˜è¦6ç”˜è‚ƒå®¹é‡æŠ˜ç®—ï¼‰
                    prefer_ratio = st.number_input(
                        "ä¼˜å‘ä¼˜è´­æ¯”ä¾‹",
                        min_value=0.0,
                        max_value=1.0,
                        value=current_params["prefer"],
                        step=0.001,
                        key=f"{station_name}_prefer"
                    )
                    
                    # 3. é™ç”µç‡ï¼ˆå‚è€ƒæ‘˜è¦4æ±Ÿè‹/æ¹–å—é™ç”µæ•°æ®ï¼ŒèŒƒå›´0-1ï¼‰
                    limit_rate = st.number_input(
                        "é™ç”µç‡",
                        min_value=0.0,
                        max_value=1.0,
                        value=current_params["limit"],
                        step=0.001,
                        key=f"{station_name}_limit"
                    )
                    
                    # æ›´æ–°session_stateä¸­çš„å‚æ•°
                    st.session_state["station_params"][station_name] = {
                        "online": online_coeff,
                        "prefer": prefer_ratio,
                        "limit": limit_rate
                    }
            
            # æ˜ å°„é…ç½®å±•ç¤º
            with st.expander("âš™ï¸ äº¤æ˜“å•å…ƒæ˜ å°„é…ç½®", expanded=False):
                for k, v in UNIT_TO_STATION.items():
                    st.write(f"â€¢ {k} â†’ {v}")
        
        st.divider()
        st.write("ğŸ“Œ å…¶ä»–åŠŸèƒ½æ¨¡å—ï¼ˆé¢„ç•™ï¼‰")
    
    # 3. ä¸»é¡µé¢å†…å®¹
    st.title("ğŸ”§ è¿ç»­ç«ä»·è°ƒæ•´")
    st.divider()
    
    # 3.1 è·å–å…³é”®å˜é‡
    selected_months = st.session_state.get("selected_months", [])
    forecast_file = st.session_state.get("forecast")
    station_params = st.session_state.get("station_params", DEFAULT_STATION_PARAMS)
    
    # 3.2 æ˜¾ç¤ºå½“å‰æ‰€æœ‰åœºç«™çš„å‚æ•°æ±‡æ€»ï¼ˆæ–¹ä¾¿ç”¨æˆ·æ ¸å¯¹ï¼‰
    st.subheader("ğŸ“Š å½“å‰åœºç«™å‚æ•°æ±‡æ€»")
    # è½¬æ¢ä¸ºDataFrameå±•ç¤º
    param_summary = []
    for station_name, params in station_params.items():
        final_coeff = params["online"] * params["prefer"] * params["limit"]
        param_summary.append({
            "åœºç«™åç§°": station_name,
            "ä¸Šç½‘ç”µé‡æŠ˜ç®—ç³»æ•°": params["online"],
            "ä¼˜å‘ä¼˜è´­æ¯”ä¾‹": params["prefer"],
            "é™ç”µç‡": params["limit"],
            "æœ€ç»ˆè®¡ç®—ç³»æ•°": round(final_coeff, 6)
        })
    param_df = pd.DataFrame(param_summary)
    st.dataframe(param_df, use_container_width=True, hide_index=True)
    
    # 3.3 æ‰§è¡Œæµ‹ç®—æŒ‰é’®
    run_disabled = not (selected_months and forecast_file)
    if st.button("å¼€å§‹æµ‹ç®—", type="primary", disabled=run_disabled):
        with st.spinner("æ­£åœ¨æµ‹ç®—æ•°æ®ï¼Œè¯·ç¨å€™..."):
            # åŠ è½½åˆçº¦æ–‡ä»¶
            contract_files = load_contract_files(selected_months)
            # ç”Ÿæˆæ•´åˆæ–‡ä»¶
            integrated_io = generate_integrated_file_streamlit(contract_files, UNIT_TO_STATION)
            # å¤„ç†é¢„æµ‹æ–‡ä»¶å’Œç”µä»·ç”µé‡æ–‡ä»¶
            forecast_processed_io = process_power_forecast_streamlit(forecast_file)
            price_quantity_processed_io = process_price_quantity_streamlit(integrated_io)
            # æŒ‰åœºç«™å‚æ•°è®¡ç®—å·®å€¼ï¼ˆå…³é”®ï¼šä¼ å…¥åœºç«™å‚æ•°å­—å…¸ï¼‰
            result_data, station_coefficient = calculate_difference_streamlit(
                forecast_processed_io,
                integrated_io,
                station_params
            )
        
        # 3.4 å±•ç¤ºæµ‹ç®—ç»“æœ
        st.divider()
        st.header("ğŸ“ˆ æœ€ç»ˆæ±‡æ€»æ•°æ®å±•ç¤º")
        if result_data:
            # æŒ‰åœºç«™åˆ†æ ‡ç­¾å±•ç¤º
            station_tabs = st.tabs(list(result_data.keys()))
            for tab, (station_name, df) in zip(station_tabs, result_data.items()):
                with tab:
                    st.subheader(f"ğŸ“ {station_name}ï¼ˆæœ€ç»ˆç³»æ•°ï¼š{station_coefficient[station_name]:.6f}ï¼‰")
                    # æ•°æ®å±•ç¤º
                    st.dataframe(
                        df,
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            "æ—¶é—´": st.column_config.TextColumn("æ—¶æ®µ", width="small"),
                            "å¯¹åº”æ—¶æ®µç”µä»·": st.column_config.NumberColumn("ç”µä»·(å…ƒ)", format="%.2f"),
                        }
                    )
                    # ä¸‹è½½åŠŸèƒ½
                    csv_data = df.to_csv(index=False, encoding="utf-8-sig")
                    st.download_button(
                        label=f"ğŸ“¥ ä¸‹è½½{station_name}æ•°æ®ï¼ˆCSVï¼‰",
                        data=csv_data,
                        file_name=f"{station_name}_è°ƒæ•´ç»“æœ.csv",
                        mime="text/csv"
                    )
        else:
            st.warning("æš‚æ— å¯å±•ç¤ºçš„ç»“æœæ•°æ®ï¼ˆå¯èƒ½æ˜¯é¢„æµ‹æ–‡ä»¶ä¸åˆçº¦æ–‡ä»¶åœºç«™ä¸åŒ¹é…ï¼‰")
        
        st.success("âœ… æµ‹ç®—å®Œæˆï¼")
    
    # 3.5 æç¤ºä¿¡æ¯
    if run_disabled:
        if not selected_months:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ ã€Œè¿ç»­ç«ä»·è°ƒæ•´ã€èœå•ä¸­ä¸Šä¼ å¹¶é€‰æ‹©è¦åˆ†æçš„æœˆåº¦åˆçº¦æ–‡ä»¶ï¼")
        elif not forecast_file:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ ã€Œè¿ç»­ç«ä»·è°ƒæ•´ã€èœå•ä¸­ä¸Šä¼ åŠŸç‡é¢„æµ‹æ–‡ä»¶ï¼")

if __name__ == "__main__":
    main()
