import streamlit as st
import pandas as pd
import os
import zipfile
import re
from datetime import datetime, date, time
from openpyxl.styles import Alignment, PatternFill
from io import BytesIO

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŠŸç‡é¢„æµ‹ä¸ç”µä»·ç”µé‡åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° ----------------------
def clean_unit_name(unit_name):
    """æ¸…ç†äº¤æ˜“å•å…ƒåç§°ï¼šå»é™¤æ‹¬å·åŠæ‹¬å·å†…çš„å†…å®¹"""
    if pd.isna(unit_name) or unit_name == '':
        return ""
    unit_str = str(unit_name).strip()
    cleaned_str = re.sub(r'(\(.*?\)|ï¼ˆ.*?ï¼‰)', '', unit_str).strip()
    return cleaned_str

def truncate_to_two_decimal(x):
    """å°†æ•°å€¼æˆªæ–­åˆ°ä¸¤ä½å°æ•°ï¼ˆåªèˆä¸å…¥ï¼‰"""
    if pd.isna(x):
        return None
    try:
        return float(int(float(x) * 100)) / 100
    except:
        return None

def format_worksheet(worksheet):
    """è®¾ç½®å·¥ä½œè¡¨æ ¼å¼ï¼šå†…å®¹å±…ä¸­ï¼Œåˆ—å®½30"""
    alignment = Alignment(horizontal='center', vertical='center')
    for row in worksheet.iter_rows():
        for cell in row:
            cell.alignment = alignment
    for col in worksheet.columns:
        worksheet.column_dimensions[col[0].column_letter].width = 30

def extract_key_columns(df):
    """æå–å…³é”®åˆ—ï¼ˆæ—¥æœŸã€æ—¶æ®µã€ç”µé‡ã€ç”µä»·ï¼‰"""
    key_columns = {
        'æ—¥æœŸ': None,
        'æ—¶æ®µ': None,
        'æ—¶æ®µåç§°': None,
        'ç”µé‡': None,
        'ç”µä»·': None
    }
    for col in df.columns:
        col_str = str(col).strip().lower()
        if 'æ—¥æœŸ' in col_str:
            key_columns['æ—¥æœŸ'] = col
        elif 'æ—¶æ®µ' in col_str and 'åç§°' not in col_str:
            key_columns['æ—¶æ®µ'] = col
        elif 'æ—¶æ®µåç§°' in col_str:
            key_columns['æ—¶æ®µåç§°'] = col
        elif 'ç”µé‡' in col_str:
            key_columns['ç”µé‡'] = col
        elif 'ç”µä»·' in col_str:
            key_columns['ç”µä»·'] = col
    if key_columns['ç”µé‡'] is None and key_columns['ç”µä»·'] is None:
        return pd.DataFrame()
    selected_cols = [col for col in key_columns.values() if col is not None]
    return df[selected_cols].copy()

def is_valid_excel_bytes(excel_bytes):
    """æ ¡éªŒExcelå­—èŠ‚æµæœ‰æ•ˆæ€§"""
    try:
        with zipfile.ZipFile(BytesIO(excel_bytes), 'r') as zf:
            return '[Content_Types].xml' in zf.namelist()
    except:
        return False

# ---------------------- æ ¸å¿ƒä¸šåŠ¡å‡½æ•° ----------------------
def generate_integrated_file_streamlit(source_excel_files, unit_station_mapping):
    """
    Streamlitç‰ˆæœ¬ï¼šç”Ÿæˆç”µé‡ç”µä»·æ•´åˆæ–‡ä»¶
    :param source_excel_files: Streamlitä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆBytesIOï¼‰
    :param unit_station_mapping: äº¤æ˜“å•å…ƒæ˜ å°„å­—å…¸
    :return: æ•´åˆåçš„Excelå­—èŠ‚æµ
    """
    # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
    unit_data = {unit: [] for unit in unit_station_mapping.keys()}
    
    # å¤„ç†æ¯ä¸ªä¸Šä¼ çš„æ–‡ä»¶
    for file_idx, uploaded_file in enumerate(source_excel_files):
        st.write(f"ğŸ” å¤„ç†æ–‡ä»¶ï¼š{uploaded_file.name}")
        try:
            xls = pd.ExcelFile(uploaded_file, engine='openpyxl')
            # éå†å·¥ä½œè¡¨
            for sheet in xls.sheet_names:
                df = xls.parse(sheet)
                if df.empty or df.shape[1] < 1:
                    st.write(f"  - å·¥ä½œè¡¨'{sheet}'æ— æ•°æ®ï¼Œè·³è¿‡")
                    continue
                
                key_df = extract_key_columns(df)
                if key_df.empty:
                    st.write(f"  - å·¥ä½œè¡¨'{sheet}'æ— ç”µé‡/ç”µä»·åˆ—ï¼Œè·³è¿‡")
                    continue
                
                # æŒ‰äº¤æ˜“å•å…ƒæ‹†åˆ†
                for idx, row in df.iterrows():
                    try:
                        raw_unit = row.iloc[0]
                        cleaned_unit = clean_unit_name(raw_unit)
                        if cleaned_unit not in unit_station_mapping:
                            continue
                        key_row = key_df.iloc[idx:idx+1].copy()
                        if not key_row.empty:
                            key_row['æ•°æ®æ¥æº'] = f"æ–‡ä»¶ï¼š{uploaded_file.name} | å·¥ä½œè¡¨ï¼š{sheet} | åŸå§‹å•å…ƒï¼š{raw_unit}"
                            unit_data[cleaned_unit].append(key_row)
                    except Exception as e:
                        continue
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶ {uploaded_file.name} å‡ºé”™ï¼š{str(e)}")
            continue
    
    # ç”Ÿæˆæ•´åˆExcel
    output_io = BytesIO()
    with pd.ExcelWriter(output_io, engine='openpyxl', mode='w') as writer:
        for cleaned_unit, station_name in unit_station_mapping.items():
            st.write(f"ğŸ“ ç”Ÿæˆ{station_name}å·¥ä½œè¡¨")
            data_list = unit_data.get(cleaned_unit, [])
            if not data_list:
                pd.DataFrame({"æç¤º": [f"æ— æœ‰æ•ˆæ•°æ®ï¼š{cleaned_unit}"]}).to_excel(
                    writer, sheet_name=station_name, index=False
                )
                format_worksheet(writer.sheets[station_name])
                continue
            
            merged_df = pd.concat(data_list, ignore_index=True)
            if 'æ—¥æœŸ' in merged_df.columns:
                merged_df['æ—¥æœŸ'] = pd.to_datetime(merged_df['æ—¥æœŸ'], errors='coerce')
                merged_df = merged_df.sort_values(by=['æ—¥æœŸ', 'æ—¶æ®µ']).reset_index(drop=True)
            
            # å°æ•°å¤„ç†
            for col in merged_df.columns:
                if 'ç”µé‡' in col or 'ç”µä»·' in col:
                    merged_df[col] = merged_df[col].apply(truncate_to_two_decimal)
            
            merged_df.to_excel(writer, sheet_name=station_name, index=False)
            format_worksheet(writer.sheets[station_name])
            st.write(f"  âœ… {station_name}ï¼š{len(merged_df)}è¡Œæ•°æ®")
    
    output_io.seek(0)
    return output_io

def process_power_forecast_streamlit(forecast_file):
    """Streamlitç‰ˆæœ¬ï¼šå¤„ç†åŠŸç‡é¢„æµ‹æ•°æ®"""
    output_io = BytesIO()
    try:
        xls = pd.ExcelFile(forecast_file, engine='openpyxl')
        sheet_names = xls.sheet_names
        today = date.today()
        
        with pd.ExcelWriter(output_io, engine='openpyxl') as writer:
            for sheet_name in sheet_names:
                if sheet_name == 'å¡«å†™è¯´æ˜':
                    continue
                try:
                    df = xls.parse(sheet_name)
                except Exception as e:
                    st.error(f"è§£æå·¥ä½œè¡¨ '{sheet_name}' å‡ºé”™ï¼š{str(e)}")
                    continue
                
                if df.empty or df.shape[0] < 4 or df.shape[1] < 2:
                    st.write(f"å·¥ä½œè¡¨ '{sheet_name}' æ•°æ®ç»“æ„å¼‚å¸¸ï¼Œè·³è¿‡")
                    continue
                
                # å¤„ç†æ—¶é—´åˆ—
                time_column = df.iloc[:, 0]
                data_columns = df.columns[1:]
                times = []
                for t in time_column:
                    if isinstance(t, str):
                        try:
                            times.append(pd.to_datetime(t).time())
                        except:
                            times.append(None)
                    elif isinstance(t, (datetime, pd.Timestamp)):
                        times.append(t.time())
                    elif isinstance(t, time):
                        times.append(t)
                    else:
                        times.append(None)
                
                valid_times_mask = [t is not None for t in times]
                times = [t for t in times if t is not None]
                df = df[valid_times_mask].reset_index(drop=True)
                
                if not times:
                    st.write(f"å·¥ä½œè¡¨ '{sheet_name}' æ— æœ‰æ•ˆæ—¶é—´æ•°æ®ï¼Œè·³è¿‡")
                    continue
                
                # å¤„ç†é¢„æµ‹æ•°æ®
                processed_data = []
                for col in data_columns:
                    try:
                        col_date = pd.to_datetime(col).date()
                        if col_date >= today:
                            col_data = df[col]
                            averaged_data = []
                            for i in range(0, len(col_data), 4):
                                segment = col_data[i:i+4]
                                if not segment.isna().all():
                                    avg_val = segment.mean()
                                    averaged_data.append(truncate_to_two_decimal(avg_val))
                                else:
                                    averaged_data.append(None)
                            if any(pd.notna(averaged_data)):
                                row = [col_date] + averaged_data
                                processed_data.append(row)
                    except Exception as e:
                        st.write(f"å¤„ç†åˆ— '{col}' å‡ºé”™ï¼š{str(e)}")
                        continue
                
                if not processed_data:
                    st.write(f"å·¥ä½œè¡¨ '{sheet_name}' æ— æœ‰æ•ˆé¢„æµ‹æ•°æ®ï¼Œè·³è¿‡")
                    continue
                
                # æ„å»ºè¾“å‡ºæ•°æ®
                time_points = [time(hour=i) for i in range(24)]
                columns = ['æ—¶é—´'] + [row[0] for row in processed_data]
                processed_df = pd.DataFrame(columns=columns)
                processed_df['æ—¶é—´'] = [t.strftime('%H:%M:%S') for t in time_points]
                
                for i, row in enumerate(processed_data):
                    col_name = row[0]
                    for j in range(min(24, len(row[1:]))):
                        processed_df.loc[j, col_name] = row[j+1]
                
                processed_df = processed_df.dropna(axis=1, how='all')
                processed_df.to_excel(writer, sheet_name=sheet_name, index=False)
                format_worksheet(writer.sheets[sheet_name])
                st.write(f"âœ… å·¥ä½œè¡¨ '{sheet_name}' å¤„ç†å®Œæˆ")
    
    except Exception as e:
        st.error(f"å¤„ç†é¢„æµ‹æ•°æ®å‡ºé”™ï¼š{str(e)}")
    
    output_io.seek(0)
    return output_io

def process_price_quantity_streamlit(price_quantity_file, summary_file):
    """Streamlitç‰ˆæœ¬ï¼šå¤„ç†ç”µä»·ç”µé‡æ•°æ®"""
    output_io = BytesIO()
    try:
        xls_input = pd.ExcelFile(price_quantity_file, engine='openpyxl')
        xls_summary = pd.ExcelFile(summary_file, engine='openpyxl') if summary_file else None
        
        sheet_names = xls_input.sheet_names
        with pd.ExcelWriter(output_io, engine='openpyxl') as writer:
            for sheet_name in sheet_names:
                try:
                    df = xls_input.parse(sheet_name)
                except Exception as e:
                    st.error(f"è§£æå·¥ä½œè¡¨ '{sheet_name}' å‡ºé”™ï¼š{str(e)}")
                    continue
                
                if df.empty:
                    st.write(f"å·¥ä½œè¡¨ '{sheet_name}' ä¸ºç©ºï¼Œè·³è¿‡")
                    continue
                
                # æå–å…³é”®åˆ—
                date_col = next((col for col in df.columns if 'æ—¥æœŸ' in str(col)), None)
                quantity_cols = [col for col in df.columns if 'ç”µé‡' in str(col)]
                price_cols = [col for col in df.columns if 'ç”µä»·' in str(col)]
                
                if not date_col or not quantity_cols:
                    st.write(f"å·¥ä½œè¡¨ '{sheet_name}' ç¼ºå°‘æ—¥æœŸ/ç”µé‡åˆ—ï¼Œè·³è¿‡")
                    continue
                
                # è§£ææ•°æ®
                dates = []
                quantity_data = []
                price_data = []
                for idx, row in df.iterrows():
                    try:
                        current_date = pd.to_datetime(row[date_col]).date()
                        dates.append(current_date)
                        quantities = [truncate_to_two_decimal(row[col]) for col in quantity_cols]
                        quantity_data.append(quantities)
                        prices = [truncate_to_two_decimal(row[col]) for col in price_cols]
                        price_data.append(prices)
                    except Exception as e:
                        st.write(f"è§£æ{sheet_name}ç¬¬{idx+1}è¡Œå‡ºé”™ï¼š{str(e)}")
                        continue
                
                if not dates or not quantity_data:
                    st.write(f"å·¥ä½œè¡¨ '{sheet_name}' æ— æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡")
                    continue
                
                # è¯»å–æ±‡æ€»æ•°æ®
                date_to_summary = {}
                if xls_summary and sheet_name in xls_summary.sheet_names:
                    try:
                        summary_df = xls_summary.parse(sheet_name)
                        summary_date_col = summary_df.columns[0] if not summary_df.empty else None
                        if summary_date_col:
                            for idx, row in summary_df.iterrows():
                                try:
                                    s_date = pd.to_datetime(row[summary_date_col]).date()
                                    s_quantity = truncate_to_two_decimal(row[1]) if len(row) > 1 and pd.notna(row[1]) else None
                                    if s_date and s_quantity:
                                        date_to_summary[s_date] = s_quantity
                                except:
                                    continue
                    except Exception as e:
                        st.write(f"è¯»å–{sheet_name}æ±‡æ€»æ•°æ®å‡ºé”™ï¼š{str(e)}")
                
                # ç”Ÿæˆå¤„ç†åæ•°æ®
                processed_data = []
                for i, (date, quantities, prices) in enumerate(zip(dates, quantity_data, price_data)):
                    row_data = [date] + quantities + prices
                    processed_data.append(row_data)
                    
                    if date in date_to_summary:
                        diffs = []
                        for q in quantities:
                            if pd.notna(q):
                                diff = q - date_to_summary[date]
                                diffs.append(truncate_to_two_decimal(diff))
                            else:
                                diffs.append(None)
                        diff_row = [f"{date} (å·®é¢)"] + diffs + prices
                        processed_data.append(diff_row)
                
                output_cols = ['æ—¥æœŸ'] + quantity_cols + price_cols
                processed_df = pd.DataFrame(processed_data, columns=output_cols)
                processed_df.to_excel(writer, sheet_name=sheet_name, index=False)
                format_worksheet(writer.sheets[sheet_name])
                st.write(f"âœ… å·¥ä½œè¡¨ '{sheet_name}' å¤„ç†å®Œæˆ")
    
    except Exception as e:
        st.error(f"å¤„ç†ç”µä»·ç”µé‡æ•°æ®å‡ºé”™ï¼š{str(e)}")
    
    output_io.seek(0)
    return output_io

def calculate_difference_streamlit(forecast_file, price_quantity_file):
    """Streamlitç‰ˆæœ¬ï¼šè®¡ç®—å·®å€¼"""
    # åŠŸç‡é¢„æµ‹ç³»æ•°
    station_coefficient = {
        'é£å‚¨ä¸€æœŸ': 0.8*0.725*0.7 ,   
        'é£å‚¨äºŒæœŸ': 0.8*0.725*0.7,
        'æ —æºª': 0.8*0.725*0.7,
        'å³ªå±±ä¸€æœŸ': 0.8*0.725*0.7 ,
        'åœ£å¢ƒå±±': 0.8*0.725*0.7,
        'è¥„åŒ—å†œå…‰': 0.8*0.775*0.8,
        'æµ æ°´æ¸”å…‰': 0.8*0.775*0.8
    }
    
    output_io = BytesIO()
    try:
        forecast_xls = pd.ExcelFile(forecast_file, engine='openpyxl')
        price_quantity_xls = pd.ExcelFile(price_quantity_file, engine='openpyxl')
        
        forecast_sheet_names = forecast_xls.sheet_names
        price_quantity_sheet_names = price_quantity_xls.sheet_names

        with pd.ExcelWriter(output_io, engine='openpyxl') as writer:
            for sheet_name in forecast_sheet_names:
                if sheet_name == 'å¡«å†™è¯´æ˜':
                    continue
                if sheet_name not in price_quantity_sheet_names:
                    st.write(f"å·¥ä½œè¡¨ '{sheet_name}' åœ¨ç”µä»·ç”µé‡æ–‡ä»¶ä¸­ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                    continue

                try:
                    forecast_df = forecast_xls.parse(sheet_name)
                    price_quantity_df = price_quantity_xls.parse(sheet_name)
                except Exception as e:
                    st.error(f"è§£æ{sheet_name}å‡ºé”™ï¼š{str(e)}")
                    continue

                if forecast_df.empty or len(forecast_df.columns) < 2:
                    st.write(f"{sheet_name}é¢„æµ‹æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
                    continue
                
                current_coeff = station_coefficient.get(sheet_name, 1.0)
                st.write(f"ğŸ”§ å¤„ç†{sheet_name}ï¼šåŠŸç‡é¢„æµ‹ç³»æ•° = {round(current_coeff, 4)}")
                
                # æå–åˆ—
                time_col = forecast_df.iloc[:, 0]
                forecast_cols = forecast_df.columns[1:]
                quantity_cols = [col for col in price_quantity_df.columns if 'ç”µé‡' in str(col)]
                price_cols = [col for col in price_quantity_df.columns if 'ç”µä»·' in str(col)]
                
                if not quantity_cols:
                    st.write(f"{sheet_name}æ— ç”µé‡åˆ—ï¼Œè·³è¿‡")
                    continue
                quantity_col = quantity_cols[0]
                price_col = price_cols[0] if price_cols else None

                # è®¡ç®—å·®å€¼
                processed_data = []
                for idx, row in forecast_df.iterrows():
                    if idx >= len(price_quantity_df):
                        st.write(f"{sheet_name}æ•°æ®è¡Œæ•°ä¸è¶³ï¼Œç¬¬{idx+1}è¡Œè·³è¿‡")
                        continue

                    current_time = row[0]
                    row_data = [current_time]
                    current_price = truncate_to_two_decimal(price_quantity_df.iloc[idx][price_col]) if (price_col and pd.notna(price_quantity_df.iloc[idx][price_col])) else None
                    
                    for col in forecast_cols:
                        forecast_val = row[col]
                        row_data.append(forecast_val)
                        
                        try:
                            quantity_val = price_quantity_df.iloc[idx][quantity_col]
                            if pd.notna(forecast_val) and pd.notna(quantity_val):
                                corrected_forecast = float(forecast_val) * current_coeff
                                diff_val = truncate_to_two_decimal(corrected_forecast - float(quantity_val))
                                
                                if diff_val < 0:
                                    max_negative = -float(quantity_val)
                                    diff_val = max(diff_val, max_negative)
                                
                                row_data.append(diff_val)
                            else:
                                row_data.append(None)
                        except Exception as e:
                            st.write(f"  è®¡ç®—{sheet_name}ç¬¬{idx+1}è¡Œ{col}åˆ—å·®å€¼å‡ºé”™ï¼š{str(e)}")
                            row_data.append(None)
                    
                    row_data.append(current_price)
                    processed_data.append(row_data)

                # æ„å»ºåˆ—å
                new_cols = ['æ—¶é—´']
                for col in forecast_cols:
                    new_cols.extend([col, f'{col} (ä¿®æ­£åå·®é¢)'])
                new_cols.append('å¯¹åº”æ—¶æ®µç”µä»·')
                
                processed_df = pd.DataFrame(processed_data, columns=new_cols)
                if 'å¯¹åº”æ—¶æ®µç”µä»·' in processed_df.columns:
                    processed_df['å¯¹åº”æ—¶æ®µç”µä»·'] = processed_df['å¯¹åº”æ—¶æ®µç”µä»·'].apply(truncate_to_two_decimal)
                processed_df.to_excel(writer, sheet_name=sheet_name, index=False)
                
                # è®¾ç½®æ ¼å¼ + è´Ÿå€¼æ ‡é»„
                worksheet = writer.sheets[sheet_name]
                format_worksheet(worksheet)
                yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
                for col_idx in range(2, len(new_cols)-1, 2):
                    col_letter = chr(65 + col_idx)
                    for row_idx in range(1, len(processed_df) + 1):
                        cell = worksheet[f'{col_letter}{row_idx + 1}']
                        try:
                            val = float(cell.value) if cell.value is not None else None
                            if val is not None and val < 0:
                                cell.fill = yellow_fill
                        except:
                            continue

                st.write(f"âœ… å·¥ä½œè¡¨ '{sheet_name}' å¤„ç†å®Œæˆ")
    
    except Exception as e:
        st.error(f"è®¡ç®—å·®å€¼å‡ºé”™ï¼š{str(e)}")
    
    output_io.seek(0)
    return output_io

# ---------------------- Streamlit é¡µé¢äº¤äº’ ----------------------
def main():
    st.title("ğŸ“Š åŠŸç‡é¢„æµ‹ä¸ç”µä»·ç”µé‡åˆ†æç³»ç»Ÿ")
    st.divider()
    
    # ä¾§è¾¹æ ï¼šæ–‡ä»¶ä¸Šä¼ 
    with st.sidebar:
        st.header("ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
        # 1. åŠŸç‡é¢„æµ‹æ–‡ä»¶
        forecast_file = st.file_uploader(
            "1. ä¸Šä¼ åŠŸç‡é¢„æµ‹æ–‡ä»¶ï¼ˆ2025åŠŸç‡é¢„æµ‹.xlsxï¼‰",
            type=["xlsx", "xls"],
            key="forecast"
        )
        
        # 2. æœºç»„å‡€åˆçº¦ç”µé‡æ–‡ä»¶ï¼ˆæ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ ï¼‰
        contract_files = st.file_uploader(
            "2. ä¸Šä¼ æœºç»„å‡€åˆçº¦ç”µé‡æ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªï¼‰",
            type=["xlsx", "xls"],
            accept_multiple_files=True,
            key="contract"
        )
        
        # 3. æ±‡æ€»æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        summary_file = st.file_uploader(
            "3. ä¸Šä¼ æ±‡æ€»æ–‡ä»¶ï¼ˆæ±‡æ€».xlsxï¼Œå¯é€‰ï¼‰",
            type=["xlsx", "xls"],
            key="summary"
        )
        
        # æ˜ å°„å…³ç³»ï¼ˆå›ºå®šï¼‰
        st.header("âš™ï¸ æ˜ å°„é…ç½®")
        unit_to_station = {
            "è¥„é˜³ååˆå³ªå±±æ³‰æ°´é£ç”µ": "å³ªå±±ä¸€æœŸ",
            "è†é—¨ååˆåœ£å¢ƒå±±é£ç”µ": "åœ£å¢ƒå±±",
            "è¥„é˜³èšåˆå…‰ä¼": "è¥„åŒ—å†œå…‰",
            "ä¸‰ç‹ï¼ˆååˆè¥„åŒ—ï¼‰é£ç”µ": "é£å‚¨ä¸€æœŸ",
            "è†é—¨ååˆæ —æºªé£ç”µ": "æ —æºª",
            "è¥„å·ååˆä¸‰ç‹é£å…‰å‚¨èƒ½ç”µç«™é£ç”µäºŒæœŸ": "é£å‚¨äºŒæœŸ",
            "æµ æ°´èšåˆå…³å£å…‰ä¼": "æµ æ°´æ¸”å…‰"
        }
        st.write("äº¤æ˜“å•å…ƒ â†’ åœºç«™æ˜ å°„ï¼š")
        for k, v in unit_to_station.items():
            st.write(f"â€¢ {k} â†’ {v}")
    
    # ä¸»é¡µé¢ï¼šæ‰§è¡Œæµç¨‹
    st.header("ğŸš€ æ‰§è¡Œåˆ†ææµç¨‹")
    if st.button("å¼€å§‹å¤„ç†", type="primary", disabled=not (forecast_file and contract_files)):
        with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®ï¼Œè¯·ç¨å€™..."):
            # æ­¥éª¤1ï¼šç”Ÿæˆç”µé‡ç”µä»·æ•´åˆæ–‡ä»¶
            st.subheader("æ­¥éª¤1ï¼šç”Ÿæˆç”µé‡ç”µä»·æ•´åˆæ–‡ä»¶")
            integrated_io = generate_integrated_file_streamlit(contract_files, unit_to_station)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ç”µé‡ç”µä»·æ•´åˆæ–‡ä»¶",
                data=integrated_io,
                file_name="ç”µé‡ç”µä»·æ•´åˆ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            
            # æ­¥éª¤2ï¼šå¤„ç†é¢„æµ‹æ•°æ®
            st.subheader("æ­¥éª¤2ï¼šå¤„ç†åŠŸç‡é¢„æµ‹æ•°æ®")
            forecast_processed_io = process_power_forecast_streamlit(forecast_file)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å¤„ç†ååŠŸç‡é¢„æµ‹æ–‡ä»¶",
                data=forecast_processed_io,
                file_name="2025åŠŸç‡é¢„æµ‹_å¤„ç†å.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            
            # æ­¥éª¤3ï¼šå¤„ç†ç”µä»·ç”µé‡æ•°æ®
            st.subheader("æ­¥éª¤3ï¼šå¤„ç†ç”µä»·ç”µé‡æ•°æ®")
            price_quantity_processed_io = process_price_quantity_streamlit(integrated_io, summary_file)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å¤„ç†åç”µä»·ç”µé‡æ–‡ä»¶",
                data=price_quantity_processed_io,
                file_name="ç”µé‡ç”µä»·æ•´åˆ_å¤„ç†å.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            
            # æ­¥éª¤4ï¼šè®¡ç®—å·®å€¼
            st.subheader("æ­¥éª¤4ï¼šè®¡ç®—åŠŸç‡é¢„æµ‹ä¸ç”µé‡å·®å€¼")
            difference_io = calculate_difference_streamlit(forecast_processed_io, integrated_io)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½è°ƒæ•´ç»“æœæ–‡ä»¶",
                data=difference_io,
                file_name="è°ƒæ•´ç»“æœ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        
        st.success("âœ… æ‰€æœ‰å¤„ç†å·²å®Œæˆï¼è¯·ä¸‹è½½å¯¹åº”çš„ç»“æœæ–‡ä»¶ã€‚")
    
    # æç¤ºä¿¡æ¯
    if not (forecast_file and contract_files):
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ ã€åŠŸç‡é¢„æµ‹æ–‡ä»¶ã€‘å’Œã€æœºç»„å‡€åˆçº¦ç”µé‡æ–‡ä»¶ã€‘åå†æ‰§è¡Œå¤„ç†ï¼")

if __name__ == "__main__":
    main()
