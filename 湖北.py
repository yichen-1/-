import streamlit as st
import pandas as pd
import os
import zipfile
import re
from datetime import datetime, date, time
from openpyxl.styles import Alignment, PatternFill
from io import BytesIO
import shutil

# ---------------------- å…¨å±€é…ç½® ----------------------
# æŒä¹…åŒ–å­˜å‚¨ç›®å½•ï¼ˆéƒ¨ç½²æ—¶å¯ä¿®æ”¹ä¸ºç»å¯¹è·¯å¾„ï¼‰
STORAGE_DIR = os.path.join(os.path.expanduser('~'), 'power_analysis_storage')
CONTRACT_DIR = os.path.join(STORAGE_DIR, 'monthly_contracts')
# è‡ªåŠ¨åˆ›å»ºå­˜å‚¨ç›®å½•
os.makedirs(CONTRACT_DIR, exist_ok=True)

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="è¿ç»­ç«ä»·è°ƒæ•´ç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ---------------------- å·¥å…·å‡½æ•° ----------------------
def clean_unit_name(unit_name):
    """æ¸…ç†äº¤æ˜“å•å…ƒåç§°ï¼šå»é™¤æ‹¬å·åŠæ‹¬å·å†…çš„å†…å®¹"""
    if pd.isna(unit_name) or unit_name == '':
        return ""
    unit_str = str(unit_name).strip()
    cleaned_str = re.sub(r'(\(.*?\)|ï¼ˆ.*?ï¼‰)', '', unit_str).strip()
    return cleaned_str

def truncate_to_two_decimal(x):
    """å°†æ•°å€¼æˆªæ–­åˆ°ä¸¤ä½å°æ•°ï¼ˆåªèˆä¸å…¥ï¼‰"""
    if pd.isna(x):
        return None
    try:
        return float(int(float(x) * 100)) / 100
    except:
        return None

def format_worksheet(worksheet):
    """è®¾ç½®å·¥ä½œè¡¨æ ¼å¼ï¼šå†…å®¹å±…ä¸­ï¼Œåˆ—å®½30"""
    alignment = Alignment(horizontal='center', vertical='center')
    for row in worksheet.iter_rows():
        for cell in row:
            cell.alignment = alignment
    for col in worksheet.columns:
        worksheet.column_dimensions[col[0].column_letter].width = 30

def extract_key_columns(df):
    """æå–å…³é”®åˆ—ï¼ˆæ—¥æœŸã€æ—¶æ®µã€ç”µé‡ã€ç”µä»·ï¼‰"""
    key_columns = {
        'æ—¥æœŸ': None,
        'æ—¶æ®µ': None,
        'æ—¶æ®µåç§°': None,
        'ç”µé‡': None,
        'ç”µä»·': None
    }
    for col in df.columns:
        col_str = str(col).strip().lower()
        if 'æ—¥æœŸ' in col_str:
            key_columns['æ—¥æœŸ'] = col
        elif 'æ—¶æ®µ' in col_str and 'åç§°' not in col_str:
            key_columns['æ—¶æ®µ'] = col
        elif 'æ—¶æ®µåç§°' in col_str:
            key_columns['æ—¶æ®µåç§°'] = col
        elif 'ç”µé‡' in col_str:
            key_columns['ç”µé‡'] = col
        elif 'ç”µä»·' in col_str:
            key_columns['ç”µä»·'] = col
    if key_columns['ç”µé‡'] is None and key_columns['ç”µä»·'] is None:
        return pd.DataFrame()
    selected_cols = [col for col in key_columns.values() if col is not None]
    return df[selected_cols].copy()

def is_valid_excel_bytes(excel_bytes):
    """æ ¡éªŒExcelå­—èŠ‚æµæœ‰æ•ˆæ€§"""
    try:
        with zipfile.ZipFile(BytesIO(excel_bytes), 'r') as zf:
            return '[Content_Types].xml' in zf.namelist()
    except:
        return False

# ---------------------- æŒä¹…åŒ–ç›¸å…³å‡½æ•° ----------------------
def save_monthly_contract_file(uploaded_file, month):
    """ä¿å­˜æœˆåº¦åˆçº¦æ–‡ä»¶åˆ°æœ¬åœ°å­˜å‚¨"""
    # ç”Ÿæˆæ–‡ä»¶åï¼šæœˆä»½_åŸæ–‡ä»¶å
    safe_filename = re.sub(r'[^\w\.-]', '_', uploaded_file.name)
    save_path = os.path.join(CONTRACT_DIR, f"{month}_{safe_filename}")
    # ä¿å­˜æ–‡ä»¶
    with open(save_path, 'wb') as f:
        f.write(uploaded_file.getbuffer())
    return save_path

def get_uploaded_months():
    """è·å–å·²ä¸Šä¼ çš„æœˆä»½åˆ—è¡¨"""
    months = set()
    for filename in os.listdir(CONTRACT_DIR):
        if filename.startswith(('2025-', '2024-')) and (filename.endswith('.xlsx') or filename.endswith('.xls')):
            # æå–æœˆä»½ï¼ˆæ ¼å¼ï¼š2025-11ï¼‰
            month_part = filename.split('_')[0]
            if len(month_part) == 7 and '-' in month_part:
                months.add(month_part)
    return sorted(list(months))

def get_files_by_month(month):
    """è·å–æŒ‡å®šæœˆä»½çš„åˆçº¦æ–‡ä»¶åˆ—è¡¨"""
    files = []
    for filename in os.listdir(CONTRACT_DIR):
        if filename.startswith(f"{month}_") and (filename.endswith('.xlsx') or filename.endswith('.xls')):
            file_path = os.path.join(CONTRACT_DIR, filename)
            if os.path.isfile(file_path):
                files.append(file_path)
    return files

def load_contract_files(selected_months):
    """åŠ è½½é€‰ä¸­æœˆä»½çš„æ‰€æœ‰åˆçº¦æ–‡ä»¶"""
    contract_files = []
    for month in selected_months:
        month_files = get_files_by_month(month)
        for file_path in month_files:
            # è½¬æ¢ä¸ºBytesIOä¾›pandasè¯»å–
            with open(file_path, 'rb') as f:
                bytes_io = BytesIO(f.read())
                bytes_io.name = os.path.basename(file_path)  # ä¿ç•™æ–‡ä»¶å
                contract_files.append(bytes_io)
    return contract_files

# ---------------------- æ ¸å¿ƒä¸šåŠ¡å‡½æ•° ----------------------
def generate_integrated_file_streamlit(source_excel_files, unit_station_mapping):
    """ç”Ÿæˆç”µé‡ç”µä»·æ•´åˆæ–‡ä»¶"""
    unit_data = {unit: [] for unit in unit_station_mapping.keys()}
    
    for file_idx, uploaded_file in enumerate(source_excel_files):
        try:
            xls = pd.ExcelFile(uploaded_file, engine='openpyxl')
            for sheet in xls.sheet_names:
                df = xls.parse(sheet)
                if df.empty or df.shape[1] < 1:
                    continue
                
                key_df = extract_key_columns(df)
                if key_df.empty:
                    continue
                
                for idx, row in df.iterrows():
                    try:
                        raw_unit = row.iloc[0]
                        cleaned_unit = clean_unit_name(raw_unit)
                        if cleaned_unit not in unit_station_mapping:
                            continue
                        key_row = key_df.iloc[idx:idx+1].copy()
                        if not key_row.empty:
                            key_row['æ•°æ®æ¥æº'] = f"æ–‡ä»¶ï¼š{uploaded_file.name} | å·¥ä½œè¡¨ï¼š{sheet} | åŸå§‹å•å…ƒï¼š{raw_unit}"
                            unit_data[cleaned_unit].append(key_row)
                    except Exception as e:
                        continue
        except Exception as e:
            continue
    
    output_io = BytesIO()
    with pd.ExcelWriter(output_io, engine='openpyxl', mode='w') as writer:
        for cleaned_unit, station_name in unit_station_mapping.items():
            data_list = unit_data.get(cleaned_unit, [])
            if not data_list:
                pd.DataFrame({"æç¤º": [f"æ— æœ‰æ•ˆæ•°æ®ï¼š{cleaned_unit}"]}).to_excel(
                    writer, sheet_name=station_name, index=False
                )
                format_worksheet(writer.sheets[station_name])
                continue
            
            merged_df = pd.concat(data_list, ignore_index=True)
            if 'æ—¥æœŸ' in merged_df.columns:
                merged_df['æ—¥æœŸ'] = pd.to_datetime(merged_df['æ—¥æœŸ'], errors='coerce')
                merged_df = merged_df.sort_values(by=['æ—¥æœŸ', 'æ—¶æ®µ']).reset_index(drop=True)
            
            for col in merged_df.columns:
                if 'ç”µé‡' in col or 'ç”µä»·' in col:
                    merged_df[col] = merged_df[col].apply(truncate_to_two_decimal)
            
            merged_df.to_excel(writer, sheet_name=station_name, index=False)
            format_worksheet(writer.sheets[station_name])
    
    output_io.seek(0)
    return output_io

def process_power_forecast_streamlit(forecast_file):
    """å¤„ç†åŠŸç‡é¢„æµ‹æ•°æ®"""
    output_io = BytesIO()
    try:
        xls = pd.ExcelFile(forecast_file, engine='openpyxl')
        sheet_names = xls.sheet_names
        today = date.today()
        
        with pd.ExcelWriter(output_io, engine='openpyxl') as writer:
            for sheet_name in sheet_names:
                if sheet_name == 'å¡«å†™è¯´æ˜':
                    continue
                try:
                    df = xls.parse(sheet_name)
                except Exception as e:
                    continue
                
                if df.empty or df.shape[0] < 4 or df.shape[1] < 2:
                    continue
                
                time_column = df.iloc[:, 0]
                data_columns = df.columns[1:]
                times = []
                for t in time_column:
                    if isinstance(t, str):
                        try:
                            times.append(pd.to_datetime(t).time())
                        except:
                            times.append(None)
                    elif isinstance(t, (datetime, pd.Timestamp)):
                        times.append(t.time())
                    elif isinstance(t, time):
                        times.append(t)
                    else:
                        times.append(None)
                
                valid_times_mask = [t is not None for t in times]
                times = [t for t in times if t is not None]
                df = df[valid_times_mask].reset_index(drop=True)
                
                if not times:
                    continue
                
                processed_data = []
                for col in data_columns:
                    try:
                        col_date = pd.to_datetime(col).date()
                        if col_date >= today:
                            col_data = df[col]
                            averaged_data = []
                            for i in range(0, len(col_data), 4):
                                segment = col_data[i:i+4]
                                if not segment.isna().all():
                                    avg_val = segment.mean()
                                    averaged_data.append(truncate_to_two_decimal(avg_val))
                                else:
                                    averaged_data.append(None)
                            if any(pd.notna(averaged_data)):
                                row = [col_date] + averaged_data
                                processed_data.append(row)
                    except Exception as e:
                        continue
                
                if not processed_data:
                    continue
                
                time_points = [time(hour=i) for i in range(24)]
                columns = ['æ—¶é—´'] + [row[0] for row in processed_data]
                processed_df = pd.DataFrame(columns=columns)
                processed_df['æ—¶é—´'] = [t.strftime('%H:%M:%S') for t in time_points]
                
                for i, row in enumerate(processed_data):
                    col_name = row[0]
                    for j in range(min(24, len(row[1:]))):
                        processed_df.loc[j, col_name] = row[j+1]
                
                processed_df = processed_df.dropna(axis=1, how='all')
                processed_df.to_excel(writer, sheet_name=sheet_name, index=False)
                format_worksheet(writer.sheets[sheet_name])
    
    except Exception as e:
        pass
    
    output_io.seek(0)
    return output_io

def process_price_quantity_streamlit(price_quantity_file):
    """å¤„ç†ç”µä»·ç”µé‡æ•°æ®"""
    output_io = BytesIO()
    try:
        xls_input = pd.ExcelFile(price_quantity_file, engine='openpyxl')
        sheet_names = xls_input.sheet_names
        
        with pd.ExcelWriter(output_io, engine='openpyxl') as writer:
            for sheet_name in sheet_names:
                try:
                    df = xls_input.parse(sheet_name)
                except Exception as e:
                    continue
                
                if df.empty:
                    continue
                
                date_col = next((col for col in df.columns if 'æ—¥æœŸ' in str(col)), None)
                quantity_cols = [col for col in df.columns if 'ç”µé‡' in str(col)]
                price_cols = [col for col in df.columns if 'ç”µä»·' in str(col)]
                
                if not date_col or not quantity_cols:
                    continue
                
                dates = []
                quantity_data = []
                price_data = []
                for idx, row in df.iterrows():
                    try:
                        current_date = pd.to_datetime(row[date_col]).date()
                        dates.append(current_date)
                        quantities = [truncate_to_two_decimal(row[col]) for col in quantity_cols]
                        quantity_data.append(quantities)
                        prices = [truncate_to_two_decimal(row[col]) for col in price_cols]
                        price_data.append(prices)
                    except Exception as e:
                        continue
                
                if not dates or not quantity_data:
                    continue
                
                # ç”Ÿæˆæ•°æ®
                processed_data = []
                for i, (date, quantities, prices) in enumerate(zip(dates, quantity_data, price_data)):
                    row_data = [date] + quantities + prices
                    processed_data.append(row_data)
                
                output_cols = ['æ—¥æœŸ'] + quantity_cols + price_cols
                processed_df = pd.DataFrame(processed_data, columns=output_cols)
                processed_df.to_excel(writer, sheet_name=sheet_name, index=False)
                format_worksheet(writer.sheets[sheet_name])
    
    except Exception as e:
        pass
    
    output_io.seek(0)
    return output_io

def calculate_difference_streamlit(forecast_file, price_quantity_file):
    """è®¡ç®—å·®å€¼ï¼ˆä»…è¿”å›æ•°æ®å­—å…¸ï¼‰"""
    station_coefficient = {
        'é£å‚¨ä¸€æœŸ': 0.8*0.725*0.7 ,   
        'é£å‚¨äºŒæœŸ': 0.8*0.725*0.7,
        'æ —æºª': 0.8*0.725*0.7,
        'å³ªå±±ä¸€æœŸ': 0.8*0.725*0.7 ,
        'åœ£å¢ƒå±±': 0.8*0.725*0.7,
        'è¥„åŒ—å†œå…‰': 0.8*0.775*0.8,
        'æµ æ°´æ¸”å…‰': 0.8*0.775*0.8
    }
    
    # ç”¨äºå±•ç¤ºçš„æ•°æ®å­—å…¸ï¼š{åœºç«™å: æ•°æ®æ¡†}
    result_data = {}
    
    try:
        forecast_xls = pd.ExcelFile(forecast_file, engine='openpyxl')
        price_quantity_xls = pd.ExcelFile(price_quantity_file, engine='openpyxl')
        
        forecast_sheet_names = forecast_xls.sheet_names
        price_quantity_sheet_names = price_quantity_xls.sheet_names

        for sheet_name in forecast_sheet_names:
            if sheet_name == 'å¡«å†™è¯´æ˜':
                continue
            if sheet_name not in price_quantity_sheet_names:
                continue

            try:
                forecast_df = forecast_xls.parse(sheet_name)
                price_quantity_df = price_quantity_xls.parse(sheet_name)
            except Exception as e:
                continue

            if forecast_df.empty or len(forecast_df.columns) < 2:
                continue
            
            current_coeff = station_coefficient.get(sheet_name, 1.0)
            
            time_col = forecast_df.iloc[:, 0]
            forecast_cols = forecast_df.columns[1:]
            quantity_cols = [col for col in price_quantity_df.columns if 'ç”µé‡' in str(col)]
            price_cols = [col for col in price_quantity_df.columns if 'ç”µä»·' in str(col)]
            
            if not quantity_cols:
                continue
            quantity_col = quantity_cols[0]
            price_col = price_cols[0] if price_cols else None

            processed_data = []
            for idx, row in forecast_df.iterrows():
                if idx >= len(price_quantity_df):
                    continue

                current_time = row[0]
                row_data = [current_time]
                current_price = truncate_to_two_decimal(price_quantity_df.iloc[idx][price_col]) if (price_col and pd.notna(price_quantity_df.iloc[idx][price_col])) else None
                
                for col in forecast_cols:
                    forecast_val = row[col]
                    row_data.append(forecast_val)
                    
                    try:
                        quantity_val = price_quantity_df.iloc[idx][quantity_col]
                        if pd.notna(forecast_val) and pd.notna(quantity_val):
                            corrected_forecast = float(forecast_val) * current_coeff
                            diff_val = truncate_to_two_decimal(corrected_forecast - float(quantity_val))
                            
                            if diff_val < 0:
                                max_negative = -float(quantity_val)
                                diff_val = max(diff_val, max_negative)
                            
                            row_data.append(diff_val)
                        else:
                            row_data.append(None)
                    except Exception as e:
                        row_data.append(None)
                
                row_data.append(current_price)
                processed_data.append(row_data)

            new_cols = ['æ—¶é—´']
            for col in forecast_cols:
                new_cols.extend([col, f'{col} (ä¿®æ­£åå·®é¢)'])
            new_cols.append('å¯¹åº”æ—¶æ®µç”µä»·')
            
            processed_df = pd.DataFrame(processed_data, columns=new_cols)
            if 'å¯¹åº”æ—¶æ®µç”µä»·' in processed_df.columns:
                processed_df['å¯¹åº”æ—¶æ®µç”µä»·'] = processed_df['å¯¹åº”æ—¶æ®µç”µä»·'].apply(truncate_to_two_decimal)
            
            # ä¿å­˜åˆ°ç»“æœå­—å…¸
            result_data[sheet_name] = processed_df.copy()
    
    except Exception as e:
        st.error(f"è®¡ç®—å·®å€¼å‡ºé”™ï¼š{str(e)}")
    
    return result_data

# ---------------------- ä¸»é¡µé¢é€»è¾‘ï¼ˆå°è£…ä¸ºå±•å¼€å¼èœå•ï¼‰ ----------------------
def main():
    # ä¾§è¾¹æ ä¸»èœå•ï¼šè¿ç»­ç«ä»·è°ƒæ•´ï¼ˆå±•å¼€å¼ï¼‰
    with st.sidebar:
        st.title("ğŸ“‹ ç³»ç»ŸåŠŸèƒ½èœå•")
        
        # æ ¸å¿ƒï¼šè¿ç»­ç«ä»·è°ƒæ•´ å±•å¼€èœå•
        with st.expander("ğŸ”§ è¿ç»­ç«ä»·è°ƒæ•´", expanded=False):
            st.header("ğŸ“ æ–‡ä»¶ç®¡ç†")
            
            # 1. æ‰¹é‡ä¸Šä¼ æœˆåº¦åˆçº¦æ–‡ä»¶
            st.subheader("1. æ‰¹é‡ä¸Šä¼ æœˆåº¦åˆçº¦æ–‡ä»¶")
            new_contract_files = st.file_uploader(
                "é€‰æ‹©åˆçº¦æ–‡ä»¶ï¼ˆæ”¯æŒæ‰¹é‡ä¸Šä¼ ï¼‰",
                type=["xlsx", "xls"],
                accept_multiple_files=True,
                key="new_contract"
            )
            selected_month = st.text_input(
                "æ–‡ä»¶å¯¹åº”æœˆä»½ï¼ˆæ ¼å¼ï¼š2025-11ï¼‰",
                value=datetime.now().strftime("%Y-%m"),
                key="contract_month"
            )
            
            # æ‰¹é‡ä¿å­˜é€»è¾‘
            if st.button("ä¿å­˜æœˆåº¦æ–‡ä»¶", key="save_contract"):
                if not new_contract_files:
                    st.warning("âš ï¸ è¯·å…ˆé€‰æ‹©è¦ä¸Šä¼ çš„åˆçº¦æ–‡ä»¶ï¼")
                elif not selected_month:
                    st.warning("âš ï¸ è¯·è¾“å…¥å¯¹åº”çš„æœˆä»½ï¼ˆæ ¼å¼ï¼š2025-11ï¼‰ï¼")
                else:
                    with st.spinner("æ‰¹é‡ä¿å­˜æ–‡ä»¶ä¸­..."):
                        saved_files = []
                        failed_files = []
                        for file in new_contract_files:
                            try:
                                save_path = save_monthly_contract_file(file, selected_month)
                                saved_files.append(os.path.basename(save_path))
                            except Exception as e:
                                failed_files.append(f"{file.name} - {str(e)}")
                        
                        if saved_files:
                            st.success(f"âœ… æˆåŠŸä¿å­˜ {len(saved_files)} ä¸ªæ–‡ä»¶ï¼š")
                            for fname in saved_files:
                                st.write(f"  - {fname}")
                        if failed_files:
                            st.error(f"âŒ ä¿å­˜å¤±è´¥ {len(failed_files)} ä¸ªæ–‡ä»¶ï¼š")
                            for fname in failed_files:
                                st.write(f"  - {fname}")
            
            # 2. é€‰æ‹©å·²ä¸Šä¼ çš„æœˆä»½
            st.subheader("2. é€‰æ‹©åˆ†ææœˆä»½")
            uploaded_months = get_uploaded_months()
            if uploaded_months:
                selected_months = st.multiselect(
                    "å‹¾é€‰è¦åˆ†æçš„æœˆä»½",
                    options=uploaded_months,
                    default=uploaded_months,
                    key="selected_months"
                )
                # å±•ç¤ºæ¯ä¸ªæœˆä»½çš„æ–‡ä»¶æ•°é‡
                st.write("ğŸ“‹ å„æœˆä»½æ–‡ä»¶ç»Ÿè®¡ï¼š")
                for month in uploaded_months:
                    file_count = len(get_files_by_month(month))
                    st.write(f"  â€¢ {month}ï¼š{file_count} ä¸ªæ–‡ä»¶")
            else:
                selected_months = []
                st.info("æš‚æ— å·²ä¸Šä¼ çš„æœˆåº¦åˆçº¦æ–‡ä»¶ï¼Œè¯·å…ˆä¸Šä¼ ")
            
            # 3. ä¸Šä¼ åŠŸç‡é¢„æµ‹æ–‡ä»¶
            st.subheader("3. åŠŸç‡é¢„æµ‹æ–‡ä»¶")
            forecast_file = st.file_uploader(
                "ä¸Šä¼ åŠŸç‡é¢„æµ‹æ–‡ä»¶ï¼ˆ2025åŠŸç‡é¢„æµ‹.xlsxï¼‰",
                type=["xlsx", "xls"],
                key="forecast"
            )
            
            # æ˜ å°„é…ç½®ï¼ˆæŠ˜å å±•ç¤ºï¼‰
            with st.expander("âš™ï¸ äº¤æ˜“å•å…ƒæ˜ å°„é…ç½®", expanded=False):
                unit_to_station = {
                    "è¥„é˜³ååˆå³ªå±±æ³‰æ°´é£ç”µ": "å³ªå±±ä¸€æœŸ",
                    "è†é—¨ååˆåœ£å¢ƒå±±é£ç”µ": "åœ£å¢ƒå±±",
                    "è¥„é˜³èšåˆå…‰ä¼": "è¥„åŒ—å†œå…‰",
                    "ä¸‰ç‹ï¼ˆååˆè¥„åŒ—ï¼‰é£ç”µ": "é£å‚¨ä¸€æœŸ",
                    "è†é—¨ååˆæ —æºªé£ç”µ": "æ —æºª",
                    "è¥„å·ååˆä¸‰ç‹é£å…‰å‚¨èƒ½ç”µç«™é£ç”µäºŒæœŸ": "é£å‚¨äºŒæœŸ",
                    "æµ æ°´èšåˆå…³å£å…‰ä¼": "æµ æ°´æ¸”å…‰"
                }
                for k, v in unit_to_station.items():
                    st.write(f"â€¢ {k} â†’ {v}")
        
        # å…¶ä»–æ‰©å±•èœå•ï¼ˆé¢„ç•™ï¼‰
        st.divider()
        st.write("ğŸ“Œ å…¶ä»–åŠŸèƒ½æ¨¡å—ï¼ˆé¢„ç•™ï¼‰")
        # å¯æ·»åŠ æ›´å¤šå±•å¼€èœå•
        # with st.expander("ğŸ“Š æ•°æ®æŠ¥è¡¨", expanded=False):
        #     st.write("åç»­æ·»åŠ æŠ¥è¡¨åŠŸèƒ½")
        # with st.expander("ğŸ’¾ æ•°æ®å¯¼å‡º", expanded=False):
        #     st.write("åç»­æ·»åŠ å¯¼å‡ºåŠŸèƒ½")
    
    # ä¸»é¡µé¢å†…å®¹ï¼ˆä»…åœ¨é€‰æ‹©è¿ç»­ç«ä»·è°ƒæ•´åæ˜¾ç¤ºï¼‰
    st.title("ğŸ”§ è¿ç»­ç«ä»·è°ƒæ•´")
    st.divider()
    
    # è·å–ä¾§è¾¹æ çš„å˜é‡ï¼ˆé€šè¿‡keyè·å–ï¼‰
    selected_months = st.session_state.get("selected_months", [])
    forecast_file = st.session_state.get("forecast")
    
    # æ‰§è¡ŒæŒ‰é’®ï¼ˆç¦ç”¨æ¡ä»¶ï¼šæ— é€‰ä¸­æœˆä»½/æ— é¢„æµ‹æ–‡ä»¶ï¼‰
    run_disabled = not (selected_months and forecast_file)
    if st.button("å¼€å§‹æµ‹ç®—", type="primary", disabled=run_disabled):
        with st.spinner("æ­£åœ¨æµ‹ç®—æ•°æ®ï¼Œè¯·ç¨å€™..."):
            # åŠ è½½é€‰ä¸­æœˆä»½çš„åˆçº¦æ–‡ä»¶
            contract_files = load_contract_files(selected_months)
            
            # æ‰§è¡Œæ ¸å¿ƒå¤„ç†æµç¨‹
            unit_to_station = {
                "è¥„é˜³ååˆå³ªå±±æ³‰æ°´é£ç”µ": "å³ªå±±ä¸€æœŸ",
                "è†é—¨ååˆåœ£å¢ƒå±±é£ç”µ": "åœ£å¢ƒå±±",
                "è¥„é˜³èšåˆå…‰ä¼": "è¥„åŒ—å†œå…‰",
                "ä¸‰ç‹ï¼ˆååˆè¥„åŒ—ï¼‰é£ç”µ": "é£å‚¨ä¸€æœŸ",
                "è†é—¨ååˆæ —æºªé£ç”µ": "æ —æºª",
                "è¥„å·ååˆä¸‰ç‹é£å…‰å‚¨èƒ½ç”µç«™é£ç”µäºŒæœŸ": "é£å‚¨äºŒæœŸ",
                "æµ æ°´èšåˆå…³å£å…‰ä¼": "æµ æ°´æ¸”å…‰"
            }
            integrated_io = generate_integrated_file_streamlit(contract_files, unit_to_station)
            forecast_processed_io = process_power_forecast_streamlit(forecast_file)
            price_quantity_processed_io = process_price_quantity_streamlit(integrated_io)
            result_data = calculate_difference_streamlit(forecast_processed_io, integrated_io)
        
        # ä»…å±•ç¤ºæœ€ç»ˆæ±‡æ€»æ•°æ®
        st.divider()
        st.header("ğŸ“ˆ æœ€ç»ˆæ±‡æ€»æ•°æ®å±•ç¤º")
        if result_data:
            # æŒ‰åœºç«™åˆ†æ ‡ç­¾å±•ç¤º
            station_tabs = st.tabs(list(result_data.keys()))
            for tab, (station_name, df) in zip(station_tabs, result_data.items()):
                with tab:
                    st.subheader(f"ğŸ“ {station_name}")
                    # æ•°æ®å±•ç¤ºï¼ˆæ”¯æŒç­›é€‰/æ’åºï¼‰
                    st.dataframe(
                        df,
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            "æ—¶é—´": st.column_config.TextColumn("æ—¶æ®µ", width="small"),
                            "å¯¹åº”æ—¶æ®µç”µä»·": st.column_config.NumberColumn("ç”µä»·(å…ƒ)", format="%.2f"),
                        }
                    )
                    # å•åœºç«™æ•°æ®ä¸‹è½½
                    csv_data = df.to_csv(index=False, encoding="utf-8-sig")
                    st.download_button(
                        label=f"ğŸ“¥ ä¸‹è½½{station_name}æ•°æ®ï¼ˆCSVï¼‰",
                        data=csv_data,
                        file_name=f"{station_name}_è°ƒæ•´ç»“æœ.csv",
                        mime="text/csv"
                    )
        else:
            st.warning("æš‚æ— å¯å±•ç¤ºçš„ç»“æœæ•°æ®")
        
        st.success("âœ… æµ‹ç®—å®Œæˆï¼")
    
    # æç¤ºä¿¡æ¯
    if run_disabled:
        if not selected_months:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ ã€Œè¿ç»­ç«ä»·è°ƒæ•´ã€èœå•ä¸­ä¸Šä¼ å¹¶é€‰æ‹©è¦åˆ†æçš„æœˆåº¦åˆçº¦æ–‡ä»¶ï¼")
        elif not forecast_file:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ ã€Œè¿ç»­ç«ä»·è°ƒæ•´ã€èœå•ä¸­ä¸Šä¼ åŠŸç‡é¢„æµ‹æ–‡ä»¶ï¼")

if __name__ == "__main__":
    main()
