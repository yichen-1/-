import streamlit as st
import pandas as pd
import re
from datetime import datetime
import warnings
import pdfplumber
from io import BytesIO
import sys
import os

# å¿½ç•¥æ ·å¼è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl.stylesheet")

# ---------------------- æ ¸å¿ƒé…ç½®ï¼ˆæ–°å¢æ°´å°è¿‡æ»¤+æ‰©å±•ç§‘ç›®æ˜ å°„ï¼‰ ----------------------
# 1. å¸¸è§æ°´å°å…³é”®è¯ï¼ˆéœ€æ ¹æ®å®é™…PDFè¡¥å……ï¼‰
WATERMARK_KEYWORDS = ["ååˆèƒ½æº", "å¤§åº†æ™¶ç››", "å¤ªé˜³èƒ½å‘ç”µ", "å†…éƒ¨ä½¿ç”¨", "CONFIDENTIAL", "è‰ç¨¿"]
# 2. å®Œæ•´ç§‘ç›®æ˜ å°„ï¼ˆè¦†ç›–æ›´å¤šå¯èƒ½ç¼–ç ï¼‰
TRADE_CODE_MAP = {
    "0101010101": "ä¼˜å…ˆå‘ç”µäº¤æ˜“",
    "0101020101": "ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“", 
    "0101020301": "çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“",
    "0101040203": "é€ä¸Šæµ·çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“(ç”µèƒ½é‡)",
    "0101040301": "é€è¾½å®äº¤æ˜“",
    "0101040321": "é€ååŒ—äº¤æ˜“", 
    "0101040322": "é€å±±ä¸œäº¤æ˜“",
    "0101040330": "é€æµ™æ±Ÿäº¤æ˜“",
    "0102020101": "çœå†…ç°è´§æ—¥å‰äº¤æ˜“",
    "0102020301": "çœå†…ç°è´§å®æ—¶äº¤æ˜“",
    "0102010101": "çœé—´ç°è´§æ—¥å‰äº¤æ˜“",
    "0102010201": "çœé—´ç°è´§æ—¥å†…äº¤æ˜“",
    "0202030001": "ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨",
    "0202030002": "çœé—´çœå†…ä»·å·®è´¹ç”¨",
    "0101050101": "çœå†…ç»¿è‰²ç”µåŠ›äº¤æ˜“(ç”µèƒ½é‡)",
    "0101060101": "æ—¥èåˆäº¤æ˜“",
    "0101070101": "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´",
    "0101090101": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",
    "0101100101": "åå·®è€ƒæ ¸è´¹ç”¨",
    "0101030101": "å±…æ°‘å†œä¸šç”¨ç”µäº¤æ˜“"  # æ–°å¢å¯èƒ½ç§‘ç›®
}
# 3. ç§‘ç›®åç§°å…³é”®è¯åº“ï¼ˆç”¨äºæ¨¡ç³Šä¿®æ­£ï¼‰
TRADE_NAME_KEYWORDS = {
    "ä¼˜å…ˆå‘ç”µ": "ä¼˜å…ˆå‘ç”µäº¤æ˜“",
    "ä»£ç†è´­ç”µ": "ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“",
    "ç›´æ¥äº¤æ˜“": "çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“",
    "ç°è´§æ—¥å‰": "çœå†…ç°è´§æ—¥å‰äº¤æ˜“",
    "ç°è´§å®æ—¶": "çœå†…ç°è´§å®æ—¶äº¤æ˜“",
    "é˜»å¡è´¹ç”¨": "ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨",
    "ä»·å·®è´¹ç”¨": "çœé—´çœå†…ä»·å·®è´¹ç”¨",
    "è¾…åŠ©æœåŠ¡": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",
    "åå·®è€ƒæ ¸": "åå·®è€ƒæ ¸è´¹ç”¨"
}
# 4. ç‰¹æ®Šç§‘ç›®ï¼ˆä»…å«è´¹ç”¨ï¼‰
SPECIAL_TRADES = ["ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨", "çœé—´çœå†…ä»·å·®è´¹ç”¨", "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š", "åå·®è€ƒæ ¸è´¹ç”¨"]

# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆå…¨é“¾è·¯ä¼˜åŒ–ï¼‰ ----------------------
def remove_watermark(text):
    """ç¬¬ä¸€æ­¥ï¼šç§»é™¤æ°´å°å¹²æ‰°"""
    if not text:
        return ""
    # 1. ç§»é™¤æ°´å°å…³é”®è¯
    cleaned_text = text
    for keyword in WATERMARK_KEYWORDS:
        cleaned_text = cleaned_text.replace(keyword, "")
    # 2. ç§»é™¤è¿ç»­ç©ºç™½ç¬¦å’Œç‰¹æ®Šå­—ç¬¦
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text)  # å¤šä¸ªç©ºæ ¼è½¬å•ä¸ª
    cleaned_text = re.sub(r'[\x00-\x1F\x7F]', '', cleaned_text)  # æ§åˆ¶å­—ç¬¦
    return cleaned_text.strip()

def safe_convert_to_numeric(value):
    """ç¬¬äºŒæ­¥ï¼šå®‰å…¨è½¬æ¢æ•°å€¼ï¼ˆå¢åŠ æ•°æ®åˆç†æ€§æ ¡éªŒï¼‰"""
    if value is None or pd.isna(value) or value == '':
        return None
    
    # å…ˆç§»é™¤æ°´å°æ®‹ç•™
    val_str = remove_watermark(str(value)).strip()
    # æ’é™¤ç§‘ç›®ç¼–ç å’Œçº¯ç¬¦å·
    if re.match(r'^\d{9,10}$', val_str) or val_str in ['-', '.', '', 'â€”', 'â€”â€”']:
        return None
    
    try:
        # æ¸…ç†åƒåˆ†ä½ã€å…¨è§’ç¬¦å·
        cleaned = re.sub(r'[^\d.-]', '', val_str.replace('ï¼Œ', ',').replace('ã€‚', '.'))
        if not cleaned or cleaned in ['-', '.']:
            return None
        num = float(cleaned)
        # åˆç†æ€§æ ¡éªŒï¼ˆç¤ºä¾‹ï¼šç”µé‡ä¸ä¼šå°äº0ï¼Œç”µä»·ä¸ä¼šè¶…è¿‡10000å…ƒ/MWhï¼‰
        if 'ç”µé‡' in str(value) and num < 0:
            return None
        if 'ç”µä»·' in str(value) and (num < 0 or num > 10000):
            return None
        return num
    except (ValueError, TypeError):
        return None

def extract_clear_date(pdf_text):
    """ç¬¬ä¸‰æ­¥ï¼šç²¾å‡†æå–æ¸…åˆ†æ—¥æœŸï¼ˆè¦†ç›–æ‰€æœ‰å¸¸è§æ ¼å¼ï¼‰"""
    date_patterns = [
        r'æ¸…åˆ†æ—¥æœŸ[:ï¼š]\s*(\d{4}[å¹´/-]\d{1,2}[æœˆ/-]\d{1,2}[æ—¥]?)',  # æ¸…åˆ†æ—¥æœŸï¼š2026-01-01/2026å¹´01æœˆ01æ—¥
        r'ç»“ç®—æ—¥æœŸ[:ï¼š]\s*(\d{4}[å¹´/-]\d{1,2}[æœˆ/-]\d{1,2}[æ—¥]?)',  # ç»“ç®—æ—¥æœŸï¼š2026.01.01
        r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)\s*æ¸…åˆ†',  # 2026å¹´01æœˆ01æ—¥æ¸…åˆ†
        r'(\d{4}-\d{1,2}-\d{1,2})\s*ç°è´§æ—¥æ¸…åˆ†'  # 2026-01-01 ç°è´§æ—¥æ¸…åˆ†
    ]
    
    for pattern in date_patterns:
        match = re.search(pattern, pdf_text)
        if match:
            date_str = match.group(1)
            # ç»Ÿä¸€æ ¼å¼ä¸ºYYYY-MM-DD
            date_str = re.sub(r'[å¹´æœˆæ—¥]', '-', date_str).rstrip('-')
            # è¡¥å…¨ä¸¤ä½æ•°æœˆä»½/æ—¥æœŸ
            parts = date_str.split('-')
            if len(parts) == 3:
                year, month, day = parts
                return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
    return None

def extract_base_info(pdf_text):
    """ç¬¬å››æ­¥ï¼šæå–åŸºç¡€ä¿¡æ¯ï¼ˆå…¬å¸ã€æ—¥æœŸã€åˆè®¡ï¼‰"""
    # å…ˆå»æ°´å°
    clean_text = remove_watermark(pdf_text)
    lines = clean_text.split('\n')
    
    # 1. å…¬å¸åç§°ï¼ˆåŒ¹é…â€œæœ‰é™å…¬å¸â€ç»“å°¾ï¼‰
    company_name = "æœªçŸ¥å…¬å¸"
    for line in lines:
        if "å…¬å¸åç§°" in line:
            match = re.search(r'å…¬å¸åç§°[:ï¼š]\s*([^ï¼Œã€‚\n]+æœ‰é™å…¬å¸)', line)
            if match:
                company_name = match.group(1).strip()
                break
    
    # 2. æ¸…åˆ†æ—¥æœŸï¼ˆè°ƒç”¨ç²¾å‡†æå–å‡½æ•°ï¼‰
    date = extract_clear_date(clean_text)
    
    # 3. åˆè®¡/å°è®¡æ•°æ®ï¼ˆä¿ç•™â€œå°è®¡â€ï¼‰
    total_quantity = None  # æ€»ç”µé‡
    total_fee = None       # æ€»ç”µè´¹
    subtotal_quantity = None  # å°è®¡ç”µé‡
    subtotal_fee = None       # å°è®¡ç”µè´¹
    
    for line in lines:
        line_clean = remove_watermark(line).replace(' ', '').replace(',', '')
        # åŒ¹é…â€œå°è®¡â€ï¼ˆå½“æ—¥æ±‡æ€»ï¼‰
        if 'å°è®¡' in line_clean:
            qty_match = re.search(r'å°è®¡ç”µé‡[:ï¼š]([\d\.]+)|ç”µé‡å°è®¡[:ï¼š]([\d\.]+)', line_clean)
            fee_match = re.search(r'å°è®¡ç”µè´¹[:ï¼š]([\d\.]+)|ç”µè´¹å°è®¡[:ï¼š]([\d\.]+)', line_clean)
            if qty_match:
                subtotal_quantity = safe_convert_to_numeric(next(g for g in qty_match.groups() if g))
            if fee_match:
                subtotal_fee = safe_convert_to_numeric(next(g for g in fee_match.groups() if g))
        # åŒ¹é…â€œåˆè®¡â€ï¼ˆå…¨å±€æ±‡æ€»ï¼‰
        elif 'åˆè®¡' in line_clean and 'å°è®¡' not in line_clean:
            qty_match = re.search(r'åˆè®¡ç”µé‡[:ï¼š]([\d\.]+)|æ€»ç”µé‡[:ï¼š]([\d\.]+)', line_clean)
            fee_match = re.search(r'åˆè®¡ç”µè´¹[:ï¼š]([\d\.]+)|æ€»ç”µè´¹[:ï¼š]([\d\.]+)', line_clean)
            if qty_match:
                total_quantity = safe_convert_to_numeric(next(g for g in qty_match.groups() if g))
            if fee_match:
                total_fee = safe_convert_to_numeric(next(g for g in fee_match.groups() if g))
    
    # ä¼˜å…ˆç”¨â€œå°è®¡â€ï¼ˆå½“æ—¥æ±‡æ€»æ›´å…³é”®ï¼‰
    final_qty = subtotal_quantity if subtotal_quantity is not None else total_quantity
    final_fee = subtotal_fee if subtotal_fee is not None else total_fee
    
    return company_name, date, final_qty, final_fee, (subtotal_quantity is not None or total_quantity is not None)

def locate_table_columns(table_rows):
    """ç¬¬äº”æ­¥ï¼šç²¾å‡†å®šä½è¡¨æ ¼åˆ—ï¼ˆåŸºäºå®Œæ•´è¡¨å¤´æ–‡æœ¬ï¼‰"""
    # ç›®æ ‡åˆ—çš„å®Œæ•´å…³é”®è¯ï¼ˆéœ€ä¸PDFè¡¨å¤´å®Œå…¨åŒ¹é…ï¼‰
    target_columns = {
        "ç§‘ç›®ç¼–ç ": [],
        "ç§‘ç›®åç§°": [],
        "äº¤æ˜“ç”µé‡": [],  # åŒ¹é…â€œäº¤æ˜“ç”µé‡(å…†ç“¦æ—¶)â€â€œç”µé‡(MWh)â€
        "ç»“ç®—ç”µä»·": [],  # åŒ¹é…â€œç»“ç®—ç”µä»·(å…ƒ/å…†ç“¦æ—¶)â€â€œç”µä»·(å…ƒ)â€
        "ç»“ç®—ç”µè´¹": []   # åŒ¹é…â€œç»“ç®—ç”µè´¹(å…ƒ)â€â€œç”µè´¹(å…ƒ)â€
    }
    
    # éå†å‰3è¡Œè¡¨å¤´ï¼Œè®°å½•æ¯åˆ—çš„åŒ¹é…åº¦
    for row_idx, row in enumerate(table_rows[:3]):
        for col_idx, cell in enumerate(row):
            cell_clean = remove_watermark(str(cell)).lower().strip()
            # åŒ¹é…ç§‘ç›®ç¼–ç 
            if any(key in cell_clean for key in ["ç§‘ç›®ç¼–ç ", "ç¼–ç ", "code"]):
                target_columns["ç§‘ç›®ç¼–ç "].append((row_idx, col_idx, 1.0))
            # åŒ¹é…ç§‘ç›®åç§°
            elif any(key in cell_clean for key in ["ç§‘ç›®åç§°", "ç»“ç®—ç±»å‹", "åç§°", "type"]):
                target_columns["ç§‘ç›®åç§°"].append((row_idx, col_idx, 1.0))
            # åŒ¹é…äº¤æ˜“ç”µé‡ï¼ˆå¿…é¡»åŒ…å«â€œç”µé‡â€+å•ä½ï¼‰
            elif any(key in cell_clean for key in ["ç”µé‡", "mw", "å…†ç“¦æ—¶"]) and not "ä»·" in cell_clean:
                target_columns["äº¤æ˜“ç”µé‡"].append((row_idx, col_idx, 0.9))
            # åŒ¹é…ç»“ç®—ç”µä»·ï¼ˆå¿…é¡»åŒ…å«â€œä»·â€+å•ä½ï¼‰
            elif any(key in cell_clean for key in ["ç”µä»·", "å•ä»·", "price"]) and not "é‡" in cell_clean:
                target_columns["ç»“ç®—ç”µä»·"].append((row_idx, col_idx, 0.9))
            # åŒ¹é…ç»“ç®—ç”µè´¹ï¼ˆå¿…é¡»åŒ…å«â€œè´¹â€+å•ä½ï¼‰
            elif any(key in cell_clean for key in ["ç”µè´¹", "é‡‘é¢", "fee", "å…ƒ"]) and not "é‡" in cell_clean and not "ä»·" in cell_clean:
                target_columns["ç»“ç®—ç”µè´¹"].append((row_idx, col_idx, 0.9))
    
    # ç¡®å®šæœ€ç»ˆåˆ—ç´¢å¼•ï¼ˆå–åŒ¹é…åº¦æœ€é«˜çš„åˆ—ï¼Œé¿å…é‡å¤ï¼‰
    used_cols = set()
    final_cols = {}
    for col_name, matches in target_columns.items():
        if not matches:
            final_cols[col_name] = -1  # æœªæ‰¾åˆ°
            continue
        # æŒ‰è¡Œä¼˜å…ˆçº§ï¼ˆç¬¬1è¡Œè¡¨å¤´ > ç¬¬2è¡Œï¼‰æ’åº
        matches.sort(key=lambda x: (x[0], -x[2]))
        for row_idx, col_idx, score in matches:
            if col_idx not in used_cols:
                final_cols[col_name] = col_idx
                used_cols.add(col_idx)
                break
        else:
            final_cols[col_name] = -1
    
    return final_cols

def correct_trade_name(trade_name):
    """ç¬¬å…­æ­¥ï¼šä¿®æ­£ç§‘ç›®åç§°ï¼ˆæ°´å°æ±¡æŸ“åä¿®å¤ï¼‰"""
    if not trade_name:
        return "æœªçŸ¥ç§‘ç›®"
    # å…ˆå»æ°´å°
    clean_name = remove_watermark(trade_name).strip()
    # 1. æŒ‰å…³é”®è¯æ¨¡ç³ŠåŒ¹é…
    for keyword, correct_name in TRADE_NAME_KEYWORDS.items():
        if keyword in clean_name:
            return correct_name
    # 2. è‹¥ä»æœªçŸ¥ï¼Œè¿”å›æ¸…ç†åçš„åç§°
    return clean_name if clean_name else "æœªçŸ¥ç§‘ç›®"

def extract_trade_data_from_tables(tables, clear_date):
    """ç¬¬ä¸ƒæ­¥ï¼šæå–ç§‘ç›®æ•°æ®ï¼ˆä¿ç•™å°è®¡è¡Œï¼Œä¿®æ­£åç§°ï¼‰"""
    trade_records = []
    
    for table in tables:
        if len(table) < 4:  # è‡³å°‘è¡¨å¤´2è¡Œ+æ•°æ®1è¡Œ+å°è®¡1è¡Œ
            continue
        
        # ç¬¬ä¸€æ­¥ï¼šæ¸…ç†è¡¨æ ¼ï¼ˆå»æ°´å°ï¼‰
        clean_table = []
        for row in table:
            clean_row = [remove_watermark(str(cell)) for cell in row]
            if any(cell.strip() != '' for cell in clean_row):  # è·³è¿‡ç©ºè¡Œ
                clean_table.append(clean_row)
        if len(clean_table) < 4:
            continue
        
        # ç¬¬äºŒæ­¥ï¼šå®šä½åˆ—ç´¢å¼•
        final_cols = locate_table_columns(clean_table)
        code_col = final_cols["ç§‘ç›®ç¼–ç "]
        name_col = final_cols["ç§‘ç›®åç§°"]
        qty_col = final_cols["äº¤æ˜“ç”µé‡"]
        price_col = final_cols["ç»“ç®—ç”µä»·"]
        fee_col = final_cols["ç»“ç®—ç”µè´¹"]
        # æ ¸å¿ƒåˆ—å¿…é¡»å­˜åœ¨ï¼ˆç¼–ç /åç§° + ç”µé‡/ç”µè´¹ï¼‰
        if (code_col == -1 and name_col == -1) or (qty_col == -1 and fee_col == -1):
            continue
        
        # ç¬¬ä¸‰æ­¥ï¼šè§£ææ•°æ®è¡Œï¼ˆä¿ç•™å°è®¡ï¼Œè·³è¿‡åˆè®¡ï¼‰
        for row_idx, row in enumerate(clean_table):
            row_clean = [cell.strip() for cell in row]
            # è·³è¿‡è¡¨å¤´è¡Œï¼ˆå‰2è¡Œï¼‰
            if row_idx < 2:
                continue
            # è·³è¿‡å…¨å±€åˆè®¡è¡Œï¼ˆä¿ç•™å°è®¡è¡Œï¼‰
            if 'åˆè®¡' in ''.join(row_clean) and 'å°è®¡' not in ''.join(row_clean):
                continue
            
            # æå–åŸºç¡€ä¿¡æ¯
            trade_code = row[code_col].strip() if (code_col != -1 and code_col < len(row)) else ''
            raw_name = row[name_col].strip() if (name_col != -1 and name_col < len(row)) else ''
            # ä¿®æ­£ç§‘ç›®åç§°
            trade_name = TRADE_CODE_MAP.get(trade_code, correct_trade_name(raw_name))
            
            # æå–æ•°æ®ï¼ˆå¸¦åˆç†æ€§æ ¡éªŒï¼‰
            quantity = safe_convert_to_numeric(row[qty_col]) if (qty_col != -1 and qty_col < len(row)) else None
            price = safe_convert_to_numeric(row[price_col]) if (price_col != -1 and price_col < len(row)) else None
            fee = safe_convert_to_numeric(row[fee_col]) if (fee_col != -1 and fee_col < len(row)) else None
            
            # ç‰¹æ®Šç§‘ç›®å¤„ç†ï¼ˆä»…ä¿ç•™è´¹ç”¨ï¼‰
            if trade_name in SPECIAL_TRADES:
                quantity = None
                price = None
            
            # æ ‡è®°æ˜¯å¦ä¸ºå°è®¡è¡Œ
            is_subtotal = 'å°è®¡' in ''.join(row_clean)
            
            # æ–°å¢ï¼šæ•°æ®è¡Œå¿…é¡»å…³è”æ—¥æœŸ
            if not is_subtotal and (quantity is None and fee is None):
                continue  # éå°è®¡è¡Œæ— æ•°æ®åˆ™è·³è¿‡
            
            # æ·»åŠ åˆ°ç»“æœ
            trade_records.append({
                "ç§‘ç›®åç§°": trade_name,
                "æ˜¯å¦å°è®¡è¡Œ": is_subtotal,
                "ç”µé‡(å…†ç“¦æ—¶)": quantity if not is_subtotal else quantity,
                "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": price if not is_subtotal else None,  # å°è®¡è¡Œæ— ç”µä»·
                "ç”µè´¹(å…ƒ)": fee,
                "åŸå§‹ç§‘ç›®ç¼–ç ": trade_code,
                "åŸå§‹ç§‘ç›®åç§°": raw_name
            })
    
    return trade_records

def parse_pdf_file(file_obj, file_name):
    """ä¸»è§£æå‡½æ•°ï¼ˆæ•´åˆå…¨é“¾è·¯ä¼˜åŒ–ï¼‰"""
    try:
        # é‡ç½®æ–‡ä»¶æµ
        file_obj.seek(0)
        file_bytes = BytesIO(file_obj.read())
        file_bytes.seek(0)
        
        # æå–æ–‡æœ¬å’Œè¡¨æ ¼ï¼ˆå»æ°´å°ï¼‰
        all_text = ""
        all_tables = []
        with pdfplumber.open(file_bytes) as pdf:
            for page in pdf.pages:
                # æå–æ–‡æœ¬ï¼ˆå»æ°´å°ï¼‰
                text = page.extract_text() or ""
                all_text += remove_watermark(text) + "\n"
                # æå–è¡¨æ ¼ï¼ˆä¿ç•™åŸå§‹ç»“æ„ç”¨äºåˆ—å®šä½ï¼‰
                tables = page.extract_tables({
                    "vertical_strategy": "lines",  # æŒ‰è¡¨æ ¼çº¿å®šä½ï¼ˆç²¾å‡†åº¦æœ€é«˜ï¼‰
                    "horizontal_strategy": "lines",
                    "snap_tolerance": 2,  # ç¼©å°å¯¹é½å…¬å·®
                    "join_tolerance": 2,
                    "edge_min_length": 8  # è¿‡æ»¤çŸ­çº¿æ¡å¹²æ‰°
                })
                all_tables.extend(tables)
        
        # 1. æå–åŸºç¡€ä¿¡æ¯ï¼ˆå…¬å¸ã€æ—¥æœŸã€å°è®¡ï¼‰
        company_name, clear_date, total_qty, total_fee, has_subtotal = extract_base_info(all_text)
        # 2. æå–ç§‘ç›®æ•°æ®ï¼ˆå«å°è®¡è¡Œï¼‰
        trade_records = extract_trade_data_from_tables(all_tables, clear_date)
        # 3. è¡¥å……å°è®¡è¡Œï¼ˆè‹¥æœªæå–åˆ°ï¼Œæ‰‹åŠ¨æ·»åŠ ï¼‰
        if has_subtotal and not any(rec["æ˜¯å¦å°è®¡è¡Œ"] for rec in trade_records):
            trade_records.append({
                "ç§‘ç›®åç§°": "å½“æ—¥å°è®¡",
                "æ˜¯å¦å°è®¡è¡Œ": True,
                "ç”µé‡(å…†ç“¦æ—¶)": total_qty,
                "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
                "ç”µè´¹(å…ƒ)": total_fee,
                "åŸå§‹ç§‘ç›®ç¼–ç ": "SUBTOTAL",
                "åŸå§‹ç§‘ç›®åç§°": "å½“æ—¥å°è®¡"
            })
        
        # 4. è¡¥å……åœºç«™å’Œæ—¥æœŸä¿¡æ¯
        station_name = f"{company_name}ï¼ˆæ™¶ç››å…‰ä¼ç”µç«™ï¼‰" if "æ™¶ç››" in company_name else f"{company_name}ï¼ˆæœªçŸ¥åœºç«™ï¼‰"
        for record in trade_records:
            record["åœºç«™åç§°"] = station_name
            record["æ¸…åˆ†æ—¥æœŸ"] = clear_date
            # åˆ é™¤åŸå§‹å­—æ®µï¼ˆä»…ä¿ç•™æœ€ç»ˆç»“æœï¼‰
            record.pop("åŸå§‹ç§‘ç›®ç¼–ç ", None)
            record.pop("åŸå§‹ç§‘ç›®åç§°", None)
        
        return trade_records
    
    except Exception as e:
        st.error(f"PDFè§£æå¤±è´¥ï¼ˆ{file_name}ï¼‰: {str(e)}")
        return [{
            "åœºç«™åç§°": "æœªçŸ¥åœºç«™",
            "æ¸…åˆ†æ—¥æœŸ": None,
            "ç§‘ç›®åç§°": "è§£æå¤±è´¥",
            "æ˜¯å¦å°è®¡è¡Œ": False,
            "ç”µé‡(å…†ç“¦æ—¶)": None,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
            "ç”µè´¹(å…ƒ)": None
        }]

# ---------------------- Streamlit åº”ç”¨ï¼ˆé€‚é…ä¼˜åŒ–åé€»è¾‘ï¼‰ ----------------------
def main():
    st.set_page_config(page_title="æ—¥æ¸…åˆ†æ•°æ®æå–å·¥å…·ï¼ˆæ°´å°ä¼˜åŒ–ç‰ˆï¼‰", layout="wide")
    
    st.title("ğŸ“Š æ—¥æ¸…åˆ†ç»“ç®—å•æ•°æ®æå–å·¥å…·ï¼ˆæŠ—æ°´å°ç‰ˆï¼‰")
    st.markdown("**æ ¸å¿ƒåŠŸèƒ½ï¼šæ°´å°è¿‡æ»¤ | æ—¥æœŸç²¾å‡†æå– | å°è®¡è¡Œä¿ç•™ | æ•°æ®é”™ä½ä¿®å¤**")
    st.divider()
    
    # ä¸Šä¼ æ–‡ä»¶
    uploaded_files = st.file_uploader(
        "æ”¯æŒPDFæ ¼å¼ï¼ˆæ¨èå•æ–‡ä»¶ä¸Šä¼ ï¼Œé¿å…æ‰¹é‡å¹²æ‰°ï¼‰",
        type=['pdf'],
        accept_multiple_files=False  # å•æ–‡ä»¶ä¸Šä¼ æ›´ç¨³å®š
    )
    
    if uploaded_files and st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary"):
        st.divider()
        st.subheader("âš™ï¸ å¤„ç†è¿›åº¦")
        
        # å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆæ›´ç¨³å®šï¼‰
        file = uploaded_files
        st.write(f"æ­£åœ¨å¤„ç†ï¼š{file.name}")
        trade_records = parse_pdf_file(file, file.name)
        file.close()
        
        # è½¬æ¢ä¸ºDataFrameï¼ˆè°ƒæ•´åˆ—é¡ºåºï¼‰
        result_df = pd.DataFrame(trade_records)
        col_order = ["åœºç«™åç§°", "æ¸…åˆ†æ—¥æœŸ", "ç§‘ç›®åç§°", "æ˜¯å¦å°è®¡è¡Œ", "ç”µé‡(å…†ç“¦æ—¶)", "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)", "ç”µè´¹(å…ƒ)"]
        result_df = result_df[col_order]
        
        # æ˜¾ç¤ºç»“æœï¼ˆé«˜äº®å°è®¡è¡Œï¼‰
        st.subheader("ğŸ“ˆ æå–ç»“æœï¼ˆå°è®¡è¡Œå·²é«˜äº®ï¼‰")
        # é«˜äº®å°è®¡è¡Œ
        styled_df = result_df.style.apply(
            lambda row: ['background-color: #f0f8ff' if row["æ˜¯å¦å°è®¡è¡Œ"] else '' for _ in row],
            axis=1
        )
        st.dataframe(styled_df, use_container_width=True)
        
        # å…³é”®ä¿¡æ¯ç»Ÿè®¡
        subtotal_count = result_df[result_df["æ˜¯å¦å°è®¡è¡Œ"]].shape[0]
        valid_trade_count = result_df[~result_df["æ˜¯å¦å°è®¡è¡Œ"]].shape[0]
        st.info(f"**ç»Ÿè®¡ä¿¡æ¯ï¼š** å…±æå– {valid_trade_count} ä¸ªç§‘ç›® + {subtotal_count} ä¸ªå°è®¡è¡Œ | æ¸…åˆ†æ—¥æœŸï¼š{result_df['æ¸…åˆ†æ—¥æœŸ'].iloc[0] or 'æœªè¯†åˆ«'}")
        
        # æ•°æ®å®Œæ•´æ€§åˆ†æ
        data_cols = ["ç”µé‡(å…†ç“¦æ—¶)", "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)", "ç”µè´¹(å…ƒ)"]
        filled_cells = result_df[data_cols].notna().sum().sum()
        total_cells = len(result_df) * len(data_cols)
        st.info(f"**æ•°æ®å®Œæ•´æ€§ï¼š** æœ‰æ•ˆæ•°æ®å•å…ƒæ ¼ {filled_cells}/{total_cells} ({filled_cells/total_cells*100:.1f}%)")
        
        # ä¸‹è½½Excelï¼ˆä¿ç•™é«˜äº®æ ¼å¼ï¼‰
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            result_df.to_excel(writer, index=False, sheet_name="æ—¥æ¸…åˆ†æ•°æ®")
            # é«˜äº®å°è®¡è¡Œï¼ˆExcelä¸­ï¼‰
            worksheet = writer.sheets["æ—¥æ¸…åˆ†æ•°æ®"]
            for row_idx in range(2, len(result_df) + 2):  # ç¬¬1è¡Œæ˜¯è¡¨å¤´
                if result_df.iloc[row_idx - 2]["æ˜¯å¦å°è®¡è¡Œ"]:
                    for col_idx in range(1, len(col_order) + 1):
                        worksheet.cell(row=row_idx, column=col_idx).fill = pd.ExcelWriter._xlsx.styles.PatternFill(
                            start_color="F0F8FF", end_color="F0F8FF", fill_type="solid"
                        )
        output.seek(0)
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½Excelï¼ˆå°è®¡è¡Œé«˜äº®ï¼‰",
            data=output,
            file_name=f"æ—¥æ¸…åˆ†æ•°æ®_æŠ—æ°´å°ç‰ˆ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )
        
        st.success("âœ… å¤„ç†å®Œæˆï¼è‹¥ä»æœ‰æ•°æ®é—®é¢˜ï¼Œè¯·æ£€æŸ¥PDFæ°´å°æ˜¯å¦å·²æ·»åŠ åˆ°WATERMARK_KEYWORDSä¸­")
    
    else:
        st.info("ğŸ‘† è¯·ä¸Šä¼ å•ä¸ªPDFæ–‡ä»¶å¼€å§‹å¤„ç†ï¼ˆå»ºè®®å…ˆæ¸…ç†PDFæ°´å°å†ä¸Šä¼ ï¼‰")

if __name__ == "__main__":
    os.environ["PYTHONIOENCODING"] = "utf-8"
    main()
