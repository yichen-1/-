import streamlit as st
import pandas as pd
import re
from datetime import datetime
import warnings
import pdfplumber
from io import BytesIO
import sys
import os
from openpyxl.styles import PatternFill

warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl.stylesheet")

# ---------------------- æ ¸å¿ƒé…ç½®ï¼ˆ100%é€šç”¨åŒ–ï¼‰ ----------------------
# 1. é€šç”¨å†—ä½™æ–‡æœ¬å…³é”®è¯ï¼ˆæ— ä»»ä½•å•åœºç«™ä¸“å±å†…å®¹ï¼‰
REDUNDANT_KEYWORDS = [
    "å†…éƒ¨ä½¿ç”¨", "CONFIDENTIAL", "è‰ç¨¿", "ç°è´§è¯•ç»“ç®—æœŸé—´", "æ—¥æ¸…åˆ†å•",
    "å…¬å¸åç§°", "ç¼–å·ï¼š", "å•ä½ï¼š", "æ¸…åˆ†æ—¥æœŸ", "åˆè®¡ç”µé‡", "åˆè®¡ç”µè´¹",
    "æœºç»„", "è®¡é‡ç”µé‡", "ç”µèƒ½é‡ç”µè´¹", "ç§‘ç›®ç¼–ç ", "ç»“ç®—ç±»å‹", "å®¡æ‰¹ï¼š",
    "å®¡æ ¸ï¼š", "ç¼–åˆ¶ï¼š", "åŠ ç›–ç”µå­ç­¾ç« ", "dqjs"  # ç§»é™¤â€œå¤§åº†æ™¶ç››â€â€œååˆèƒ½æºâ€ç­‰ä¸“å±è¯
]
# 2. é€šç”¨ç§‘ç›®ç¼–ç -åç§°æ˜ å°„ï¼ˆè¦†ç›–å…¨ç±»å‹åœºç«™ï¼‰
TRADE_CODE_MAP = {
    "0101010101": "ä¼˜å…ˆå‘ç”µäº¤æ˜“",
    "0101020101": "ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“", 
    "0101020301": "çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“",
    "0101040203": "é€ä¸Šæµ·çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“(ç”µèƒ½é‡)",
    "0101040301": "é€è¾½å®äº¤æ˜“",
    "0101040321": "é€ååŒ—äº¤æ˜“", 
    "0101040322": "é€å±±ä¸œäº¤æ˜“",
    "0101040330": "é€æµ™æ±Ÿäº¤æ˜“",
    "0102020101": "çœå†…ç°è´§æ—¥å‰äº¤æ˜“",
    "0102020301": "çœå†…ç°è´§å®æ—¶äº¤æ˜“",
    "0102010101": "çœé—´ç°è´§æ—¥å‰äº¤æ˜“",
    "0102010201": "çœé—´ç°è´§æ—¥å†…äº¤æ˜“",
    "0202030001": "ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨",
    "0202030002": "çœé—´çœå†…ä»·å·®è´¹ç”¨",
    "0101070101": "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´",
    "0101090101": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",
    "0101100101": "åå·®è€ƒæ ¸è´¹ç”¨",
    "101070101": "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´",  # å…¼å®¹9ä½ç¼–ç 
    "101090101": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",
    "101100101": "åå·®è€ƒæ ¸è´¹ç”¨"
}
# 3. é€šç”¨æ•°æ®åˆç†æ€§è§„åˆ™ï¼ˆé€‚é…é£ç”µ/å…‰ä¼/å‚¨èƒ½ç­‰ï¼‰
DATA_RULES = {
    "ç”µé‡(å…†ç“¦æ—¶)": {"min": 0, "max": 5000},  # è¦†ç›–å¤§å‹é£ç”µåœºå•æ—¥ç”µé‡
    "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": {"min": 0, "max": 2000},
    "ç”µè´¹(å…ƒ)": {"min": 0, "max": 10000000}
}
# 4. åœºç«™ç±»å‹å…³é”®è¯ï¼ˆé€‚é…æ‰€æœ‰åœºç«™ï¼‰
STATION_TYPE_KEYWORDS = ["é£ç”µåœº", "å…‰ä¼ç”µç«™", "å‚¨èƒ½ç”µç«™", "ç”µç«™", "åœºç«™", "å‘ç”µåœº"]

# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆé€šç”¨åŒ–+æ— æ•ˆè¿‡æ»¤ï¼‰ ----------------------
def remove_redundant_text(text):
    """é€šç”¨å†—ä½™æ–‡æœ¬æ¸…ç†"""
    if not text:
        return ""
    cleaned = str(text).strip()
    for keyword in REDUNDANT_KEYWORDS:
        cleaned = cleaned.replace(keyword, "")
    cleaned = re.sub(r'\s+', ' ', cleaned)
    cleaned = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\.\-\: ]', '', cleaned)
    return cleaned.strip()

def safe_convert_to_numeric(value, data_type=""):
    """é€šç”¨æ•°å€¼è½¬æ¢"""
    if value is None or pd.isna(value) or value == '':
        return None
    
    val_str = remove_redundant_text(value)
    if re.match(r'^\d{10}$', val_str) or val_str in ['-', '.', '', 'â€”', 'â€”â€”']:
        return None
    
    try:
        cleaned = re.sub(r'[^\d.-]', '', val_str.replace('ï¼Œ', ',').replace('ã€‚', '.'))
        if not cleaned or cleaned in ['-', '.']:
            return None
        num = float(cleaned)
        if data_type in DATA_RULES:
            rule = DATA_RULES[data_type]
            if num < rule["min"] or num > rule["max"]:
                return None
        return num
    except (ValueError, TypeError):
        return None

def extract_general_info(pdf_text, file_name):
    """é€šç”¨åŸºç¡€ä¿¡æ¯æå–ï¼ˆé€‚é…æ‰€æœ‰åœºç«™ï¼‰"""
    clean_text = remove_redundant_text(pdf_text)
    lines = clean_text.split('\n')
    
    # 1. å…¬å¸åç§°ï¼ˆä»â€œå…¬å¸åç§°ï¼šXXXâ€æˆ–æ–‡ä»¶åæå–ï¼‰
    company_name = "æœªçŸ¥å‘ç”µå…¬å¸"
    company_match = re.search(r'å…¬å¸åç§°[:ï¼š]\s*([^ï¼Œã€‚\n]+å…¬å¸)', clean_text)
    if company_match:
        company_name = company_match.group(1).strip()
    else:
        # ä»æ–‡ä»¶åè¡¥å……ï¼ˆå¦‚â€œXXé£ç”µ_æ—¥æ¸…åˆ†å•.pdfâ€ï¼‰
        company_match = re.search(r'([^_]+å…¬å¸|[^_]+å‘ç”µ)', file_name)
        if company_match:
            company_name = company_match.group(1).strip()
    
    # 2. åœºç«™åç§°ï¼ˆåŠ¨æ€è¯†åˆ«â€œé£ç”µåœº/å…‰ä¼ç”µç«™â€ç­‰ï¼‰
    station_name = "æœªçŸ¥åœºç«™"
    for line in lines:
        for type_key in STATION_TYPE_KEYWORDS:
            if type_key in line:
                # åŒ¹é…â€œXXé£ç”µåœºâ€â€œXXå…‰ä¼ç”µç«™â€
                match = re.search(r'([^ï¼Œã€‚\n]+' + type_key + ')', line)
                if match:
                    station_name = match.group(1).strip()
                    break
        if station_name != "æœªçŸ¥åœºç«™":
            break
    # ä»æ–‡ä»¶åè¡¥å……ï¼ˆå¦‚â€œXXé£ç”µåœº_20260101.pdfâ€ï¼‰
    if station_name == "æœªçŸ¥åœºç«™":
        for type_key in STATION_TYPE_KEYWORDS:
            if type_key in file_name:
                match = re.search(r'([^_]+' + type_key + ')', file_name)
                if match:
                    station_name = match.group(1).strip()
                    break
    
    # 3. æ¸…åˆ†æ—¥æœŸï¼ˆå¤šæ ¼å¼å…¼å®¹ï¼‰
    date = None
    date_patterns = [
        r'æ¸…åˆ†æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        r'ç»“ç®—æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        r'æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        r'(\d{4}-\d{1,2}-\d{1,2})'  # ä»æ–‡æœ¬ä»»æ„ä½ç½®æå–æ—¥æœŸ
    ]
    for pattern in date_patterns:
        match = re.search(pattern, clean_text)
        if match:
            date_str = match.group(1).strip()
            if "å¹´" in date_str:
                date_str = date_str.replace("å¹´", "-").replace("æœˆ", "-").replace("æ—¥", "")
            date = date_str
            break
    # ä»æ–‡ä»¶åè¡¥å……ï¼ˆå¦‚â€œæ—¥æ¸…åˆ†å•_20260101.pdfâ€ï¼‰
    if not date:
        date_match = re.search(r'(\d{4}-\d{1,2}-\d{1,2}|\d{8})', file_name)
        if date_match:
            date_str = date_match.group(1)
            if len(date_str) == 8:
                date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
            else:
                date = date_str
    
    # 4. å°è®¡æ•°æ®ï¼ˆé€šç”¨åŒ¹é…ï¼‰
    subtotal_qty = None
    subtotal_fee = None
    subtotal_match = re.search(
        r'å°è®¡[:ï¼š]?\s*ç”µé‡[:ï¼š]?\s*([\d\.]+)\s*.*?ç”µä»·[:ï¼š]?\s*([\d\.]+)\s*.*?ç”µè´¹[:ï¼š]?\s*([\d\.]+)',
        clean_text, re.DOTALL
    )
    if subtotal_match:
        subtotal_qty = safe_convert_to_numeric(subtotal_match.group(1), "ç”µé‡(å…†ç“¦æ—¶)")
        subtotal_fee = safe_convert_to_numeric(subtotal_match.group(3), "ç”µè´¹(å…ƒ)")
    
    return company_name, station_name, date, subtotal_qty, subtotal_fee

def filter_valid_table_rows(table):
    """è¿‡æ»¤æ— æ•ˆè¡Œï¼ˆå‰”é™¤æ— æ„ä¹‰ç§‘ç›®ï¼‰"""
    valid_rows = []
    for row in table:
        row_clean = [remove_redundant_text(cell) for cell in row]
        row_str = ''.join(row_clean).replace(" ", "")
        
        # æ— æ•ˆè¡Œç‰¹å¾ï¼šæ— ç¼–ç ã€æ— ç§‘ç›®åã€æ— ä»»ä½•æ•°æ®
        has_code = any(re.match(r'^\d{9,10}$', cell.replace(" ", "")) for cell in row_clean)
        has_trade_name = any(len(cell) >= 4 for cell in row_clean if "ç§‘ç›®" not in cell and "ç±»å‹" not in cell)
        has_data = any(safe_convert_to_numeric(cell) is not None for cell in row_clean)
        is_empty = all(cell == '' for cell in row_clean)
        is_header = any(keyword in row_str for keyword in ["ç§‘ç›®ç¼–ç ", "ç»“ç®—ç±»å‹", "ç”µé‡", "ç”µä»·", "ç”µè´¹", "åˆè®¡"])
        
        # åªä¿ç•™æœ‰ç¼–ç /ç§‘ç›®å/æ•°æ®çš„è¡Œ
        if (has_code or has_trade_name or has_data) and not is_empty and not is_header:
            valid_rows.append(row_clean)
    return valid_rows

def get_trade_name(trade_code, trade_text):
    """é€šç”¨ç§‘ç›®åç§°åŒ¹é…"""
    if trade_code in TRADE_CODE_MAP:
        return TRADE_CODE_MAP[trade_code]
    # æŒ‰å…³é”®è¯æ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚â€œç°è´§ç»“ç®—â€â†’â€œç°è´§ç»“ç®—ä»·å·®è°ƒæ•´â€ï¼‰
    trade_keywords = {
        "ä¼˜å…ˆå‘ç”µ": "ä¼˜å…ˆå‘ç”µäº¤æ˜“",
        "ä»£ç†è´­ç”µ": "ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“",
        "ç›´æ¥äº¤æ˜“": "çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“",
        "ç°è´§æ—¥å‰": "çœå†…ç°è´§æ—¥å‰äº¤æ˜“",
        "ç°è´§å®æ—¶": "çœå†…ç°è´§å®æ—¶äº¤æ˜“",
        "é˜»å¡è´¹ç”¨": "ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨",
        "ä»·å·®è´¹ç”¨": "çœé—´çœå†…ä»·å·®è´¹ç”¨",
        "ç°è´§ç»“ç®—": "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´",
        "è¾…åŠ©æœåŠ¡": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",
        "åå·®è€ƒæ ¸": "åå·®è€ƒæ ¸è´¹ç”¨"
    }
    for key, name in trade_keywords.items():
        if key in trade_text:
            return name
    return "æœªè¯†åˆ«ç§‘ç›®"

def extract_valid_trade_data(table, company_name, station_name, date):
    """æå–æœ‰æ•ˆæ•°æ®ï¼ˆå‰”é™¤æ— æ•ˆæœªè¯†åˆ«ç§‘ç›®ï¼‰"""
    trade_records = []
    valid_rows = filter_valid_table_rows(table)
    if len(valid_rows) == 0:
        return trade_records
    
    # é€šç”¨åˆ—å®šä½ï¼ˆå…¼å®¹ä¸åŒè¡¨å¤´é¡ºåºï¼‰
    cols = {"code": -1, "name": -1, "qty": -1, "price": -1, "fee": -1}
    for header_row in valid_rows[:2]:
        for col_idx, cell in enumerate(header_row):
            cell_clean = remove_redundant_text(cell).lower()
            if "ç¼–ç " in cell_clean:
                cols["code"] = col_idx
            elif "ç±»å‹" in cell_clean or "åç§°" in cell_clean:
                cols["name"] = col_idx
            elif "ç”µé‡" in cell_clean and "ä»·" not in cell_clean:
                cols["qty"] = col_idx
            elif "ç”µä»·" in cell_clean or "å•ä»·" in cell_clean:
                cols["price"] = col_idx
            elif "ç”µè´¹" in cell_clean or "é‡‘é¢" in cell_clean:
                cols["fee"] = col_idx
        if all(v != -1 for v in cols.values()):
            break
    # å…œåº•ï¼šæŒ‰â€œç¼–ç â†’åç§°â†’ç”µé‡â†’ç”µä»·â†’ç”µè´¹â€å›ºå®šé¡ºåºï¼ˆé€šç”¨è¡¨æ ¼ç»“æ„ï¼‰
    if any(v == -1 for v in cols.values()) and len(valid_rows[0]) >= 5:
        cols = {"code": 0, "name": 1, "qty": 2, "price": 3, "fee": 4}
    
    # è§£ææ•°æ®ï¼ˆå‰”é™¤æ— æ•ˆæœªè¯†åˆ«ç§‘ç›®ï¼‰
    for row_idx, row in enumerate(valid_rows):
        if row_idx < 2 and ("ç¼–ç " in ''.join(row) or "ç±»å‹" in ''.join(row)):
            continue
        
        trade_code = row[cols["code"]].strip().replace(" ", "") if (cols["code"] < len(row)) else ""
        trade_text = row[cols["name"]].strip() if (cols["name"] < len(row)) else ""
        trade_name = get_trade_name(trade_code, trade_text)
        
        # æå–æ•°æ®
        quantity = safe_convert_to_numeric(row[cols["qty"]], "ç”µé‡(å…†ç“¦æ—¶)") if (cols["qty"] < len(row)) else None
        price = safe_convert_to_numeric(row[cols["price"]], "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)") if (cols["price"] < len(row)) else None
        fee = safe_convert_to_numeric(row[cols["fee"]], "ç”µè´¹(å…ƒ)") if (cols["fee"] < len(row)) else None
        
        # ç‰¹æ®Šç§‘ç›®å¤„ç†
        if trade_name in ["ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨", "çœé—´çœå†…ä»·å·®è´¹ç”¨", "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š", "åå·®è€ƒæ ¸è´¹ç”¨"]:
            quantity = None
            price = None
        
        # å…³é”®è¿‡æ»¤ï¼šå‰”é™¤â€œæœªè¯†åˆ«ç§‘ç›®â€ä¸”æ— ä»»ä½•æ•°æ®çš„è¡Œï¼ˆè§£å†³ç”¨æˆ·åé¦ˆçš„æ— æ•ˆç§‘ç›®ï¼‰
        if trade_name == "æœªè¯†åˆ«ç§‘ç›®" and quantity is None and fee is None:
            continue
        
        # æ ‡è®°æå–çŠ¶æ€
        extract_status = "æˆåŠŸ"
        if quantity is None and fee is None and trade_name not in ["ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨", "çœé—´çœå†…ä»·å·®è´¹ç”¨", "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š", "åå·®è€ƒæ ¸è´¹ç”¨"]:
            extract_status = "æ— æœ‰æ•ˆæ•°æ®"
        
        trade_records.append({
            "å…¬å¸åç§°": company_name,
            "åœºç«™åç§°": station_name,
            "æ¸…åˆ†æ—¥æœŸ": date,
            "ç§‘ç›®åç§°": trade_name,
            "åŸå§‹ç§‘ç›®ç¼–ç ": trade_code,
            "åŸå§‹ç§‘ç›®æ–‡æœ¬": trade_text,
            "æ˜¯å¦å°è®¡è¡Œ": False,
            "ç”µé‡(å…†ç“¦æ—¶)": quantity,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": price,
            "ç”µè´¹(å…ƒ)": fee,
            "æå–çŠ¶æ€": extract_status
        })
    
    return trade_records

# ---------------------- é€šç”¨PDFè§£æä¸»å‡½æ•° ----------------------
def parse_pdf_general(file_obj, file_name):
    try:
        file_obj.seek(0)
        file_bytes = BytesIO(file_obj.read())
        file_bytes.seek(0)
        
        all_text = ""
        all_tables = []
        with pdfplumber.open(file_bytes) as pdf:
            for page in pdf.pages:
                text = page.extract_text() or ""
                all_text += text + "\n"
                # é€šç”¨è¡¨æ ¼æå–ï¼ˆå…¼å®¹ä¸åŒPDFæ ¼å¼ï¼‰
                tables = page.extract_tables({
                    "vertical_strategy": "lines_strict",
                    "horizontal_strategy": "lines_strict",
                    "snap_tolerance": 1,
                    "join_tolerance": 1,
                    "edge_min_length": 3
                })
                all_tables.extend(tables)
        
        # æå–é€šç”¨åŸºç¡€ä¿¡æ¯
        company_name, station_name, date, subtotal_qty, subtotal_fee = extract_general_info(all_text, file_name)
        
        # æå–ç§‘ç›®æ•°æ®
        trade_records = []
        for table in all_tables:
            if len(table) < 2:
                continue
            table_data = extract_valid_trade_data(table, company_name, station_name, date)
            trade_records.extend(table_data)
        
        # è¡¥å……å°è®¡è¡Œ
        if (subtotal_qty is not None or subtotal_fee is not None) and len(trade_records) > 0:
            trade_records.append({
                "å…¬å¸åç§°": company_name,
                "åœºç«™åç§°": station_name,
                "æ¸…åˆ†æ—¥æœŸ": date,
                "ç§‘ç›®åç§°": "å½“æ—¥å°è®¡",
                "åŸå§‹ç§‘ç›®ç¼–ç ": "SUBTOTAL",
                "åŸå§‹ç§‘ç›®æ–‡æœ¬": "å½“æ—¥å°è®¡",
                "æ˜¯å¦å°è®¡è¡Œ": True,
                "ç”µé‡(å…†ç“¦æ—¶)": subtotal_qty,
                "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
                "ç”µè´¹(å…ƒ)": subtotal_fee,
                "æå–çŠ¶æ€": "æˆåŠŸ"
            })
        
        # å»é‡
        unique_records = []
        seen_keys = set()
        for rec in trade_records:
            key = f"{rec['åœºç«™åç§°']}_{rec['ç§‘ç›®åç§°']}_{rec['åŸå§‹ç§‘ç›®ç¼–ç ']}"
            if key not in seen_keys:
                seen_keys.add(key)
                unique_records.append(rec)
        
        return unique_records if len(unique_records) > 0 else [{
            "å…¬å¸åç§°": "æœªçŸ¥å‘ç”µå…¬å¸",
            "åœºç«™åç§°": "æœªçŸ¥åœºç«™",
            "æ¸…åˆ†æ—¥æœŸ": None,
            "ç§‘ç›®åç§°": "è§£æå¤±è´¥",
            "åŸå§‹ç§‘ç›®ç¼–ç ": "",
            "åŸå§‹ç§‘ç›®æ–‡æœ¬": "",
            "æ˜¯å¦å°è®¡è¡Œ": False,
            "ç”µé‡(å…†ç“¦æ—¶)": None,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
            "ç”µè´¹(å…ƒ)": None,
            "æå–çŠ¶æ€": "è§£æé”™è¯¯"
        }]
    
    except Exception as e:
        st.error(f"PDFè§£æé”™è¯¯: {str(e)}")
        return [{
            "å…¬å¸åç§°": "æœªçŸ¥å‘ç”µå…¬å¸",
            "åœºç«™åç§°": "æœªçŸ¥åœºç«™",
            "æ¸…åˆ†æ—¥æœŸ": None,
            "ç§‘ç›®åç§°": "è§£æå¤±è´¥",
            "åŸå§‹ç§‘ç›®ç¼–ç ": "",
            "åŸå§‹ç§‘ç›®æ–‡æœ¬": "",
            "æ˜¯å¦å°è®¡è¡Œ": False,
            "ç”µé‡(å…†ç“¦æ—¶)": None,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
            "ç”µè´¹(å…ƒ)": None,
            "æå–çŠ¶æ€": "è§£æé”™è¯¯"
        }]

# ---------------------- é€šç”¨Streamlitåº”ç”¨ ----------------------
def main():
    st.set_page_config(page_title="é€šç”¨æ—¥æ¸…åˆ†æ•°æ®æå–å·¥å…·", layout="wide")
    
    st.title("ğŸ“Š é€šç”¨ç°è´§æ—¥æ¸…åˆ†ç»“ç®—å•æ•°æ®æå–å·¥å…·")
    st.markdown("**é€‚é…åœºæ™¯ï¼šé£ç”µåœºã€å…‰ä¼ç”µç«™ã€å‚¨èƒ½ç”µç«™ç­‰æ‰€æœ‰å‘ç”µåœºç«™ | è‡ªåŠ¨å‰”é™¤æ— æ•ˆç§‘ç›®**")
    st.divider()
    
    # æ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ ï¼ˆä¸åŒåœºç«™ï¼‰
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ PDFæ–‡ä»¶ï¼ˆæ”¯æŒå¤šåœºç«™æ‰¹é‡ä¸Šä¼ ï¼‰",
        type=["pdf"],
        accept_multiple_files=True
    )
    
    if uploaded_files and st.button("ğŸš€ å¼€å§‹æ‰¹é‡æå–", type="primary"):
        st.divider()
        st.subheader("âš™ï¸ å¤„ç†è¿›åº¦")
        
        all_results = []
        progress_bar = st.progress(0)
        
        for idx, file in enumerate(uploaded_files):
            st.write(f"æ­£åœ¨å¤„ç†ï¼š{file.name}")
            file_results = parse_pdf_general(file, file.name)
            all_results.extend(file_results)
            progress_bar.progress((idx + 1) / len(uploaded_files))
            file.close()
        
        progress_bar.empty()
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(all_results).fillna("")
        col_order = [
            "å…¬å¸åç§°", "åœºç«™åç§°", "æ¸…åˆ†æ—¥æœŸ", "ç§‘ç›®åç§°", 
            "åŸå§‹ç§‘ç›®ç¼–ç ", "åŸå§‹ç§‘ç›®æ–‡æœ¬", "æ˜¯å¦å°è®¡è¡Œ",
            "ç”µé‡(å…†ç“¦æ—¶)", "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)", "ç”µè´¹(å…ƒ)", "æå–çŠ¶æ€"
        ]
        df = df[col_order]
        
        # æ˜¾ç¤ºç»“æœï¼ˆé«˜äº®å°è®¡è¡Œï¼‰
        st.subheader("ğŸ“ˆ æ‰¹é‡æå–ç»“æœ")
        styled_df = df.style.apply(
            lambda row: ["background-color: #e6f3ff" if row["æ˜¯å¦å°è®¡è¡Œ"] else "" for _ in row],
            axis=1
        )
        st.dataframe(styled_df, use_container_width=True)
        
        # é€šç”¨ç»Ÿè®¡
        total_stations = df["åœºç«™åç§°"].nunique()
        total_trades = len(df[df["æ˜¯å¦å°è®¡è¡Œ"] == False])
        success_count = len(df[df["æå–çŠ¶æ€"] == "æˆåŠŸ"])
        st.info(f"**ç»Ÿè®¡ï¼š** è¦†ç›–åœºç«™ {total_stations} ä¸ª | æœ‰æ•ˆç§‘ç›® {total_trades} ä¸ª | æˆåŠŸæå– {success_count} ä¸ª")
        
        # ä¸‹è½½é€šç”¨Excel
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="å¤šåœºç«™æ—¥æ¸…åˆ†æ•°æ®")
            # é«˜äº®å°è®¡è¡Œ
            ws = writer.sheets["å¤šåœºç«™æ—¥æ¸…åˆ†æ•°æ®"]
            light_blue = PatternFill(start_color="E6F3FF", end_color="E6F3FF", fill_type="solid")
            for row in range(2, len(df) + 2):
                if df.iloc[row-2]["æ˜¯å¦å°è®¡è¡Œ"]:
                    for col in range(1, len(col_order) + 1):
                        ws.cell(row=row, column=col).fill = light_blue
        
        output.seek(0)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å¤šåœºç«™Excel",
            data=output,
            file_name=f"å¤šåœºç«™æ—¥æ¸…åˆ†æ•°æ®_{datetime.now().strftime('%Y%m%d%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )
        
        st.success("âœ… æ‰¹é‡æå–å®Œæˆï¼æ— æ•ˆæœªè¯†åˆ«ç§‘ç›®å·²è‡ªåŠ¨å‰”é™¤")
    
    else:
        st.info("ğŸ‘† è¯·ä¸Šä¼ ä»»æ„åœºç«™çš„ç°è´§æ—¥æ¸…åˆ†ç»“ç®—å•PDFï¼ˆæ”¯æŒæ‰¹é‡ï¼‰")

if __name__ == "__main__":
    os.environ["PYTHONIOENCODING"] = "utf-8"
    main()
