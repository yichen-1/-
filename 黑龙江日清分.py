import streamlit as st
import pandas as pd
import re
from datetime import datetime
import warnings
import pdfplumber
from io import BytesIO
import sys
import os
from openpyxl.styles import PatternFill

warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl.stylesheet")

# ---------------------- æ ¸å¿ƒé…ç½®ï¼ˆç²¾å‡†åŒ¹é…PDFå›ºå®šæ ¼å¼ï¼‰ ----------------------
# 1. æ°´å°+å†—ä½™æ–‡æœ¬å…³é”®è¯ï¼ˆè¦†ç›–PDFä¸­æ‰€æœ‰éè¡¨æ ¼æ–‡æœ¬ï¼‰
REDUNDANT_KEYWORDS = [
    "ååˆèƒ½æº", "å¤§åº†æ™¶ç››", "å¤ªé˜³èƒ½å‘ç”µ", "å†…éƒ¨ä½¿ç”¨", "CONFIDENTIAL", "è‰ç¨¿",
    "ç°è´§è¯•ç»“ç®—æœŸé—´", "æ—¥æ¸…åˆ†å•", "å…¬å¸åç§°", "ç¼–å·ï¼š", "å•ä½ï¼š", "æ¸…åˆ†æ—¥æœŸ",
    "åˆè®¡ç”µé‡", "åˆè®¡ç”µè´¹", "æœºç»„", "è®¡é‡ç”µé‡", "ç”µèƒ½é‡ç”µè´¹", "ç§‘ç›®ç¼–ç ", "ç»“ç®—ç±»å‹",
    "å®¡æ‰¹ï¼š", "å®¡æ ¸ï¼š", "ç¼–åˆ¶ï¼š", "åŠ ç›–ç”µå­ç­¾ç« ", "dqjs2627800", "2026å¹´1æœˆ"
]
# 2. ç§‘ç›®ç¼–ç -åç§°æ˜ å°„ï¼ˆä¸PDFå®Œå…¨ä¸€è‡´ï¼‰
TRADE_CODE_MAP = {
    "0101010101": "ä¼˜å…ˆå‘ç”µäº¤æ˜“",
    "0101020101": "ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“", 
    "0101020301": "çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“",
    "0101040203": "é€ä¸Šæµ·çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“(ç”µèƒ½é‡)",
    "0101040301": "é€è¾½å®äº¤æ˜“",
    "0101040321": "é€ååŒ—äº¤æ˜“", 
    "0101040322": "é€å±±ä¸œäº¤æ˜“",
    "0101040330": "é€æµ™æ±Ÿäº¤æ˜“",
    "0102020101": "çœå†…ç°è´§æ—¥å‰äº¤æ˜“",
    "0102020301": "çœå†…ç°è´§å®æ—¶äº¤æ˜“",
    "0102010101": "çœé—´ç°è´§æ—¥å‰äº¤æ˜“",
    "0102010201": "çœé—´ç°è´§æ—¥å†…äº¤æ˜“",
    "0202030001": "ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨",
    "0202030002": "çœé—´çœå†…ä»·å·®è´¹ç”¨"
}
# 3. æ•°æ®åˆç†æ€§è§„åˆ™ï¼ˆæŒ‰å…‰ä¼ç”µç«™å•æ—¥æ•°æ®è®¾å®šï¼‰
DATA_RULES = {
    "ç”µé‡(å…†ç“¦æ—¶)": {"min": 0, "max": 1000},  # å•æ—¥å‘ç”µé‡ä¸ä¼šè¶…1000MWh
    "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": {"min": 0, "max": 500},  # ç”µä»·ä¸ä¼šè¶…500å…ƒ/MWh
    "ç”µè´¹(å…ƒ)": {"min": 0, "max": 1000000}    # å•æ—¥ç”µè´¹ä¸ä¼šè¶…100ä¸‡
}

# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆå…¨é“¾è·¯å‡€åŒ–ï¼‰ ----------------------
def remove_redundant_text(text):
    """ç¬¬ä¸€æ­¥ï¼šå½»åº•ç§»é™¤å†—ä½™æ–‡æœ¬ï¼ˆæ°´å°ã€é¡µçœ‰ã€é¡µè„šï¼‰"""
    if not text:
        return ""
    cleaned = str(text).strip()
    # 1. ç§»é™¤å†—ä½™å…³é”®è¯
    for keyword in REDUNDANT_KEYWORDS:
        cleaned = cleaned.replace(keyword, "")
    # 2. ç§»é™¤è¿ç»­ç©ºç™½ç¬¦å’Œä¹±ç 
    cleaned = re.sub(r'\s+', ' ', cleaned)
    cleaned = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\.\-\: ]', '', cleaned)  # ä¿ç•™ä¸­æ–‡ã€æ•°å­—ã€åŸºç¡€ç¬¦å·
    return cleaned.strip()

def safe_convert_to_numeric(value, data_type=""):
    """ç¬¬äºŒæ­¥ï¼šå®‰å…¨è½¬æ¢+æ•°æ®åˆç†æ€§æ ¡éªŒ"""
    if value is None or pd.isna(value) or value == '':
        return None
    
    val_str = remove_redundant_text(value)
    # æ’é™¤ç§‘ç›®ç¼–ç å’Œçº¯ç¬¦å·
    if re.match(r'^\d{9,10}$', val_str) or val_str in ['-', '.', '', 'â€”', 'â€”â€”']:
        return None
    
    try:
        cleaned = re.sub(r'[^\d.-]', '', val_str.replace('ï¼Œ', ',').replace('ã€‚', '.'))
        if not cleaned or cleaned in ['-', '.']:
            return None
        num = float(cleaned)
        
        # æŒ‰æ•°æ®ç±»å‹æ ¡éªŒåˆç†æ€§
        if data_type in DATA_RULES:
            rule = DATA_RULES[data_type]
            if num < rule["min"] or num > rule["max"]:
                return None  # è¿‡æ»¤å¼‚å¸¸å€¼ï¼ˆå¦‚7.8E13ï¼‰
        return num
    except (ValueError, TypeError):
        return None

def extract_fixed_info(pdf_text):
    """ç¬¬ä¸‰æ­¥ï¼šä»PDFå›ºå®šä½ç½®æå–åŸºç¡€ä¿¡æ¯ï¼ˆé¿å…è¡¨æ ¼æ±¡æŸ“ï¼‰"""
    # 1. å…¬å¸åç§°ï¼ˆåŒ¹é…â€œå…¬å¸åç§°ï¼šXXXæœ‰é™å…¬å¸â€ï¼‰
    company_match = re.search(r'å…¬å¸åç§°[:ï¼š]\s*([^ï¼Œã€‚\n]+æœ‰é™å…¬å¸)', pdf_text)
    company_name = company_match.group(1).strip() if company_match else "å¤§åº†æ™¶ç››å¤ªé˜³èƒ½å‘ç”µæœ‰é™å…¬å¸"
    
    # 2. åœºç«™åç§°ï¼ˆå›ºå®šä¸ºâ€œæ™¶ç››å…‰ä¼ç”µç«™â€ï¼ŒPDFä¸­æ˜ç¡®æ ‡æ³¨ï¼‰
    station_name = f"{company_name}ï¼ˆæ™¶ç››å…‰ä¼ç”µç«™ï¼‰"
    
    # 3. æ¸…åˆ†æ—¥æœŸï¼ˆåŒ¹é…â€œæ¸…åˆ†æ—¥æœŸï¼š2026-01-01â€ï¼‰
    date_match = re.search(r'æ¸…åˆ†æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2})', pdf_text)
    clear_date = date_match.group(1).strip() if date_match else "2026-01-01"
    
    # 4. å°è®¡æ•°æ®ï¼ˆä»â€œå°è®¡â€è¡Œæå–ï¼ŒåŒ¹é…â€œå°è®¡ 445.245 80.54 35862.18â€ï¼‰
    subtotal_match = re.search(r'å°è®¡\s+([\d\.]+)\s+([\d\.]+)\s+([\d\.]+)', pdf_text)
    subtotal_qty = safe_convert_to_numeric(subtotal_match.group(1), "ç”µé‡(å…†ç“¦æ—¶)") if subtotal_match else None
    subtotal_fee = safe_convert_to_numeric(subtotal_match.group(3), "ç”µè´¹(å…ƒ)") if subtotal_match else None
    
    return station_name, clear_date, subtotal_qty, subtotal_fee

def filter_valid_table_rows(table):
    """ç¬¬å››æ­¥ï¼šè¿‡æ»¤è¡¨æ ¼ä¸­çš„æ— æ•ˆè¡Œï¼ˆåªä¿ç•™å«ç§‘ç›®ç¼–ç /æœ‰æ•ˆæ•°æ®çš„è¡Œï¼‰"""
    valid_rows = []
    for row in table:
        row_clean = [remove_redundant_text(cell) for cell in row]
        row_str = ''.join(row_clean)
        
        # ä¿ç•™æ¡ä»¶ï¼š1. å«10ä½ç§‘ç›®ç¼–ç ï¼›2. å«ç»“ç®—ç±»å‹å…³é”®è¯ï¼›3. éç©ºä¸”éè¡¨å¤´
        has_code = any(re.match(r'^\d{10}$', cell) for cell in row_clean)
        has_trade = any(trade in row_str for trade in TRADE_CODE_MAP.values())
        is_empty = all(cell == '' for cell in row_clean)
        is_header = any(keyword in row_str for keyword in ["ç§‘ç›®ç¼–ç ", "ç»“ç®—ç±»å‹", "ç”µé‡", "ç”µä»·", "ç”µè´¹"])
        
        if (has_code or has_trade) and not is_empty and not is_header:
            valid_rows.append(row_clean)
    return valid_rows

def locate_exact_columns(table_rows):
    """ç¬¬äº”æ­¥ï¼šç²¾å‡†å®šä½åˆ—ï¼ˆåŸºäºPDFå®é™…è¡¨å¤´é¡ºåºï¼šç¼–ç â†’ç±»å‹â†’ç”µé‡â†’ç”µä»·â†’ç”µè´¹ï¼‰"""
    # PDFè¡¨å¤´å›ºå®šé¡ºåºï¼šç§‘ç›®ç¼–ç  | ç»“ç®—ç±»å‹ | ç”µé‡ | ç”µä»· | ç”µè´¹
    final_cols = {"code": -1, "name": -1, "qty": -1, "price": -1, "fee": -1}
    
    # åªä»ç¬¬ä¸€è¡Œè¡¨å¤´åŒ¹é…
    if len(table_rows) == 0:
        return final_cols
    
    header_row = table_rows[0]
    for col_idx, cell in enumerate(header_row):
        cell_clean = remove_redundant_text(cell).lower()
        if "ç¼–ç " in cell_clean:
            final_cols["code"] = col_idx
        elif "ç±»å‹" in cell_clean or "åç§°" in cell_clean:
            final_cols["name"] = col_idx
        elif "ç”µé‡" in cell_clean and "ä»·" not in cell_clean:
            final_cols["qty"] = col_idx
        elif "ç”µä»·" in cell_clean or "å•ä»·" in cell_clean:
            final_cols["price"] = col_idx
        elif "ç”µè´¹" in cell_clean or "é‡‘é¢" in cell_clean:
            final_cols["fee"] = col_idx
    
    # å…œåº•ï¼šè‹¥æœªåŒ¹é…åˆ°ï¼ŒæŒ‰å›ºå®šé¡ºåºèµ‹å€¼ï¼ˆPDFè¡¨æ ¼åˆ—é¡ºåºå›ºå®šï¼‰
    if final_cols["code"] == -1 and len(header_row) >= 5:
        final_cols = {"code": 0, "name": 1, "qty": 2, "price": 3, "fee": 4}
    
    return final_cols

def extract_valid_trade_data(table, station_name, clear_date):
    """ç¬¬å…­æ­¥ï¼šæå–æœ‰æ•ˆç§‘ç›®æ•°æ®ï¼ˆä¸¥æ ¼åŒ¹é…ç¼–ç +æ•°æ®è§„åˆ™ï¼‰"""
    trade_records = []
    valid_rows = filter_valid_table_rows(table)
    if len(valid_rows) == 0:
        return trade_records
    
    # å®šä½åˆ—ï¼ˆç”¨è¿‡æ»¤åçš„è¡¨å¤´è¡Œï¼‰
    cols = locate_exact_columns([valid_rows[0]])  # ç¬¬ä¸€è¡Œä¸ºè¡¨å¤´
    if cols["code"] == -1:
        return trade_records
    
    # è§£ææ•°æ®è¡Œï¼ˆä»ç¬¬äºŒè¡Œå¼€å§‹ï¼‰
    for row in valid_rows[1:]:
        # æå–ç§‘ç›®ç¼–ç å’Œåç§°
        trade_code = row[cols["code"]].strip() if cols["code"] < len(row) else ""
        trade_name = TRADE_CODE_MAP.get(trade_code, "æœªçŸ¥ç§‘ç›®")
        if trade_name == "æœªçŸ¥ç§‘ç›®":
            continue
        
        # æå–æ•°æ®ï¼ˆæŒ‰ç±»å‹æ ¡éªŒï¼‰
        quantity = safe_convert_to_numeric(row[cols["qty"]], "ç”µé‡(å…†ç“¦æ—¶)") if (cols["qty"] < len(row)) else None
        price = safe_convert_to_numeric(row[cols["price"]], "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)") if (cols["price"] < len(row)) else None
        fee = safe_convert_to_numeric(row[cols["fee"]], "ç”µè´¹(å…ƒ)") if (cols["fee"] < len(row)) else None
        
        # å¸¸è§„ç§‘ç›®å¿…é¡»æœ‰ç”µé‡/ç”µä»·ï¼ˆæ’é™¤ç‰¹æ®Šç§‘ç›®ï¼‰
        is_regular = trade_name not in ["ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨", "çœé—´çœå†…ä»·å·®è´¹ç”¨"]
        if is_regular and (quantity is None or quantity == 0):
            continue
        
        # æ–°å¢è®°å½•
        trade_records.append({
            "åœºç«™åç§°": station_name,
            "æ¸…åˆ†æ—¥æœŸ": clear_date,
            "ç§‘ç›®åç§°": trade_name,
            "æ˜¯å¦å°è®¡è¡Œ": False,
            "ç”µé‡(å…†ç“¦æ—¶)": quantity,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": price,
            "ç”µè´¹(å…ƒ)": fee
        })
    
    return trade_records

# ---------------------- PDFè§£æä¸»å‡½æ•° ----------------------
def parse_pdf_final(file_obj):
    try:
        file_obj.seek(0)
        file_bytes = BytesIO(file_obj.read())
        file_bytes.seek(0)
        
        # 1. æå–PDFå…¨æ–‡å’Œè¡¨æ ¼
        all_text = ""
        all_tables = []
        with pdfplumber.open(file_bytes) as pdf:
            for page in pdf.pages:
                # æå–å…¨æ–‡ï¼ˆç”¨äºå›ºå®šä¿¡æ¯æå–ï¼‰
                text = page.extract_text() or ""
                all_text += text + "\n"
                # æå–è¡¨æ ¼ï¼ˆæŒ‰çº¿æ¡å®šä½ï¼Œé¿å…æ–‡æœ¬å¹²æ‰°ï¼‰
                tables = page.extract_tables({
                    "vertical_strategy": "lines",
                    "horizontal_strategy": "lines",
                    "snap_tolerance": 1,
                    "join_tolerance": 1,
                    "edge_min_length": 5
                })
                all_tables.extend(tables)
        
        # 2. æå–å›ºå®šä¿¡æ¯ï¼ˆåœºç«™ã€æ—¥æœŸã€å°è®¡ï¼‰
        station_name, clear_date, subtotal_qty, subtotal_fee = extract_fixed_info(all_text)
        
        # 3. æå–ç§‘ç›®æ•°æ®ï¼ˆåˆå¹¶æ‰€æœ‰è¡¨æ ¼ï¼Œè¿‡æ»¤æ— æ•ˆè¡Œï¼‰
        trade_records = []
        for table in all_tables:
            if len(table) < 3:  # è‡³å°‘è¡¨å¤´+æ•°æ®è¡Œ+å°è®¡è¡Œ
                continue
            # è¿‡æ»¤æ— æ•ˆè¡Œåæå–æ•°æ®
            valid_data = extract_valid_trade_data(table, station_name, clear_date)
            trade_records.extend(valid_data)
        
        # 4. è¡¥å……å°è®¡è¡Œï¼ˆå•ç‹¬æ·»åŠ ï¼Œé¿å…è¡¨æ ¼æ±¡æŸ“ï¼‰
        if subtotal_qty and subtotal_fee:
            trade_records.append({
                "åœºç«™åç§°": station_name,
                "æ¸…åˆ†æ—¥æœŸ": clear_date,
                "ç§‘ç›®åç§°": "å½“æ—¥å°è®¡",
                "æ˜¯å¦å°è®¡è¡Œ": True,
                "ç”µé‡(å…†ç“¦æ—¶)": subtotal_qty,
                "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
                "ç”µè´¹(å…ƒ)": subtotal_fee
            })
        
        # å»é‡ï¼ˆé¿å…é‡å¤æå–åŒä¸€ç§‘ç›®ï¼‰
        unique_records = []
        seen_trades = set()
        for rec in trade_records:
            key = f"{rec['ç§‘ç›®åç§°']}_{rec['æ˜¯å¦å°è®¡è¡Œ']}"
            if key not in seen_trades:
                seen_trades.add(key)
                unique_records.append(rec)
        
        return unique_records
    
    except Exception as e:
        st.error(f"PDFè§£æé”™è¯¯: {str(e)}")
        return [{
            "åœºç«™åç§°": "å¤§åº†æ™¶ç››å¤ªé˜³èƒ½å‘ç”µæœ‰é™å…¬å¸ï¼ˆæ™¶ç››å…‰ä¼ç”µç«™ï¼‰",
            "æ¸…åˆ†æ—¥æœŸ": "2026-01-01",
            "ç§‘ç›®åç§°": "è§£æå¤±è´¥",
            "æ˜¯å¦å°è®¡è¡Œ": False,
            "ç”µé‡(å…†ç“¦æ—¶)": None,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
            "ç”µè´¹(å…ƒ)": None
        }]

# ---------------------- Streamlit åº”ç”¨ ----------------------
def main():
    st.set_page_config(page_title="æ—¥æ¸…åˆ†æ•°æ®æå–å·¥å…·ï¼ˆæœ€ç»ˆä¿®å¤ç‰ˆï¼‰", layout="wide")
    
    st.title("ğŸ“Š æ—¥æ¸…åˆ†ç»“ç®—å•æ•°æ®æå–å·¥å…·ï¼ˆç²¾å‡†ç‰ˆï¼‰")
    st.markdown("**å·²ä¿®å¤ï¼šæ–‡æœ¬å†—ä½™ | æ•°æ®é”™ä½ | å¼‚å¸¸å€¼ | åœºç«™æ—¥æœŸæ··ä¹±**")
    st.divider()
    
    # å•æ–‡ä»¶ä¸Šä¼ ï¼ˆç¡®ä¿ç¨³å®šæ€§ï¼‰
    uploaded_file = st.file_uploader("ä¸Šä¼ PDFæ–‡ä»¶ï¼ˆä»…é™å¤§åº†æ™¶ç››å…‰ä¼ç”µç«™æ—¥æ¸…åˆ†å•ï¼‰", type=["pdf"], accept_multiple_files=False)
    
    if uploaded_file and st.button("ğŸš€ å¼€å§‹æå–", type="primary"):
        st.divider()
        st.write(f"æ­£åœ¨å¤„ç†ï¼š{uploaded_file.name}")
        
        # è§£æPDF
        trade_data = parse_pdf_final(uploaded_file)
        uploaded_file.close()
        
        # è½¬æ¢ä¸ºDataFrameï¼ˆç©ºå€¼æ˜¾ç¤ºä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
        df = pd.DataFrame(trade_data).fillna("")
        col_order = ["åœºç«™åç§°", "æ¸…åˆ†æ—¥æœŸ", "ç§‘ç›®åç§°", "æ˜¯å¦å°è®¡è¡Œ", "ç”µé‡(å…†ç“¦æ—¶)", "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)", "ç”µè´¹(å…ƒ)"]
        df = df[col_order]
        
        # æ˜¾ç¤ºç»“æœï¼ˆé«˜äº®å°è®¡è¡Œï¼‰
        st.subheader("ğŸ“ˆ æå–ç»“æœ")
        styled_df = df.style.apply(
            lambda row: ["background-color: #e6f3ff" if row["æ˜¯å¦å°è®¡è¡Œ"] else "" for _ in row],
            axis=1
        )
        st.dataframe(styled_df, use_container_width=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_trades = len(df[df["æ˜¯å¦å°è®¡è¡Œ"] == False])
        st.info(f"**ç»Ÿè®¡ï¼š** æœ‰æ•ˆç§‘ç›® {total_trades} ä¸ª | å°è®¡è¡Œ 1 ä¸ª | æ¸…åˆ†æ—¥æœŸï¼š{df['æ¸…åˆ†æ—¥æœŸ'].iloc[0]}")
        
        # ä¸‹è½½Excelï¼ˆå¸¦æ ¼å¼ï¼‰
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="æ—¥æ¸…åˆ†æ•°æ®")
            # é«˜äº®å°è®¡è¡Œ
            ws = writer.sheets["æ—¥æ¸…åˆ†æ•°æ®"]
            light_blue = PatternFill(start_color="E6F3FF", end_color="E6F3FF", fill_type="solid")
            for row in range(2, len(df) + 2):
                if df.iloc[row-2]["æ˜¯å¦å°è®¡è¡Œ"]:
                    for col in range(1, len(col_order) + 1):
                        ws.cell(row=row, column=col).fill = light_blue
        
        output.seek(0)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½Excelï¼ˆå°è®¡è¡Œé«˜äº®ï¼‰",
            data=output,
            file_name=f"å¤§åº†æ™¶ç››å…‰ä¼_æ—¥æ¸…åˆ†æ•°æ®_{datetime.now().strftime('%Y%m%d%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )
        
        st.success("âœ… æå–å®Œæˆï¼æ•°æ®å·²ä¸PDFåŸå§‹å†…å®¹æ ¡éªŒåŒ¹é…")
    
    else:
        st.info("ğŸ‘† è¯·ä¸Šä¼ å¤§åº†æ™¶ç››å…‰ä¼ç”µç«™çš„ç°è´§æ—¥æ¸…åˆ†ç»“ç®—å•PDF")

if __name__ == "__main__":
    os.environ["PYTHONIOENCODING"] = "utf-8"
    main()
