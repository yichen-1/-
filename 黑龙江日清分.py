import streamlit as st
import pandas as pd
import re
from datetime import datetime
import warnings
import pdfplumber
from io import BytesIO
import sys
import os
from openpyxl.styles import PatternFill

warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl.stylesheet")

# ---------------------- æ ¸å¿ƒé…ç½®ï¼ˆä¿ç•™é€šç”¨åŒ–ï¼‰ ----------------------
REDUNDANT_KEYWORDS = [
    "å†…éƒ¨ä½¿ç”¨", "CONFIDENTIAL", "è‰ç¨¿", "ç°è´§è¯•ç»“ç®—æœŸé—´", "æ—¥æ¸…åˆ†å•",
    "å…¬å¸åç§°", "ç¼–å·ï¼š", "å•ä½ï¼š", "æ¸…åˆ†æ—¥æœŸ", "åˆè®¡ç”µé‡", "åˆè®¡ç”µè´¹",
    "è®¡é‡ç”µé‡", "ç”µèƒ½é‡ç”µè´¹", "ç§‘ç›®ç¼–ç ", "å®¡æ‰¹ï¼š", "å®¡æ ¸ï¼š", "ç¼–åˆ¶ï¼š", "åŠ ç›–ç”µå­ç­¾ç« ", "dqjs"
]
TRADE_CODE_MAP = {
    "0101010101": "ä¼˜å…ˆå‘ç”µäº¤æ˜“",
    "0101020101": "ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“", 
    "0101020301": "çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“",
    "0101040203": "é€ä¸Šæµ·çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“(ç”µèƒ½é‡)",
    "0101040301": "é€è¾½å®äº¤æ˜“",
    "0101040321": "é€ååŒ—äº¤æ˜“", 
    "0101040322": "é€å±±ä¸œäº¤æ˜“",
    "0101040330": "é€æµ™æ±Ÿäº¤æ˜“",
    "0102020101": "çœå†…ç°è´§æ—¥å‰äº¤æ˜“",
    "0102020301": "çœå†…ç°è´§å®æ—¶äº¤æ˜“",
    "0102010101": "çœé—´ç°è´§æ—¥å‰äº¤æ˜“",
    "0102010201": "çœé—´ç°è´§æ—¥å†…äº¤æ˜“",
    "0202030001": "ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨",
    "0202030002": "çœé—´çœå†…ä»·å·®è´¹ç”¨",
    "0101070101": "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´",
    "0101090101": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",
    "0101100101": "åå·®è€ƒæ ¸è´¹ç”¨",
    "101070101": "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´",
    "101090101": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",
    "101100101": "åå·®è€ƒæ ¸è´¹ç”¨"
}
DATA_RULES = {
    "ç”µé‡(å…†ç“¦æ—¶)": {"min": 0, "max": 5000},
    "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": {"min": 0, "max": 2000},
    "ç”µè´¹(å…ƒ)": {"min": 0, "max": 10000000}
}

# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆç²¾å‡†ä¼˜åŒ–ï¼‰ ----------------------
def remove_redundant_text(text):
    if not text:
        return ""
    cleaned = str(text).strip()
    for keyword in REDUNDANT_KEYWORDS:
        cleaned = cleaned.replace(keyword, "")
    cleaned = re.sub(r'\s+', ' ', cleaned)
    cleaned = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\.\-\: ]', '', cleaned)
    return cleaned.strip()

def safe_convert_to_numeric(value, data_type=""):
    if value is None or pd.isna(value) or value == '':
        return None
    val_str = remove_redundant_text(value)
    if re.match(r'^\d{10}$', val_str) or val_str in ['-', '.', '', 'â€”', 'â€”â€”']:
        return None
    try:
        cleaned = re.sub(r'[^\d.-]', '', val_str.replace('ï¼Œ', ',').replace('ã€‚', '.'))
        if not cleaned or cleaned in ['-', '.']:
            return None
        num = float(cleaned)
        if data_type in DATA_RULES:
            rule = DATA_RULES[data_type]
            if num < rule["min"] or num > rule["max"]:
                return None
        return num
    except (ValueError, TypeError):
        return None

def extract_general_info(pdf_text, file_name):
    """ä¼˜åŒ–1ï¼šåœºç«™åç§°ä¼˜å…ˆå–â€œæœºç»„â€å¯¹åº”çš„åç§°"""
    clean_text = remove_redundant_text(pdf_text)
    lines = clean_text.split('\n')
    
    # 1. å…¬å¸åç§°ï¼ˆé€šç”¨æå–ï¼‰
    company_name = "æœªçŸ¥å‘ç”µå…¬å¸"
    company_match = re.search(r'å…¬å¸åç§°[:ï¼š]\s*([^ï¼Œã€‚\n]+å…¬å¸)', clean_text)
    if company_match:
        company_name = company_match.group(1).strip()
    else:
        company_match = re.search(r'([^_]+å…¬å¸|[^_]+å‘ç”µ)', file_name)
        if company_match:
            company_name = company_match.group(1).strip()
    
    # 2. åœºç«™åç§°ï¼šä¼˜å…ˆä»â€œæœºç»„ï¼šXXXâ€æå–ï¼ˆç”¨æˆ·æ ¸å¿ƒéœ€æ±‚ï¼‰
    station_name = "æœªçŸ¥åœºç«™"
   æœºç»„_match = re.search(r'æœºç»„[:ï¼š]\s*([^ï¼Œã€‚\n]+)', clean_text)  # åŒ¹é…â€œæœºç»„ï¼šæ™¶ç››å…‰ä¼ç”µç«™â€
    if æœºç»„_match:
        station_name = æœºç»„_match.group(1).strip()
    else:
        # å¤‡é€‰ï¼šä»æ–‡æœ¬ä¸­æ‰¾åœºç«™ç±»å‹å…³é”®è¯
        for line in lines:
            for type_key in ["é£ç”µåœº", "å…‰ä¼ç”µç«™", "å‚¨èƒ½ç”µç«™", "ç”µç«™", "åœºç«™"]:
                if type_key in line:
                    match = re.search(r'([^ï¼Œã€‚\n]+' + type_key + ')', line)
                    if match:
                        station_name = match.group(1).strip()
                        break
            if station_name != "æœªçŸ¥åœºç«™":
                break
        # å†å¤‡é€‰ï¼šä»æ–‡ä»¶åæå–
        if station_name == "æœªçŸ¥åœºç«™":
            for type_key in ["é£ç”µåœº", "å…‰ä¼ç”µç«™", "å‚¨èƒ½ç”µç«™", "ç”µç«™", "åœºç«™"]:
                if type_key in file_name:
                    match = re.search(r'([^_]+' + type_key + ')', file_name)
                    if match:
                        station_name = match.group(1).strip()
                        break
    
    # 3. æ¸…åˆ†æ—¥æœŸï¼ˆé€šç”¨æå–ï¼‰
    date = None
    date_patterns = [
        r'æ¸…åˆ†æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        r'ç»“ç®—æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        r'æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        r'(\d{4}-\d{1,2}-\d{1,2})'
    ]
    for pattern in date_patterns:
        match = re.search(pattern, clean_text)
        if match:
            date_str = match.group(1).strip()
            if "å¹´" in date_str:
                date_str = date_str.replace("å¹´", "-").replace("æœˆ", "-").replace("æ—¥", "")
            date = date_str
            break
    if not date:
        date_match = re.search(r'(\d{4}-\d{1,2}-\d{1,2}|\d{8})', file_name)
        if date_match:
            date_str = date_match.group(1)
            if len(date_str) == 8:
                date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
            else:
                date = date_str
    
    # 4. å°è®¡æ•°æ®ï¼ˆé€šç”¨æå–ï¼‰
    subtotal_qty = None
    subtotal_fee = None
    subtotal_match = re.search(
        r'å°è®¡[:ï¼š]?\s*ç”µé‡[:ï¼š]?\s*([\d\.]+)\s*.*?ç”µä»·[:ï¼š]?\s*([\d\.]+)\s*.*?ç”µè´¹[:ï¼š]?\s*([\d\.]+)',
        clean_text, re.DOTALL
    )
    if subtotal_match:
        subtotal_qty = safe_convert_to_numeric(subtotal_match.group(1), "ç”µé‡(å…†ç“¦æ—¶)")
        subtotal_fee = safe_convert_to_numeric(subtotal_match.group(3), "ç”µè´¹(å…ƒ)")
    
    return company_name, station_name, date, subtotal_qty, subtotal_fee

def filter_valid_table_rows(table):
    """ä¼˜åŒ–2ï¼šä¿ç•™å«â€œç»“ç®—ç±»å‹â€çš„è¡¨å¤´è¡Œï¼Œä¾¿äºåç»­å®šä½"""
    valid_rows = []
    for row in table:
        row_clean = [remove_redundant_text(cell) for cell in row]
        row_str = ''.join(row_clean).replace(" ", "")
        is_empty = all(cell == '' for cell in row_clean)
        # ä¿ç•™ï¼š1. å«â€œç»“ç®—ç±»å‹â€çš„è¡¨å¤´è¡Œï¼›2. å«ç¼–ç /ç§‘ç›®/æ•°æ®çš„è¡Œï¼›3. éç©º
        has_settlement_type = "ç»“ç®—ç±»å‹" in row_str
        has_code = any(re.match(r'^\d{9,10}$', cell.replace(" ", "")) for cell in row_clean)
        has_trade = any(len(cell) >= 4 for cell in row_clean if "ç§‘ç›®" not in cell)
        has_data = any(safe_convert_to_numeric(cell) is not None for cell in row_clean)
        
        if (has_settlement_type or has_code or has_trade or has_data) and not is_empty:
            valid_rows.append(row_clean)
    return valid_rows

def extract_valid_trade_data(table, company_name, station_name, date):
    """ä¼˜åŒ–3ï¼šä»â€œç»“ç®—ç±»å‹â€è¡¨å¤´è¡Œçš„ä¸‹ä¸€è¡Œå¼€å§‹æå–ç§‘ç›®ï¼ˆé¿å…æœªè¯†åˆ«å¼€å¤´ï¼‰"""
    trade_records = []
    valid_rows = filter_valid_table_rows(table)
    if len(valid_rows) < 2:  # è‡³å°‘éœ€è¦â€œç»“ç®—ç±»å‹â€è¡¨å¤´è¡Œ + 1è¡Œæ•°æ®
        return trade_records
    
    # æ­¥éª¤1ï¼šæ‰¾åˆ°â€œç»“ç®—ç±»å‹â€æ‰€åœ¨çš„è¡¨å¤´è¡Œï¼ˆç¡®å®šæ•°æ®èµ·å§‹ä½ç½®ï¼‰
    settlement_header_idx = -1
    for idx, row in enumerate(valid_rows):
        row_str = ''.join(row).replace(" ", "")
        if "ç»“ç®—ç±»å‹" in row_str:
            settlement_header_idx = idx
            break
    # è‹¥æœªæ‰¾åˆ°ï¼Œé»˜è®¤ç¬¬0è¡Œä¸ºè¡¨å¤´
    if settlement_header_idx == -1:
        settlement_header_idx = 0
    # æ•°æ®ä»â€œç»“ç®—ç±»å‹â€è¡Œçš„ä¸‹ä¸€è¡Œå¼€å§‹ï¼ˆç”¨æˆ·æ ¸å¿ƒéœ€æ±‚ï¼‰
    data_start_idx = settlement_header_idx + 1
    if data_start_idx >= len(valid_rows):
        return trade_records  # æ— æ•°æ®è¡Œï¼Œè¿”å›ç©º
    
    # æ­¥éª¤2ï¼šå®šä½åˆ—ï¼ˆåŸºäºâ€œç»“ç®—ç±»å‹â€è¡¨å¤´è¡Œï¼‰
    header_row = valid_rows[settlement_header_idx]
    cols = {"code": -1, "name": -1, "qty": -1, "price": -1, "fee": -1}
    for col_idx, cell in enumerate(header_row):
        cell_clean = remove_redundant_text(cell).lower()
        if "ç¼–ç " in cell_clean:
            cols["code"] = col_idx
        elif "ç»“ç®—ç±»å‹" in cell_clean:  # æ˜ç¡®â€œç»“ç®—ç±»å‹â€åˆ—ä¸ºç§‘ç›®åç§°åˆ—
            cols["name"] = col_idx
        elif "ç”µé‡" in cell_clean and "ä»·" not in cell_clean:
            cols["qty"] = col_idx
        elif "ç”µä»·" in cell_clean or "å•ä»·" in cell_clean:
            cols["price"] = col_idx
        elif "ç”µè´¹" in cell_clean or "é‡‘é¢" in cell_clean:
            cols["fee"] = col_idx
    # å…œåº•ï¼šæŒ‰â€œç¼–ç â†’ç»“ç®—ç±»å‹â†’ç”µé‡â†’ç”µä»·â†’ç”µè´¹â€å›ºå®šé¡ºåº
    if any(v == -1 for v in cols.values()) and len(header_row) >= 5:
        cols = {"code": 0, "name": 1, "qty": 2, "price": 3, "fee": 4}
    
    # æ­¥éª¤3ï¼šä»æ•°æ®èµ·å§‹è¡Œå¼€å§‹è§£æï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
    for row_idx in range(data_start_idx, len(valid_rows)):
        row = valid_rows[row_idx]
        row_str = ''.join([remove_redundant_text(cell) for cell in row]).replace(" ", "")
        
        # è·³è¿‡åˆè®¡è¡Œ
        if "åˆè®¡" in row_str and "å°è®¡" not in row_str:
            continue
        
        # æå–ç¼–ç å’Œç§‘ç›®åç§°ï¼ˆä»â€œç»“ç®—ç±»å‹â€åˆ—å–åç§°ï¼‰
        trade_code = row[cols["code"]].strip().replace(" ", "") if (cols["code"] < len(row)) else ""
        trade_text = row[cols["name"]].strip() if (cols["name"] < len(row)) else ""
        # ç²¾å‡†åŒ¹é…ç§‘ç›®åç§°
        trade_name = TRADE_CODE_MAP.get(trade_code, "")
        if not trade_name:
            trade_keywords = {
                "ä¼˜å…ˆå‘ç”µ": "ä¼˜å…ˆå‘ç”µäº¤æ˜“",
                "ä»£ç†è´­ç”µ": "ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“",
                "ç›´æ¥äº¤æ˜“": "çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“",
                "ç°è´§æ—¥å‰": "çœå†…ç°è´§æ—¥å‰äº¤æ˜“",
                "ç°è´§å®æ—¶": "çœå†…ç°è´§å®æ—¶äº¤æ˜“",
                "é˜»å¡è´¹ç”¨": "ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨",
                "ä»·å·®è´¹ç”¨": "çœé—´çœå†…ä»·å·®è´¹ç”¨",
                "ç°è´§ç»“ç®—": "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´",
                "è¾…åŠ©æœåŠ¡": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",
                "åå·®è€ƒæ ¸": "åå·®è€ƒæ ¸è´¹ç”¨"
            }
            for key, name in trade_keywords.items():
                if key in trade_text:
                    trade_name = name
                    break
        # ä»æœªåŒ¹é…åˆ°åˆ™è·³è¿‡ï¼ˆé¿å…æœªè¯†åˆ«ç§‘ç›®å¼€å¤´ï¼‰
        if not trade_name:
            continue
        
        # æå–æ•°æ®
        quantity = safe_convert_to_numeric(row[cols["qty"]], "ç”µé‡(å…†ç“¦æ—¶)") if (cols["qty"] < len(row)) else None
        price = safe_convert_to_numeric(row[cols["price"]], "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)") if (cols["price"] < len(row)) else None
        fee = safe_convert_to_numeric(row[cols["fee"]], "ç”µè´¹(å…ƒ)") if (cols["fee"] < len(row)) else None
        
        # ç‰¹æ®Šç§‘ç›®å¤„ç†
        if trade_name in ["ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨", "çœé—´çœå†…ä»·å·®è´¹ç”¨", "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š", "åå·®è€ƒæ ¸è´¹ç”¨"]:
            quantity = None
            price = None
        
        # åªä¿ç•™æœ‰æœ‰æ•ˆæ•°æ®çš„ç§‘ç›®
        if quantity is None and fee is None and trade_name not in ["ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨", "çœé—´çœå†…ä»·å·®è´¹ç”¨", "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š", "åå·®è€ƒæ ¸è´¹ç”¨"]:
            continue
        
        trade_records.append({
            "å…¬å¸åç§°": company_name,
            "åœºç«™åç§°": station_name,
            "æ¸…åˆ†æ—¥æœŸ": date,
            "ç§‘ç›®åç§°": trade_name,
            "åŸå§‹ç§‘ç›®ç¼–ç ": trade_code,
            "åŸå§‹ç§‘ç›®æ–‡æœ¬": trade_text,
            "æ˜¯å¦å°è®¡è¡Œ": "å°è®¡" in row_str,
            "ç”µé‡(å…†ç“¦æ—¶)": quantity,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": price,
            "ç”µè´¹(å…ƒ)": fee,
            "æå–çŠ¶æ€": "æˆåŠŸ"
        })
    
    return trade_records

# ---------------------- é€šç”¨PDFè§£æä¸»å‡½æ•° ----------------------
def parse_pdf_general(file_obj, file_name):
    try:
        file_obj.seek(0)
        file_bytes = BytesIO(file_obj.read())
        file_bytes.seek(0)
        
        all_text = ""
        all_tables = []
        with pdfplumber.open(file_bytes) as pdf:
            for page in pdf.pages:
                text = page.extract_text() or ""
                all_text += text + "\n"
                tables = page.extract_tables({
                    "vertical_strategy": "lines_strict",
                    "horizontal_strategy": "lines_strict",
                    "snap_tolerance": 1,
                    "join_tolerance": 1,
                    "edge_min_length": 3
                })
                all_tables.extend(tables)
        
        company_name, station_name, date, subtotal_qty, subtotal_fee = extract_general_info(all_text, file_name)
        trade_records = []
        for table in all_tables:
            if len(table) < 2:
                continue
            table_data = extract_valid_trade_data(table, company_name, station_name, date)
            trade_records.extend(table_data)
        
        # è¡¥å……å°è®¡è¡Œ
        if (subtotal_qty is not None or subtotal_fee is not None) and len(trade_records) > 0:
            trade_records.append({
                "å…¬å¸åç§°": company_name,
                "åœºç«™åç§°": station_name,
                "æ¸…åˆ†æ—¥æœŸ": date,
                "ç§‘ç›®åç§°": "å½“æ—¥å°è®¡",
                "åŸå§‹ç§‘ç›®ç¼–ç ": "SUBTOTAL",
                "åŸå§‹ç§‘ç›®æ–‡æœ¬": "å½“æ—¥å°è®¡",
                "æ˜¯å¦å°è®¡è¡Œ": True,
                "ç”µé‡(å…†ç“¦æ—¶)": subtotal_qty,
                "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
                "ç”µè´¹(å…ƒ)": subtotal_fee,
                "æå–çŠ¶æ€": "æˆåŠŸ"
            })
        
        # å»é‡
        unique_records = []
        seen_keys = set()
        for rec in trade_records:
            key = f"{rec['åœºç«™åç§°']}_{rec['ç§‘ç›®åç§°']}_{rec['åŸå§‹ç§‘ç›®ç¼–ç ']}"
            if key not in seen_keys:
                seen_keys.add(key)
                unique_records.append(rec)
        
        return unique_records if len(unique_records) > 0 else [{
            "å…¬å¸åç§°": "æœªçŸ¥å‘ç”µå…¬å¸",
            "åœºç«™åç§°": "æœªçŸ¥åœºç«™",
            "æ¸…åˆ†æ—¥æœŸ": None,
            "ç§‘ç›®åç§°": "è§£æå¤±è´¥",
            "åŸå§‹ç§‘ç›®ç¼–ç ": "",
            "åŸå§‹ç§‘ç›®æ–‡æœ¬": "",
            "æ˜¯å¦å°è®¡è¡Œ": False,
            "ç”µé‡(å…†ç“¦æ—¶)": None,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
            "ç”µè´¹(å…ƒ)": None,
            "æå–çŠ¶æ€": "è§£æé”™è¯¯"
        }]
    
    except Exception as e:
        st.error(f"PDFè§£æé”™è¯¯: {str(e)}")
        return [{
            "å…¬å¸åç§°": "æœªçŸ¥å‘ç”µå…¬å¸",
            "åœºç«™åç§°": "æœªçŸ¥åœºç«™",
            "æ¸…åˆ†æ—¥æœŸ": None,
            "ç§‘ç›®åç§°": "è§£æå¤±è´¥",
            "åŸå§‹ç§‘ç›®ç¼–ç ": "",
            "åŸå§‹ç§‘ç›®æ–‡æœ¬": "",
            "æ˜¯å¦å°è®¡è¡Œ": False,
            "ç”µé‡(å…†ç“¦æ—¶)": None,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
            "ç”µè´¹(å…ƒ)": None,
            "æå–çŠ¶æ€": "è§£æé”™è¯¯"
        }]

# ---------------------- é€šç”¨Streamlitåº”ç”¨ ----------------------
def main():
    st.set_page_config(page_title="é€šç”¨æ—¥æ¸…åˆ†æ•°æ®æå–å·¥å…·ï¼ˆæœ€ç»ˆç‰ˆï¼‰", layout="wide")
    
    st.title("ğŸ“Š é€šç”¨ç°è´§æ—¥æ¸…åˆ†ç»“ç®—å•æ•°æ®æå–å·¥å…·ï¼ˆç²¾å‡†ç‰ˆï¼‰")
    st.markdown("**æ ¸å¿ƒç‰¹æ€§ï¼šåœºç«™åå–â€œæœºç»„â€å­—æ®µ | ç§‘ç›®ä»â€œç»“ç®—ç±»å‹â€è¡Œå¼€å§‹ | æ— æœªè¯†åˆ«ç§‘ç›®å¼€å¤´**")
    st.divider()
    
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ PDFæ–‡ä»¶ï¼ˆæ”¯æŒå¤šåœºç«™æ‰¹é‡ä¸Šä¼ ï¼‰",
        type=["pdf"],
        accept_multiple_files=True
    )
    
    if uploaded_files and st.button("ğŸš€ å¼€å§‹æ‰¹é‡æå–", type="primary"):
        st.divider()
        st.subheader("âš™ï¸ å¤„ç†è¿›åº¦")
        
        all_results = []
        progress_bar = st.progress(0)
        
        for idx, file in enumerate(uploaded_files):
            st.write(f"æ­£åœ¨å¤„ç†ï¼š{file.name}")
            file_results = parse_pdf_general(file, file.name)
            all_results.extend(file_results)
            progress_bar.progress((idx + 1) / len(uploaded_files))
            file.close()
        
        progress_bar.empty()
        
        df = pd.DataFrame(all_results).fillna("")
        col_order = [
            "å…¬å¸åç§°", "åœºç«™åç§°", "æ¸…åˆ†æ—¥æœŸ", "ç§‘ç›®åç§°", 
            "åŸå§‹ç§‘ç›®ç¼–ç ", "åŸå§‹ç§‘ç›®æ–‡æœ¬", "æ˜¯å¦å°è®¡è¡Œ",
            "ç”µé‡(å…†ç“¦æ—¶)", "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)", "ç”µè´¹(å…ƒ)", "æå–çŠ¶æ€"
        ]
        df = df[col_order]
        
        st.subheader("ğŸ“ˆ æ‰¹é‡æå–ç»“æœ")
        styled_df = df.style.apply(
            lambda row: ["background-color: #e6f3ff" if row["æ˜¯å¦å°è®¡è¡Œ"] else "" for _ in row],
            axis=1
        )
        st.dataframe(styled_df, use_container_width=True)
        
        total_stations = df["åœºç«™åç§°"].nunique()
        total_trades = len(df[df["æ˜¯å¦å°è®¡è¡Œ"] == False])
        st.info(f"**ç»Ÿè®¡ï¼š** è¦†ç›–åœºç«™ {total_stations} ä¸ª | æœ‰æ•ˆç§‘ç›® {total_trades} ä¸ª | é¦–ç§‘ç›®å‡ä¸ºæœ‰æ•ˆç§‘ç›®")
        
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="å¤šåœºç«™æ—¥æ¸…åˆ†æ•°æ®")
            ws = writer.sheets["å¤šåœºç«™æ—¥æ¸…åˆ†æ•°æ®"]
            light_blue = PatternFill(start_color="E6F3FF", end_color="E6F3FF", fill_type="solid")
            for row in range(2, len(df) + 2):
                if df.iloc[row-2]["æ˜¯å¦å°è®¡è¡Œ"]:
                    for col in range(1, len(col_order) + 1):
                        ws.cell(row=row, column=col).fill = light_blue
        
        output.seek(0)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å¤šåœºç«™Excel",
            data=output,
            file_name=f"å¤šåœºç«™æ—¥æ¸…åˆ†æ•°æ®_{datetime.now().strftime('%Y%m%d%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )
        
        st.success("âœ… æ‰¹é‡æå–å®Œæˆï¼åœºç«™åç²¾å‡†å–è‡ªâ€œæœºç»„â€å­—æ®µï¼Œç§‘ç›®ä»â€œç»“ç®—ç±»å‹â€è¡Œå¼€å§‹ï¼Œæ— æœªè¯†åˆ«ç§‘ç›®å¼€å¤´")
    
    else:
        st.info("ğŸ‘† è¯·ä¸Šä¼ ä»»æ„åœºç«™çš„ç°è´§æ—¥æ¸…åˆ†ç»“ç®—å•PDFï¼ˆæ”¯æŒæ‰¹é‡ï¼‰")

if __name__ == "__main__":
    os.environ["PYTHONIOENCODING"] = "utf-8"
    main()
