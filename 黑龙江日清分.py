import streamlit as st
import pandas as pd
import re
from datetime import datetime
import warnings
import pdfplumber
from io import BytesIO
import sys
import os
from openpyxl.styles import PatternFill

warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl.stylesheet")

# ---------------------- æ ¸å¿ƒé…ç½®ï¼ˆè¡¥å…¨é€æµ™æ±Ÿäº¤æ˜“ï¼‰ ----------------------
REDUNDANT_KEYWORDS = [
    "å†…éƒ¨ä½¿ç”¨", "CONFIDENTIAL", "è‰ç¨¿", "ç°è´§è¯•ç»“ç®—æœŸé—´", "æ—¥æ¸…åˆ†å•",
    "å…¬å¸åç§°", "ç¼–å·ï¼š", "å•ä½ï¼š", "æ¸…åˆ†æ—¥æœŸ", "åˆè®¡ç”µé‡", "åˆè®¡ç”µè´¹",
    "è®¡é‡ç”µé‡", "ç”µèƒ½é‡ç”µè´¹", "ç§‘ç›®ç¼–ç ", "å®¡æ‰¹ï¼š", "å®¡æ ¸ï¼š", "ç¼–åˆ¶ï¼š", "åŠ ç›–ç”µå­ç­¾ç« ", "dqjs"
]
# è¡¥å…¨â€œé€æµ™æ±Ÿäº¤æ˜“â€ç¼–ç æ˜ å°„ï¼ˆç¡®ä¿10ä½/9ä½ç¼–ç éƒ½èƒ½åŒ¹é…ï¼‰
TRADE_CODE_MAP = {
    "0101010101": "ä¼˜å…ˆå‘ç”µäº¤æ˜“",
    "0101020101": "ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“", 
    "0101020301": "çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“",
    "0101040203": "é€ä¸Šæµ·çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“(ç”µèƒ½é‡)",
    "0101040301": "é€è¾½å®äº¤æ˜“",
    "0101040321": "é€ååŒ—äº¤æ˜“", 
    "0101040322": "é€å±±ä¸œäº¤æ˜“",
    "0101040330": "é€æµ™æ±Ÿäº¤æ˜“",  # è¡¥å…¨é€æµ™æ±Ÿäº¤æ˜“10ä½ç¼–ç 
    "0102020101": "çœå†…ç°è´§æ—¥å‰äº¤æ˜“",
    "0102020301": "çœå†…ç°è´§å®æ—¶äº¤æ˜“",
    "0102010101": "çœé—´ç°è´§æ—¥å‰äº¤æ˜“",
    "0102010201": "çœé—´ç°è´§æ—¥å†…äº¤æ˜“",
    "0202030001": "ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨",
    "0202030002": "çœé—´çœå†…ä»·å·®è´¹ç”¨",
    "0101070101": "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´",
    "0101090101": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",
    "0101100101": "åå·®è€ƒæ ¸è´¹ç”¨",
    "101040330": "é€æµ™æ±Ÿäº¤æ˜“",   # è¡¥å…¨é€æµ™æ±Ÿäº¤æ˜“9ä½ç¼–ç ï¼ˆçœç•¥å‰å¯¼0ï¼‰
    "101070101": "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´",
    "101090101": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",
    "101100101": "åå·®è€ƒæ ¸è´¹ç”¨"
}
DATA_RULES = {
    "ç”µé‡(å…†ç“¦æ—¶)": {"min": 0, "max": 5000},
    "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": {"min": 0, "max": 2000},
    "ç”µè´¹(å…ƒ)": {"min": 0, "max": 10000000}
}
# åœºç«™æ ¸å¿ƒç±»å‹å…³é”®è¯ï¼ˆç”¨äºç²¾ç®€åç§°ï¼‰
STATION_CORE_TYPES = ["é£ç”µåœº", "å…‰ä¼ç”µç«™", "å‚¨èƒ½ç”µç«™", "ç”µç«™", "åœºç«™"]

# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆå…¨ä¿®å¤ï¼‰ ----------------------
def remove_redundant_text(text):
    if not text:
        return ""
    cleaned = str(text).strip()
    for keyword in REDUNDANT_KEYWORDS:
        cleaned = cleaned.replace(keyword, "")
    cleaned = re.sub(r'\s+', ' ', cleaned)
    cleaned = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\.\-\: ]', '', cleaned)
    return cleaned.strip()

def safe_convert_to_numeric(value, data_type=""):
    if value is None or pd.isna(value) or value == '':
        return None
    val_str = remove_redundant_text(value)
    if re.match(r'^\d{10}$', val_str) or val_str in ['-', '.', '', 'â€”', 'â€”â€”']:
        return None
    try:
        cleaned = re.sub(r'[^\d.-]', '', val_str.replace('ï¼Œ', ',').replace('ã€‚', '.'))
        if not cleaned or cleaned in ['-', '.']:
            return None
        num = float(cleaned)
        if data_type in DATA_RULES:
            rule = DATA_RULES[data_type]
            if num < rule["min"] or num > rule["max"]:
                return None
        return num
    except (ValueError, TypeError):
        return None

def extract_general_info(pdf_text, file_name):
    """ä¿®å¤1ï¼šåœºç«™åç§°åªä¿ç•™æ ¸å¿ƒéƒ¨åˆ†ï¼ˆå¦‚â€œæ™¶ç››å…‰ä¼ç”µç«™â€ï¼‰"""
    clean_text = remove_redundant_text(pdf_text)
    lines = clean_text.split('\n')
    
    # 1. å…¬å¸åç§°ï¼ˆé€šç”¨æå–ï¼‰
    company_name = "æœªçŸ¥å‘ç”µå…¬å¸"
    company_match = re.search(r'å…¬å¸åç§°[:ï¼š]\s*([^ï¼Œã€‚\n]+å…¬å¸)', clean_text)
    if company_match:
        company_name = company_match.group(1).strip()
    else:
        company_match = re.search(r'([^_]+å…¬å¸|[^_]+å‘ç”µ)', file_name)
        if company_match:
            company_name = company_match.group(1).strip()
    
    # 2. åœºç«™åç§°ï¼šä¼˜å…ˆå–â€œæœºç»„â€å­—æ®µï¼Œä¸”åªä¿ç•™æ ¸å¿ƒéƒ¨åˆ†ï¼ˆä¿®å¤æ ¸å¿ƒï¼‰
    station_name = "æœªçŸ¥åœºç«™"
    # æ­¥éª¤1ï¼šä»â€œæœºç»„ï¼šXXXâ€æå–
    æœºç»„_match = re.search(r'æœºç»„[:ï¼š]\s*([^ï¼Œã€‚\n]+)', clean_text)
    if æœºç»„_match:
        station_name = æœºç»„_match.group(1).strip()
    else:
        # æ­¥éª¤2ï¼šä»æ–‡æœ¬æ‰¾åœºç«™ç±»å‹
        for line in lines:
            for type_key in STATION_CORE_TYPES:
                if type_key in line:
                    match = re.search(r'([^ï¼Œã€‚\n]+' + type_key + ')', line)
                    if match:
                        station_name = match.group(1).strip()
                        break
            if station_name != "æœªçŸ¥åœºç«™":
                break
        # æ­¥éª¤3ï¼šä»æ–‡ä»¶åæå–
        if station_name == "æœªçŸ¥åœºç«™":
            for type_key in STATION_CORE_TYPES:
                if type_key in file_name:
                    match = re.search(r'([^_]+' + type_key + ')', file_name)
                    if match:
                        station_name = match.group(1).strip()
                        break
    
    # æ­¥éª¤4ï¼šç²¾ç®€åœºç«™åç§°ï¼ˆåªä¿ç•™å«æ ¸å¿ƒç±»å‹çš„éƒ¨åˆ†ï¼Œå¦‚â€œæ™¶ç››å…‰ä¼ç”µç«™â€ï¼‰
    for type_key in STATION_CORE_TYPES:
        if type_key in station_name:
            # ä»ç¬¬ä¸€ä¸ªå‡ºç°æ ¸å¿ƒç±»å‹çš„ä½ç½®å¾€å‰å–å®Œæ•´åç§°ï¼ˆå¦‚â€œæ™¶ç››å…‰ä¼ç”µç«™â€ï¼‰
            core_idx = station_name.find(type_key)
            # å¾€å‰æ‰¾ç¬¬ä¸€ä¸ªéæ±‰å­—/å­—æ¯çš„åˆ†éš”ç¬¦ï¼ˆå¦‚â€œï¼ˆâ€â€œ-â€ï¼‰
            start_idx = 0
            for i in range(core_idx, -1, -1):
                if not (station_name[i].isalnum() or '\u4e00' <= station_name[i] <= '\u9fa5'):
                    start_idx = i + 1
                    break
            station_name = station_name[start_idx:core_idx + len(type_key)]
            break
    
    # 3. æ¸…åˆ†æ—¥æœŸï¼ˆé€šç”¨æå–ï¼‰
    date = None
    date_patterns = [
        r'æ¸…åˆ†æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        r'ç»“ç®—æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        r'æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        r'(\d{4}-\d{1,2}-\d{1,2})'
    ]
    for pattern in date_patterns:
        match = re.search(pattern, clean_text)
        if match:
            date_str = match.group(1).strip()
            if "å¹´" in date_str:
                date_str = date_str.replace("å¹´", "-").replace("æœˆ", "-").replace("æ—¥", "")
            date = date_str
            break
    if not date:
        date_match = re.search(r'(\d{4}-\d{1,2}-\d{1,2}|\d{8})', file_name)
        if date_match:
            date_str = date_match.group(1)
            if len(date_str) == 8:
                date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
            else:
                date = date_str
    
    # 4. å°è®¡æ•°æ®ï¼ˆå¼ºåŒ–æå–ï¼Œç¡®ä¿ä¸ä¸¢å¤±ï¼‰
    subtotal_qty = None
    subtotal_fee = None
    # åŒ¹é…æ›´å¤šå°è®¡æ ¼å¼ï¼šâ€œå°è®¡ï¼šç”µé‡XXX ç”µè´¹XXXâ€â€œå°è®¡ ç”µé‡XXX ç”µè´¹XXXâ€
    subtotal_patterns = [
        r'å°è®¡[:ï¼š]?\s*ç”µé‡[:ï¼š]?\s*([\d\.]+)\s*.*?ç”µè´¹[:ï¼š]?\s*([\d\.]+)',
        r'å°è®¡\s+([\d\.]+)\s+.*?\s+([\d\.]+)',  # è¡¨æ ¼ä¸­å°è®¡è¡Œï¼šâ€œå°è®¡ XXX ç”µä»· XXX ç”µè´¹ XXXâ€
        r'ç”µé‡å°è®¡[:ï¼š]\s*([\d\.]+)\s*ç”µè´¹[:ï¼š]\s*([\d\.]+)'
    ]
    for pattern in subtotal_patterns:
        subtotal_match = re.search(pattern, clean_text, re.DOTALL)
        if subtotal_match:
            qty_val = subtotal_match.group(1)
            fee_val = subtotal_match.group(2)
            if qty_val:
                subtotal_qty = safe_convert_to_numeric(qty_val, "ç”µé‡(å…†ç“¦æ—¶)")
            if fee_val:
                subtotal_fee = safe_convert_to_numeric(fee_val, "ç”µè´¹(å…ƒ)")
            if subtotal_qty and subtotal_fee:
                break  # æ‰¾åˆ°å®Œæ•´æ•°æ®åˆ™é€€å‡º
    
    return company_name, station_name, date, subtotal_qty, subtotal_fee

def filter_valid_table_rows(table):
    """ä¿®å¤2ï¼šä¿ç•™å°è®¡è¡Œï¼Œä¸å‰”é™¤"""
    valid_rows = []
    for row in table:
        row_clean = [remove_redundant_text(cell) for cell in row]
        row_str = ''.join(row_clean).replace(" ", "")
        is_empty = all(cell == '' for cell in row_clean)
        # ä¿ç•™ï¼š1. å«â€œç»“ç®—ç±»å‹â€çš„è¡¨å¤´ï¼›2. å«ç¼–ç /ç§‘ç›®/æ•°æ®çš„è¡Œï¼›3. å«â€œå°è®¡â€çš„è¡Œ
        has_settlement_type = "ç»“ç®—ç±»å‹" in row_str
        has_code = any(re.match(r'^\d{9,10}$', cell.replace(" ", "")) for cell in row_clean)
        has_trade = any(len(cell) >= 4 for cell in row_clean if "ç§‘ç›®" not in cell)
        has_data = any(safe_convert_to_numeric(cell) is not None for cell in row_clean)
        has_subtotal = "å°è®¡" in row_str
        
        if (has_settlement_type or has_code or has_trade or has_data or has_subtotal) and not is_empty:
            valid_rows.append(row_clean)
    return valid_rows

def extract_valid_trade_data(table, company_name, station_name, date):
    """ä¿®å¤3ï¼šè¡¥å…¨é€æµ™æ±Ÿäº¤æ˜“æå–ï¼Œä¿ç•™å°è®¡è¡Œ"""
    trade_records = []
    valid_rows = filter_valid_table_rows(table)
    if len(valid_rows) < 2:
        return trade_records
    
    # æ‰¾åˆ°â€œç»“ç®—ç±»å‹â€è¡¨å¤´è¡Œ
    settlement_header_idx = -1
    for idx, row in enumerate(valid_rows):
        row_str = ''.join(row).replace(" ", "")
        if "ç»“ç®—ç±»å‹" in row_str:
            settlement_header_idx = idx
            break
    if settlement_header_idx == -1:
        settlement_header_idx = 0
    data_start_idx = settlement_header_idx + 1
    if data_start_idx >= len(valid_rows):
        return trade_records
    
    # å®šä½åˆ—
    header_row = valid_rows[settlement_header_idx]
    cols = {"code": -1, "name": -1, "qty": -1, "price": -1, "fee": -1}
    for col_idx, cell in enumerate(header_row):
        cell_clean = remove_redundant_text(cell).lower()
        if "ç¼–ç " in cell_clean:
            cols["code"] = col_idx
        elif "ç»“ç®—ç±»å‹" in cell_clean:
            cols["name"] = col_idx
        elif "ç”µé‡" in cell_clean and "ä»·" not in cell_clean:
            cols["qty"] = col_idx
        elif "ç”µä»·" in cell_clean or "å•ä»·" in cell_clean:
            cols["price"] = col_idx
        elif "ç”µè´¹" in cell_clean or "é‡‘é¢" in cell_clean:
            cols["fee"] = col_idx
    if any(v == -1 for v in cols.values()) and len(header_row) >= 5:
        cols = {"code": 0, "name": 1, "qty": 2, "price": 3, "fee": 4}
    
    # è§£ææ•°æ®ï¼ˆä¿ç•™å°è®¡è¡Œï¼Œè¡¥å…¨é€æµ™æ±Ÿäº¤æ˜“ï¼‰
    for row_idx in range(data_start_idx, len(valid_rows)):
        row = valid_rows[row_idx]
        row_str = ''.join([remove_redundant_text(cell) for cell in row]).replace(" ", "")
        is_subtotal = "å°è®¡" in row_str
        
        # è·³è¿‡åˆè®¡è¡Œï¼Œä¿ç•™å°è®¡è¡Œ
        if "åˆè®¡" in row_str and not is_subtotal:
            continue
        
        # æå–ç¼–ç å’Œåç§°ï¼ˆè¡¥å…¨é€æµ™æ±Ÿäº¤æ˜“å…³é”®è¯ï¼‰
        trade_code = row[cols["code"]].strip().replace(" ", "") if (cols["code"] < len(row)) else ""
        trade_text = row[cols["name"]].strip() if (cols["name"] < len(row)) else ""
        trade_name = TRADE_CODE_MAP.get(trade_code, "")
        
        # è¡¥å…¨é€æµ™æ±Ÿäº¤æ˜“æ–‡æœ¬åŒ¹é…
        if not trade_name:
            trade_keywords = {
                "ä¼˜å…ˆå‘ç”µ": "ä¼˜å…ˆå‘ç”µäº¤æ˜“",
                "ä»£ç†è´­ç”µ": "ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“",
                "ç›´æ¥äº¤æ˜“": "çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“",
                "é€æµ™æ±Ÿ": "é€æµ™æ±Ÿäº¤æ˜“",  # è¡¥å…¨é€æµ™æ±Ÿå…³é”®è¯
                "é€ä¸Šæµ·": "é€ä¸Šæµ·çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“(ç”µèƒ½é‡)",
                "é€è¾½å®": "é€è¾½å®äº¤æ˜“",
                "é€ååŒ—": "é€ååŒ—äº¤æ˜“",
                "é€å±±ä¸œ": "é€å±±ä¸œäº¤æ˜“",
                "ç°è´§æ—¥å‰": "çœå†…ç°è´§æ—¥å‰äº¤æ˜“",
                "ç°è´§å®æ—¶": "çœå†…ç°è´§å®æ—¶äº¤æ˜“",
                "é˜»å¡è´¹ç”¨": "ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨",
                "ä»·å·®è´¹ç”¨": "çœé—´çœå†…ä»·å·®è´¹ç”¨",
                "ç°è´§ç»“ç®—": "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´",
                "è¾…åŠ©æœåŠ¡": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",
                "åå·®è€ƒæ ¸": "åå·®è€ƒæ ¸è´¹ç”¨"
            }
            for key, name in trade_keywords.items():
                if key in trade_text:
                    trade_name = name
                    break
        
        # ä¿ç•™å°è®¡è¡Œï¼ˆå³ä½¿æ— ç¼–ç ï¼‰
        if is_subtotal:
            trade_name = "å½“æ—¥å°è®¡"
            # ä»è¡Œä¸­æå–å°è®¡æ•°æ®
            subtotal_qty = None
            subtotal_fee = None
            # éå†è¡Œå•å…ƒæ ¼æ‰¾æ•°å€¼ï¼ˆé€‚é…è¡¨æ ¼ä¸­å°è®¡è¡Œæ ¼å¼ï¼‰
            nums = [safe_convert_to_numeric(cell) for cell in row if safe_convert_to_numeric(cell) is not None]
            if len(nums) >= 2:
                subtotal_qty = nums[0]  # ç¬¬ä¸€ä¸ªæ•°å€¼æ˜¯ç”µé‡
                subtotal_fee = nums[-1] # æœ€åä¸€ä¸ªæ•°å€¼æ˜¯ç”µè´¹
            trade_records.append({
                "å…¬å¸åç§°": company_name,
                "åœºç«™åç§°": station_name,
                "æ¸…åˆ†æ—¥æœŸ": date,
                "ç§‘ç›®åç§°": trade_name,
                "åŸå§‹ç§‘ç›®ç¼–ç ": trade_code,
                "åŸå§‹ç§‘ç›®æ–‡æœ¬": trade_text,
                "ç”µé‡(å…†ç“¦æ—¶)": subtotal_qty,
                "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
                "ç”µè´¹(å…ƒ)": subtotal_fee
            })
            continue
        
        # æ™®é€šç§‘ç›®ï¼šå¿…é¡»åŒ¹é…åˆ°åç§°æ‰ä¿ç•™
        if not trade_name:
            continue
        
        # æå–æ™®é€šç§‘ç›®æ•°æ®
        quantity = safe_convert_to_numeric(row[cols["qty"]], "ç”µé‡(å…†ç“¦æ—¶)") if (cols["qty"] < len(row)) else None
        price = safe_convert_to_numeric(row[cols["price"]], "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)") if (cols["price"] < len(row)) else None
        fee = safe_convert_to_numeric(row[cols["fee"]], "ç”µè´¹(å…ƒ)") if (cols["fee"] < len(row)) else None
        
        # ç‰¹æ®Šç§‘ç›®å¤„ç†
        if trade_name in ["ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨", "çœé—´çœå†…ä»·å·®è´¹ç”¨", "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š", "åå·®è€ƒæ ¸è´¹ç”¨"]:
            quantity = None
            price = None
        
        # ä¿ç•™æœ‰æ•°æ®çš„ç§‘ç›®
        if quantity is None and fee is None and trade_name not in ["ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨", "çœé—´çœå†…ä»·å·®è´¹ç”¨", "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š", "åå·®è€ƒæ ¸è´¹ç”¨"]:
            continue
        
        trade_records.append({
            "å…¬å¸åç§°": company_name,
            "åœºç«™åç§°": station_name,
            "æ¸…åˆ†æ—¥æœŸ": date,
            "ç§‘ç›®åç§°": trade_name,
            "åŸå§‹ç§‘ç›®ç¼–ç ": trade_code,
            "åŸå§‹ç§‘ç›®æ–‡æœ¬": trade_text,
            "ç”µé‡(å…†ç“¦æ—¶)": quantity,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": price,
            "ç”µè´¹(å…ƒ)": fee
        })
    
    return trade_records

# ---------------------- é€šç”¨PDFè§£æä¸»å‡½æ•° ----------------------
def parse_pdf_general(file_obj, file_name):
    try:
        file_obj.seek(0)
        file_bytes = BytesIO(file_obj.read())
        file_bytes.seek(0)
        
        all_text = ""
        all_tables = []
        with pdfplumber.open(file_bytes) as pdf:
            for page in pdf.pages:
                text = page.extract_text() or ""
                all_text += text + "\n"
                tables = page.extract_tables({
                    "vertical_strategy": "lines_strict",
                    "horizontal_strategy": "lines_strict",
                    "snap_tolerance": 1,
                    "join_tolerance": 1,
                    "edge_min_length": 3
                })
                all_tables.extend(tables)
        
        company_name, station_name, date, subtotal_qty, subtotal_fee = extract_general_info(all_text, file_name)
        trade_records = []
        for table in all_tables:
            if len(table) < 2:
                continue
            table_data = extract_valid_trade_data(table, company_name, station_name, date)
            trade_records.extend(table_data)
        
        # å…œåº•ï¼šè‹¥è¡¨æ ¼ä¸­æœªæå–åˆ°å°è®¡ï¼Œä»æ–‡æœ¬è¡¥å……
        has_subtotal = any(rec["ç§‘ç›®åç§°"] == "å½“æ—¥å°è®¡" for rec in trade_records)
        if not has_subtotal and (subtotal_qty is not None or subtotal_fee is not None):
            trade_records.append({
                "å…¬å¸åç§°": company_name,
                "åœºç«™åç§°": station_name,
                "æ¸…åˆ†æ—¥æœŸ": date,
                "ç§‘ç›®åç§°": "å½“æ—¥å°è®¡",
                "åŸå§‹ç§‘ç›®ç¼–ç ": "SUBTOTAL",
                "åŸå§‹ç§‘ç›®æ–‡æœ¬": "å½“æ—¥å°è®¡",
                "ç”µé‡(å…†ç“¦æ—¶)": subtotal_qty,
                "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
                "ç”µè´¹(å…ƒ)": subtotal_fee
            })
        
        # å»é‡
        unique_records = []
        seen_keys = set()
        for rec in trade_records:
            key = f"{rec['åœºç«™åç§°']}_{rec['ç§‘ç›®åç§°']}_{rec['åŸå§‹ç§‘ç›®ç¼–ç ']}"
            if key not in seen_keys:
                seen_keys.add(key)
                unique_records.append(rec)
        
        return unique_records if len(unique_records) > 0 else [{
            "å…¬å¸åç§°": "æœªçŸ¥å‘ç”µå…¬å¸",
            "åœºç«™åç§°": "æœªçŸ¥åœºç«™",
            "æ¸…åˆ†æ—¥æœŸ": None,
            "ç§‘ç›®åç§°": "è§£æå¤±è´¥",
            "åŸå§‹ç§‘ç›®ç¼–ç ": "",
            "åŸå§‹ç§‘ç›®æ–‡æœ¬": "",
            "ç”µé‡(å…†ç“¦æ—¶)": None,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
            "ç”µè´¹(å…ƒ)": None
        }]
    
    except Exception as e:
        st.error(f"PDFè§£æé”™è¯¯: {str(e)}")
        return [{
            "å…¬å¸åç§°": "æœªçŸ¥å‘ç”µå…¬å¸",
            "åœºç«™åç§°": "æœªçŸ¥åœºç«™",
            "æ¸…åˆ†æ—¥æœŸ": None,
            "ç§‘ç›®åç§°": "è§£æå¤±è´¥",
            "åŸå§‹ç§‘ç›®ç¼–ç ": "",
            "åŸå§‹ç§‘ç›®æ–‡æœ¬": "",
            "ç”µé‡(å…†ç“¦æ—¶)": None,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
            "ç”µè´¹(å…ƒ)": None
        }]

# ---------------------- é€šç”¨Streamlitåº”ç”¨ï¼ˆä¿®å¤4ï¼šåˆ é™¤å†—ä½™åˆ—ï¼‰ ----------------------
def main():
    st.set_page_config(page_title="é€šç”¨æ—¥æ¸…åˆ†æ•°æ®æå–å·¥å…·ï¼ˆæœ€ç»ˆç‰ˆï¼‰", layout="wide")
    
    st.title("ğŸ“Š é€šç”¨ç°è´§æ—¥æ¸…åˆ†ç»“ç®—å•æ•°æ®æå–å·¥å…·ï¼ˆç²¾å‡†ç‰ˆï¼‰")
    st.markdown("**æ ¸å¿ƒç‰¹æ€§ï¼šåœºç«™åç²¾ç®€ | é€æµ™æ±Ÿäº¤æ˜“æå– | å°è®¡è¡Œä¿ç•™ | æ— å†—ä½™åˆ—**")
    st.divider()
    
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ PDFæ–‡ä»¶ï¼ˆæ”¯æŒå¤šåœºç«™æ‰¹é‡ä¸Šä¼ ï¼‰",
        type=["pdf"],
        accept_multiple_files=True
    )
    
    if uploaded_files and st.button("ğŸš€ å¼€å§‹æ‰¹é‡æå–", type="primary"):
        st.divider()
        st.subheader("âš™ï¸ å¤„ç†è¿›åº¦")
        
        all_results = []
        progress_bar = st.progress(0)
        
        for idx, file in enumerate(uploaded_files):
            st.write(f"æ­£åœ¨å¤„ç†ï¼š{file.name}")
            file_results = parse_pdf_general(file, file.name)
            all_results.extend(file_results)
            progress_bar.progress((idx + 1) / len(uploaded_files))
            file.close()
        
        progress_bar.empty()
        
        # ä¿®å¤4ï¼šåˆ é™¤â€œæ˜¯å¦å°è®¡è¡Œâ€â€œæå–çŠ¶æ€â€åˆ—ï¼Œåªä¿ç•™éœ€è¦çš„åˆ—
        df = pd.DataFrame(all_results).fillna("")
        # åªä¿ç•™ç”¨æˆ·éœ€è¦çš„åˆ—ï¼ˆåˆ é™¤å†—ä½™åˆ—ï¼‰
        col_order = [
            "å…¬å¸åç§°", "åœºç«™åç§°", "æ¸…åˆ†æ—¥æœŸ", "ç§‘ç›®åç§°", 
            "åŸå§‹ç§‘ç›®ç¼–ç ", "åŸå§‹ç§‘ç›®æ–‡æœ¬", "ç”µé‡(å…†ç“¦æ—¶)", 
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)", "ç”µè´¹(å…ƒ)"
        ]
        # ç¡®ä¿åˆ—å­˜åœ¨ï¼ˆé¿å…KeyErrorï¼‰
        df = df[[col for col in col_order if col in df.columns]]
        
        # æ˜¾ç¤ºç»“æœï¼ˆé«˜äº®å°è®¡è¡Œï¼‰
        st.subheader("ğŸ“ˆ æ‰¹é‡æå–ç»“æœ")
        styled_df = df.style.apply(
            lambda row: ["background-color: #e6f3ff" if row["ç§‘ç›®åç§°"] == "å½“æ—¥å°è®¡" else "" for _ in row],
            axis=1
        )
        st.dataframe(styled_df, use_container_width=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_stations = df["åœºç«™åç§°"].nunique()
        total_trades = len(df[df["ç§‘ç›®åç§°"] != "å½“æ—¥å°è®¡"])
        subtotal_count = len(df[df["ç§‘ç›®åç§°"] == "å½“æ—¥å°è®¡"])
        st.info(f"**ç»Ÿè®¡ï¼š** è¦†ç›–åœºç«™ {total_stations} ä¸ª | æœ‰æ•ˆç§‘ç›® {total_trades} ä¸ª | å°è®¡è¡Œ {subtotal_count} ä¸ª")
        
        # ä¸‹è½½Excelï¼ˆæ— å†—ä½™åˆ—ï¼‰
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="å¤šåœºç«™æ—¥æ¸…åˆ†æ•°æ®")
            # é«˜äº®å°è®¡è¡Œ
            ws = writer.sheets["å¤šåœºç«™æ—¥æ¸…åˆ†æ•°æ®"]
            light_blue = PatternFill(start_color="E6F3FF", end_color="E6F3FF", fill_type="solid")
            for row in range(2, len(df) + 2):
                if df.iloc[row-2]["ç§‘ç›®åç§°"] == "å½“æ—¥å°è®¡":
                    for col in range(1, len(df.columns) + 1):
                        ws.cell(row=row, column=col).fill = light_blue
        
        output.seek(0)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å¤šåœºç«™Excel",
            data=output,
            file_name=f"å¤šåœºç«™æ—¥æ¸…åˆ†æ•°æ®_{datetime.now().strftime('%Y%m%d%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )
        
        st.success("âœ… æ‰¹é‡æå–å®Œæˆï¼åœºç«™åç²¾ç®€ä¸ºæ ¸å¿ƒåç§°ï¼Œé€æµ™æ±Ÿäº¤æ˜“+å°è®¡è¡Œå·²ä¿ç•™ï¼Œæ— å†—ä½™åˆ—")
    
    else:
        st.info("ğŸ‘† è¯·ä¸Šä¼ ä»»æ„åœºç«™çš„ç°è´§æ—¥æ¸…åˆ†ç»“ç®—å•PDFï¼ˆæ”¯æŒæ‰¹é‡ï¼‰")

if __name__ == "__main__":
    os.environ["PYTHONIOENCODING"] = "utf-8"
    main()
