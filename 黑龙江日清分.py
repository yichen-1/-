import streamlit as st
import pandas as pd
import re
from datetime import datetime
import warnings
import pdfplumber
from io import BytesIO
import sys
import os
from openpyxl.styles import PatternFill

warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl.stylesheet")

# ---------------------- æ ¸å¿ƒé…ç½®ï¼ˆå…³é”®æ‰©å±•+æ”¾å®½è§„åˆ™ï¼‰ ----------------------
# 1. å†—ä½™æ–‡æœ¬å…³é”®è¯ï¼ˆè¡¥å……æ›´å¤šPDFéè¡¨æ ¼æ–‡æœ¬ï¼‰
REDUNDANT_KEYWORDS = [
    "ååˆèƒ½æº", "å¤§åº†æ™¶ç››", "å¤ªé˜³èƒ½å‘ç”µ", "å†…éƒ¨ä½¿ç”¨", "CONFIDENTIAL", "è‰ç¨¿",
    "ç°è´§è¯•ç»“ç®—æœŸé—´", "æ—¥æ¸…åˆ†å•", "å…¬å¸åç§°", "ç¼–å·ï¼š", "å•ä½ï¼š", "æ¸…åˆ†æ—¥æœŸ",
    "åˆè®¡ç”µé‡", "åˆè®¡ç”µè´¹", "æœºç»„", "è®¡é‡ç”µé‡", "ç”µèƒ½é‡ç”µè´¹", "ç§‘ç›®ç¼–ç ", "ç»“ç®—ç±»å‹",
    "å®¡æ‰¹ï¼š", "å®¡æ ¸ï¼š", "ç¼–åˆ¶ï¼š", "åŠ ç›–ç”µå­ç­¾ç« ", "dqjs2627800", "2026å¹´1æœˆ",
    "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´", "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š", "åå·®è€ƒæ ¸è´¹ç”¨"
]
# 2. æ‰©å±•ç§‘ç›®ç¼–ç -åç§°æ˜ å°„ï¼ˆè¦†ç›–æ‰€æœ‰å¯èƒ½ç§‘ç›®ï¼‰
TRADE_CODE_MAP = {
    "0101010101": "ä¼˜å…ˆå‘ç”µäº¤æ˜“",
    "0101020101": "ç”µç½‘ä¼ä¸šä»£ç†è´­ç”µäº¤æ˜“", 
    "0101020301": "çœå†…ç”µåŠ›ç›´æ¥äº¤æ˜“",
    "0101040203": "é€ä¸Šæµ·çœé—´ç»¿è‰²ç”µåŠ›äº¤æ˜“(ç”µèƒ½é‡)",
    "0101040301": "é€è¾½å®äº¤æ˜“",
    "0101040321": "é€ååŒ—äº¤æ˜“", 
    "0101040322": "é€å±±ä¸œäº¤æ˜“",
    "0101040330": "é€æµ™æ±Ÿäº¤æ˜“",
    "0102020101": "çœå†…ç°è´§æ—¥å‰äº¤æ˜“",
    "0102020301": "çœå†…ç°è´§å®æ—¶äº¤æ˜“",
    "0102010101": "çœé—´ç°è´§æ—¥å‰äº¤æ˜“",
    "0102010201": "çœé—´ç°è´§æ—¥å†…äº¤æ˜“",
    "0202030001": "ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨",
    "0202030002": "çœé—´çœå†…ä»·å·®è´¹ç”¨",
    "0101070101": "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´",  # æ–°å¢é—æ¼ç§‘ç›®
    "0101090101": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",  # æ–°å¢é—æ¼ç§‘ç›®
    "0101100101": "åå·®è€ƒæ ¸è´¹ç”¨",      # æ–°å¢é—æ¼ç§‘ç›®
    "101070101": "ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´",   # å…¼å®¹9ä½ç¼–ç ï¼ˆçœç•¥å‰å¯¼0ï¼‰
    "101090101": "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š",
    "101100101": "åå·®è€ƒæ ¸è´¹ç”¨"
}
# 3. æ”¾å®½æ•°æ®åˆç†æ€§è§„åˆ™ï¼ˆé¿å…è¯¯è¿‡æ»¤ï¼‰
DATA_RULES = {
    "ç”µé‡(å…†ç“¦æ—¶)": {"min": 0, "max": 2000},  # ä¸Šé™ä»1000â†’2000
    "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": {"min": 0, "max": 1000}, # ä¸Šé™ä»500â†’1000
    "ç”µè´¹(å…ƒ)": {"min": 0, "max": 5000000}    # ä¸Šé™ä»100ä¸‡â†’500ä¸‡
}
# 4. å…è®¸ä¿ç•™çš„æœªè¯†åˆ«ç§‘ç›®å…³é”®è¯
ALLOWED_UNKNOWN_TRADES = ["ç°è´§ç»“ç®—ä»·å·®è°ƒæ•´", "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š", "åå·®è€ƒæ ¸è´¹ç”¨"]

# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆä¼˜åŒ–æå–èŒƒå›´ï¼‰ ----------------------
def remove_redundant_text(text):
    if not text:
        return ""
    cleaned = str(text).strip()
    for keyword in REDUNDANT_KEYWORDS:
        cleaned = cleaned.replace(keyword, "")
    cleaned = re.sub(r'\s+', ' ', cleaned)
    cleaned = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\.\-\: ]', '', cleaned)
    return cleaned.strip()

def safe_convert_to_numeric(value, data_type=""):
    if value is None or pd.isna(value) or value == '':
        return None
    
    val_str = remove_redundant_text(value)
    # å…¼å®¹9ä½/10ä½ç¼–ç ï¼ˆä¸è¿‡æ»¤9ä½æ•°å­—ï¼Œé¿å…è¯¯åˆ¤ç”µé‡ï¼‰
    if re.match(r'^\d{10}$', val_str) or val_str in ['-', '.', '', 'â€”', 'â€”â€”']:
        return None
    
    try:
        cleaned = re.sub(r'[^\d.-]', '', val_str.replace('ï¼Œ', ',').replace('ã€‚', '.'))
        if not cleaned or cleaned in ['-', '.']:
            return None
        num = float(cleaned)
        
        # æ”¾å®½æ ¡éªŒï¼šä»…è¿‡æ»¤æ˜æ˜¾å¼‚å¸¸å€¼ï¼ˆå¦‚è´Ÿæ•°ã€è¶…æå¤§å€¼ï¼‰
        if data_type in DATA_RULES:
            rule = DATA_RULES[data_type]
            if num < rule["min"] or num > rule["max"]:
                return None
        return num
    except (ValueError, TypeError):
        return None

def extract_fixed_info(pdf_text):
    # 1. å…¬å¸/åœºç«™åç§°
    company_match = re.search(r'å…¬å¸åç§°[:ï¼š]\s*([^ï¼Œã€‚\n]+æœ‰é™å…¬å¸)', pdf_text)
    company_name = company_match.group(1).strip() if company_match else "å¤§åº†æ™¶ç››å¤ªé˜³èƒ½å‘ç”µæœ‰é™å…¬å¸"
    station_name = f"{company_name}ï¼ˆæ™¶ç››å…‰ä¼ç”µç«™ï¼‰"
    
    # 2. æ¸…åˆ†æ—¥æœŸï¼ˆå…¼å®¹â€œ2026å¹´01æœˆ01æ—¥â€æ ¼å¼ï¼‰
    date_match = re.search(r'æ¸…åˆ†æ—¥æœŸ[:ï¼š]\s*(\d{4}-\d{1,2}-\d{1,2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)', pdf_text)
    clear_date = ""
    if date_match:
        date_str = date_match.group(1).strip()
        if "å¹´" in date_str:
            date_str = date_str.replace("å¹´", "-").replace("æœˆ", "-").replace("æ—¥", "")
        clear_date = date_str
    clear_date = clear_date if clear_date else "2026-01-01"
    
    # 3. å°è®¡æ•°æ®ï¼ˆå…¼å®¹â€œå°è®¡ï¼šç”µé‡ 445.245 ç”µè´¹ 35862.18â€æ ¼å¼ï¼‰
    subtotal_match = re.search(r'å°è®¡[:ï¼š]?\s*ç”µé‡[:ï¼š]?\s*([\d\.]+)\s*ç”µä»·[:ï¼š]?\s*([\d\.]+)\s*ç”µè´¹[:ï¼š]?\s*([\d\.]+)', pdf_text)
    subtotal_qty = safe_convert_to_numeric(subtotal_match.group(1), "ç”µé‡(å…†ç“¦æ—¶)") if subtotal_match else None
    subtotal_fee = safe_convert_to_numeric(subtotal_match.group(3), "ç”µè´¹(å…ƒ)") if subtotal_match else None
    
    return station_name, clear_date, subtotal_qty, subtotal_fee

def filter_valid_table_rows(table):
    """æ”¾å®½è¡Œè¿‡æ»¤ï¼šä¿ç•™æœªè¯†åˆ«ä½†å…³é”®çš„ç§‘ç›®è¡Œ"""
    valid_rows = []
    for row in table:
        row_clean = [remove_redundant_text(cell) for cell in row]
        row_str = ''.join(row_clean).replace(" ", "")
        
        # ä¿ç•™æ¡ä»¶ï¼š
        # 1. å«9/10ä½ç§‘ç›®ç¼–ç ï¼›2. å«å…³é”®ç§‘ç›®å…³é”®è¯ï¼›3. æœ‰æœ‰æ•ˆæ•°æ®ï¼ˆéç©ºä¸”éè¡¨å¤´ï¼‰
        has_code = any(re.match(r'^\d{9,10}$', cell.replace(" ", "")) for cell in row_clean)
        has_key_trade = any(trade in row_str for trade in ALLOWED_UNKNOWN_TRADES)
        has_data = any(safe_convert_to_numeric(cell) is not None for cell in row_clean if "å…ƒ" not in cell)
        is_empty = all(cell == '' for cell in row_clean)
        is_header = any(keyword in row_str for keyword in ["ç§‘ç›®ç¼–ç ", "ç»“ç®—ç±»å‹", "ç”µé‡", "ç”µä»·", "ç”µè´¹", "åˆè®¡"])
        
        if ((has_code or has_key_trade or has_data) and not is_empty and not is_header):
            valid_rows.append(row_clean)
    return valid_rows

def get_trade_name(trade_code, trade_text):
    """ä¼˜åŒ–ç§‘ç›®åç§°åŒ¹é…ï¼šä¿ç•™æœªè¯†åˆ«ä½†å…³é”®çš„ç§‘ç›®"""
    if trade_code in TRADE_CODE_MAP:
        return TRADE_CODE_MAP[trade_code]
    # åŒ¹é…æœªè¯†åˆ«ä½†å…è®¸ä¿ç•™çš„ç§‘ç›®
    for trade in ALLOWED_UNKNOWN_TRADES:
        if trade in trade_text:
            return trade
    return "æœªè¯†åˆ«ç§‘ç›®"

def extract_valid_trade_data(table, station_name, clear_date):
    """æå–æ‰€æœ‰æœ‰æ•ˆæ•°æ®ï¼ŒåŒ…æ‹¬æœªè¯†åˆ«ä½†å…³é”®çš„ç§‘ç›®"""
    trade_records = []
    valid_rows = filter_valid_table_rows(table)
    if len(valid_rows) == 0:
        return trade_records
    
    # å®šä½åˆ—ï¼ˆå…¼å®¹è¡¨å¤´è¡Œä½ç½®åç§»ï¼‰
    cols = {"code": -1, "name": -1, "qty": -1, "price": -1, "fee": -1}
    # æ£€æŸ¥å‰2è¡Œè¡¨å¤´ï¼ˆé¿å…è¡¨å¤´è¡Œåç§»å¯¼è‡´åˆ—å®šä½å¤±è´¥ï¼‰
    for header_row in valid_rows[:2]:
        for col_idx, cell in enumerate(header_row):
            cell_clean = remove_redundant_text(cell).lower()
            if "ç¼–ç " in cell_clean:
                cols["code"] = col_idx
            elif "ç±»å‹" in cell_clean or "åç§°" in cell_clean:
                cols["name"] = col_idx
            elif "ç”µé‡" in cell_clean and "ä»·" not in cell_clean:
                cols["qty"] = col_idx
            elif "ç”µä»·" in cell_clean or "å•ä»·" in cell_clean:
                cols["price"] = col_idx
            elif "ç”µè´¹" in cell_clean or "é‡‘é¢" in cell_clean:
                cols["fee"] = col_idx
        if all(v != -1 for v in cols.values()):
            break
    # å…œåº•ï¼šæŒ‰å›ºå®šé¡ºåºèµ‹å€¼ï¼ˆç¼–ç â†’ç±»å‹â†’ç”µé‡â†’ç”µä»·â†’ç”µè´¹ï¼‰
    if any(v == -1 for v in cols.values()) and len(valid_rows[0]) >= 5:
        cols = {"code": 0, "name": 1, "qty": 2, "price": 3, "fee": 4}
    
    # è§£ææ‰€æœ‰æœ‰æ•ˆè¡Œï¼ˆä¸è·³è¿‡æœªè¯†åˆ«ç§‘ç›®ï¼‰
    for row_idx, row in enumerate(valid_rows):
        # è·³è¿‡è¡¨å¤´è¡Œï¼ˆå‰2è¡Œï¼‰
        if row_idx < 2 and ("ç¼–ç " in ''.join(row) or "ç±»å‹" in ''.join(row)):
            continue
        
        # æå–ç¼–ç å’Œåç§°
        trade_code = row[cols["code"]].strip().replace(" ", "") if (cols["code"] < len(row)) else ""
        trade_text = row[cols["name"]].strip() if (cols["name"] < len(row)) else ""
        trade_name = get_trade_name(trade_code, trade_text)
        
        # æå–æ•°æ®ï¼ˆå…è®¸éƒ¨åˆ†å­—æ®µä¸ºç©ºï¼Œå¦‚ç‰¹æ®Šç§‘ç›®æ— ç”µé‡ï¼‰
        quantity = safe_convert_to_numeric(row[cols["qty"]], "ç”µé‡(å…†ç“¦æ—¶)") if (cols["qty"] < len(row)) else None
        price = safe_convert_to_numeric(row[cols["price"]], "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)") if (cols["price"] < len(row)) else None
        fee = safe_convert_to_numeric(row[cols["fee"]], "ç”µè´¹(å…ƒ)") if (cols["fee"] < len(row)) else None
        
        # ç‰¹æ®Šç§‘ç›®å¤„ç†ï¼ˆæ— ç”µé‡/ç”µä»·ï¼‰
        if trade_name in ["ä¸­é•¿æœŸåˆçº¦é˜»å¡è´¹ç”¨", "çœé—´çœå†…ä»·å·®è´¹ç”¨", "è¾…åŠ©æœåŠ¡è´¹ç”¨åˆ†æ‘Š", "åå·®è€ƒæ ¸è´¹ç”¨"]:
            quantity = None
            price = None
        
        # ä¿ç•™æ‰€æœ‰éç©ºè¡Œï¼ˆåŒ…æ‹¬æœªè¯†åˆ«ç§‘ç›®ï¼‰
        trade_records.append({
            "åœºç«™åç§°": station_name,
            "æ¸…åˆ†æ—¥æœŸ": clear_date,
            "ç§‘ç›®åç§°": trade_name,
            "åŸå§‹ç§‘ç›®ç¼–ç ": trade_code,
            "åŸå§‹ç§‘ç›®æ–‡æœ¬": trade_text,
            "æ˜¯å¦å°è®¡è¡Œ": False,
            "ç”µé‡(å…†ç“¦æ—¶)": quantity,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": price,
            "ç”µè´¹(å…ƒ)": fee,
            "æå–çŠ¶æ€": "æˆåŠŸ" if (quantity is not None or fee is not None or trade_name in ALLOWED_UNKNOWN_TRADES) else "æ— æœ‰æ•ˆæ•°æ®"
        })
    
    return trade_records

# ---------------------- PDFè§£æä¸»å‡½æ•° ----------------------
def parse_pdf_final(file_obj):
    try:
        file_obj.seek(0)
        file_bytes = BytesIO(file_obj.read())
        file_bytes.seek(0)
        
        all_text = ""
        all_tables = []
        with pdfplumber.open(file_bytes) as pdf:
            for page in pdf.pages:
                text = page.extract_text() or ""
                all_text += text + "\n"
                # å¢å¼ºè¡¨æ ¼æå–ï¼šä¿ç•™æ›´å¤šå¯èƒ½çš„è¡¨æ ¼ç»“æ„
                tables = page.extract_tables({
                    "vertical_strategy": "lines_strict",  # ä¸¥æ ¼æŒ‰çº¿æ¡æå–ï¼Œå‡å°‘æ–‡æœ¬å¹²æ‰°
                    "horizontal_strategy": "lines_strict",
                    "snap_tolerance": 0.5,
                    "join_tolerance": 0.5,
                    "edge_min_length": 3
                })
                all_tables.extend(tables)
        
        # æå–åŸºç¡€ä¿¡æ¯
        station_name, clear_date, subtotal_qty, subtotal_fee = extract_fixed_info(all_text)
        
        # æå–ç§‘ç›®æ•°æ®ï¼ˆåˆå¹¶æ‰€æœ‰è¡¨æ ¼ï¼‰
        trade_records = []
        for table in all_tables:
            if len(table) < 2:  # è‡³å°‘è¡¨å¤´+1è¡Œæ•°æ®
                continue
            table_data = extract_valid_trade_data(table, station_name, clear_date)
            trade_records.extend(table_data)
        
        # è¡¥å……å°è®¡è¡Œ
        if subtotal_qty is not None or subtotal_fee is not None:
            trade_records.append({
                "åœºç«™åç§°": station_name,
                "æ¸…åˆ†æ—¥æœŸ": clear_date,
                "ç§‘ç›®åç§°": "å½“æ—¥å°è®¡",
                "åŸå§‹ç§‘ç›®ç¼–ç ": "SUBTOTAL",
                "åŸå§‹ç§‘ç›®æ–‡æœ¬": "å½“æ—¥å°è®¡",
                "æ˜¯å¦å°è®¡è¡Œ": True,
                "ç”µé‡(å…†ç“¦æ—¶)": subtotal_qty,
                "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
                "ç”µè´¹(å…ƒ)": subtotal_fee,
                "æå–çŠ¶æ€": "æˆåŠŸ"
            })
        
        # å»é‡ï¼ˆæŒ‰ç§‘ç›®åç§°+åŸå§‹ç¼–ç ï¼‰
        unique_records = []
        seen_keys = set()
        for rec in trade_records:
            key = f"{rec['ç§‘ç›®åç§°']}_{rec['åŸå§‹ç§‘ç›®ç¼–ç ']}"
            if key not in seen_keys:
                seen_keys.add(key)
                unique_records.append(rec)
        
        return unique_records
    
    except Exception as e:
        st.error(f"PDFè§£æé”™è¯¯: {str(e)}")
        return [{
            "åœºç«™åç§°": "å¤§åº†æ™¶ç››å¤ªé˜³èƒ½å‘ç”µæœ‰é™å…¬å¸ï¼ˆæ™¶ç››å…‰ä¼ç”µç«™ï¼‰",
            "æ¸…åˆ†æ—¥æœŸ": "2026-01-01",
            "ç§‘ç›®åç§°": "è§£æå¤±è´¥",
            "åŸå§‹ç§‘ç›®ç¼–ç ": "",
            "åŸå§‹ç§‘ç›®æ–‡æœ¬": "",
            "æ˜¯å¦å°è®¡è¡Œ": False,
            "ç”µé‡(å…†ç“¦æ—¶)": None,
            "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)": None,
            "ç”µè´¹(å…ƒ)": None,
            "æå–çŠ¶æ€": "è§£æé”™è¯¯"
        }]

# ---------------------- Streamlit åº”ç”¨ ----------------------
def main():
    st.set_page_config(page_title="æ—¥æ¸…åˆ†æ•°æ®æå–å·¥å…·ï¼ˆå…¨é‡æå–ç‰ˆï¼‰", layout="wide")
    
    st.title("ğŸ“Š æ—¥æ¸…åˆ†ç»“ç®—å•æ•°æ®æå–å·¥å…·ï¼ˆå…¨é‡ç‰ˆï¼‰")
    st.markdown("**å·²ä¼˜åŒ–ï¼šå…¨ç§‘ç›®æå– | æ”¾å®½è¿‡æ»¤è§„åˆ™ | ä¿ç•™æœªè¯†åˆ«å…³é”®ç§‘ç›®**")
    st.divider()
    
    uploaded_file = st.file_uploader("ä¸Šä¼ PDFæ–‡ä»¶ï¼ˆå¤§åº†æ™¶ç››å…‰ä¼ç”µç«™æ—¥æ¸…åˆ†å•ï¼‰", type=["pdf"], accept_multiple_files=False)
    
    if uploaded_file and st.button("ğŸš€ å¼€å§‹å…¨é‡æå–", type="primary"):
        st.divider()
        st.write(f"æ­£åœ¨å¤„ç†ï¼š{uploaded_file.name}")
        
        # è§£æPDF
        trade_data = parse_pdf_final(uploaded_file)
        uploaded_file.close()
        
        # è½¬æ¢ä¸ºDataFrameï¼ˆä¿ç•™åŸå§‹ä¿¡æ¯ä¾¿äºæ ¸å¯¹ï¼‰
        df = pd.DataFrame(trade_data).fillna("")
        col_order = [
            "åœºç«™åç§°", "æ¸…åˆ†æ—¥æœŸ", "ç§‘ç›®åç§°", "åŸå§‹ç§‘ç›®ç¼–ç ", "åŸå§‹ç§‘ç›®æ–‡æœ¬",
            "æ˜¯å¦å°è®¡è¡Œ", "ç”µé‡(å…†ç“¦æ—¶)", "ç”µä»·(å…ƒ/å…†ç“¦æ—¶)", "ç”µè´¹(å…ƒ)", "æå–çŠ¶æ€"
        ]
        df = df[col_order]
        
        # æ˜¾ç¤ºç»“æœï¼ˆé«˜äº®å°è®¡è¡Œå’Œæœªè¯†åˆ«ç§‘ç›®ï¼‰
        st.subheader("ğŸ“ˆ å…¨é‡æå–ç»“æœ")
        def highlight_rows(row):
            if row["æ˜¯å¦å°è®¡è¡Œ"]:
                return ["background-color: #e6f3ff"] * len(row)
            elif row["ç§‘ç›®åç§°"] == "æœªè¯†åˆ«ç§‘ç›®" and row["æå–çŠ¶æ€"] == "æˆåŠŸ":
                return ["background-color: #fff2e6"] * len(row)
            else:
                return [""] * len(row)
        styled_df = df.style.apply(highlight_rows, axis=1)
        st.dataframe(styled_df, use_container_width=True)
        
        # ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ˜¾ç¤ºæå–è¯¦æƒ…ï¼‰
        total_trades = len(df[df["æ˜¯å¦å°è®¡è¡Œ"] == False])
        success_count = len(df[df["æå–çŠ¶æ€"] == "æˆåŠŸ"])
        unknown_count = len(df[df["ç§‘ç›®åç§°"] == "æœªè¯†åˆ«ç§‘ç›®"])
        st.info(f"**ç»Ÿè®¡ï¼š** æ€»ç§‘ç›® {total_trades} ä¸ª | æˆåŠŸæå– {success_count} ä¸ª | æœªè¯†åˆ«ç§‘ç›® {unknown_count} ä¸ª | æ¸…åˆ†æ—¥æœŸï¼š{df['æ¸…åˆ†æ—¥æœŸ'].iloc[0]}")
        
        # ä¸‹è½½Excelï¼ˆåŒ…å«åŸå§‹ç¼–ç å’Œæå–çŠ¶æ€ï¼‰
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="å…¨é‡æ—¥æ¸…åˆ†æ•°æ®")
            # é«˜äº®ç‰¹æ®Šè¡Œ
            ws = writer.sheets["å…¨é‡æ—¥æ¸…åˆ†æ•°æ®"]
            light_blue = PatternFill(start_color="E6F3FF", end_color="E6F3FF", fill_type="solid")
            light_orange = PatternFill(start_color="FFF2E6", end_color="FFF2E6", fill_type="solid")
            for row in range(2, len(df) + 2):
                row_data = df.iloc[row-2]
                if row_data["æ˜¯å¦å°è®¡è¡Œ"]:
                    for col in range(1, len(col_order) + 1):
                        ws.cell(row=row, column=col).fill = light_blue
                elif row_data["ç§‘ç›®åç§°"] == "æœªè¯†åˆ«ç§‘ç›®" and row_data["æå–çŠ¶æ€"] == "æˆåŠŸ":
                    for col in range(1, len(col_order) + 1):
                        ws.cell(row=row, column=col).fill = light_orange
        
        output.seek(0)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å…¨é‡Excelï¼ˆå«åŸå§‹ä¿¡æ¯ï¼‰",
            data=output,
            file_name=f"å¤§åº†æ™¶ç››å…‰ä¼_å…¨é‡æ—¥æ¸…åˆ†æ•°æ®_{datetime.now().strftime('%Y%m%d%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )
        
        st.success("âœ… å…¨é‡æå–å®Œæˆï¼æœªè¯†åˆ«ç§‘ç›®å·²æ ‡è®°ï¼Œå¯æ ¹æ®åŸå§‹ç¼–ç /æ–‡æœ¬è¡¥å……æ˜ å°„")
    
    else:
        st.info("ğŸ‘† è¯·ä¸Šä¼ å¤§åº†æ™¶ç››å…‰ä¼ç”µç«™çš„ç°è´§æ—¥æ¸…åˆ†ç»“ç®—å•PDF")

if __name__ == "__main__":
    os.environ["PYTHONIOENCODING"] = "utf-8"
    main()
