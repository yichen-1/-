import streamlit as st
import pandas as pd
import os
import zipfile
import re
import json
import uuid
from datetime import datetime, date, time
from openpyxl.styles import Alignment, PatternFill
from io import BytesIO
import shutil
import plotly.express as px

# -------------------------- å…¨å±€é…ç½®ï¼ˆæ ¸å¿ƒï¼šæŒ‰çœä»½éš”ç¦»ï¼‰ --------------------------
st.set_page_config(
    page_title="å¤šçœä»½æ–°èƒ½æºæ•°æ®ç®¡ç†ç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# çœä»½é…ç½®ï¼ˆå¯æ‰©å±•ï¼‰
PROVINCES = ["æ¹–åŒ—", "è´µå·"]
CURRENT_PROVINCE_KEY = "current_province"
CURRENT_FUNCTION_KEY = "current_function"  # è¿ç»­ç«ä»·è°ƒæ•´ / å…‰ä¼é£ç”µæ•°æ®ç®¡ç†

# åˆå§‹åŒ–å…¨å±€ä¼šè¯çŠ¶æ€
if CURRENT_PROVINCE_KEY not in st.session_state:
    st.session_state[CURRENT_PROVINCE_KEY] = "æ¹–åŒ—"
if CURRENT_FUNCTION_KEY not in st.session_state:
    st.session_state[CURRENT_FUNCTION_KEY] = "è¿ç»­ç«ä»·è°ƒæ•´"
# æŒ‰çœä»½éš”ç¦»çš„çŠ¶æ€å­˜å‚¨
if "province_data" not in st.session_state:
    st.session_state.province_data = {
        "æ¹–åŒ—": {
            "ç«ä»·è°ƒæ•´": {},  # æ¹–åŒ—è¿ç»­ç«ä»·è°ƒæ•´çš„æ‰€æœ‰çŠ¶æ€
            "å…‰ä¼é£ç”µ": {}   # æ¹–åŒ—å…‰ä¼é£ç”µæ•°æ®ç®¡ç†çš„æ‰€æœ‰çŠ¶æ€
        },
        "è´µå·": {
            "ç«ä»·è°ƒæ•´": {},  # è´µå·è¿ç»­ç«ä»·è°ƒæ•´ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
            "å…‰ä¼é£ç”µ": {}   # è´µå·å…‰ä¼é£ç”µæ•°æ®ç®¡ç†ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
        }
    }

# -------------------------- å·¥å…·å‡½æ•°ï¼ˆé€šç”¨+çœä»½ä¸“å±ï¼‰ --------------------------
# ========== é€šç”¨å·¥å…·å‡½æ•° ==========
def standardize_column_name(col):
    """åˆ—åæ ‡å‡†åŒ–"""
    col_str = str(col).strip() if col is not None else f"æœªçŸ¥åˆ—_{uuid.uuid4().hex[:8]}"
    col_str = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9_]', '_', col_str)
    if col_str == "" or col_str == "_":
        col_str = f"åˆ—_{uuid.uuid4().hex[:8]}"
    return col_str

def force_unique_columns(df):
    """å¼ºåˆ¶åˆ—åå”¯ä¸€"""
    df.columns = [standardize_column_name(col) for col in df.columns]
    cols = df.columns.tolist()
    unique_cols = []
    col_seen = {}
    
    for col in cols:
        if col not in col_seen:
            col_seen[col] = 0
            unique_cols.append(col)
        else:
            col_seen[col] += 1
            unique_col = f"{col}_{uuid.uuid4().hex[:4]}"
            unique_cols.append(unique_col)
    
    df.columns = unique_cols
    time_col_candidates = [i for i, col in enumerate(df.columns) if "æ—¶é—´" in col or "date" in col.lower()]
    if time_col_candidates:
        df.columns = ["æ—¶é—´" if i == time_col_candidates[0] else col for i, col in enumerate(df.columns)]
    return df

def extract_month_from_file(file, df=None):
    """ä»æ–‡ä»¶å/æ•°æ®ä¸­æå–æœˆä»½"""
    file_name = file.name
    month_patterns = [
        r'(\d{4})[-_å¹´](\d{2})',
        r'(\d{6})',
    ]
    for pattern in month_patterns:
        match = re.search(pattern, file_name)
        if match:
            if len(match.groups()) == 2:
                year, month = match.groups()
                return f"{year}-{month}"
            elif len(match.groups()) == 1:
                num_str = match.group(1)
                if len(num_str) == 6:
                    year = num_str[:4]
                    month = num_str[4:]
                    return f"{year}-{month}"
    if df is not None and "æ—¶é—´" in df.columns and not df.empty:
        df["æ—¶é—´"] = pd.to_datetime(df["æ—¶é—´"], errors="coerce")
        if not df["æ—¶é—´"].isna().all():
            first_date = df["æ—¶é—´"].dropna().iloc[0]
            return f"{first_date.year}-{first_date.month:02d}"
    now = datetime.now()
    return f"{now.year}-{now.month:02d}"

def to_excel(df, sheet_name="æ•°æ®"):
    if df.empty:
        st.warning("âš ï¸ æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”ŸæˆExcelæ–‡ä»¶")
        return BytesIO()
    df_export = force_unique_columns(df.copy())
    output = BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df_export.to_excel(writer, index=False, sheet_name=sheet_name)
    output.seek(0)
    return output

# ========== æ¹–åŒ—ä¸“å±å·¥å…·å‡½æ•°ï¼ˆè¿ç»­ç«ä»·è°ƒæ•´ï¼‰ ==========
def clean_unit_name(unit_name):
    if pd.isna(unit_name) or unit_name == '':
        return ""
    unit_str = str(unit_name).strip()
    cleaned_str = re.sub(r'(\(.*?\)|ï¼ˆ.*?ï¼‰)', '', unit_str).strip()
    return cleaned_str

def truncate_to_two_decimal(x):
    if pd.isna(x):
        return None
    try:
        return float(int(float(x) * 100)) / 100
    except:
        return None

def format_worksheet(worksheet):
    alignment = Alignment(horizontal='center', vertical='center')
    for row in worksheet.iter_rows():
        for cell in row:
            cell.alignment = alignment
    for col in worksheet.columns:
        worksheet.column_dimensions[col[0].column_letter].width = 30

def extract_key_columns(df):
    key_columns = {
        'æ—¥æœŸ': None, 'æ—¶æ®µ': None, 'æ—¶æ®µåç§°': None, 'ç”µé‡': None, 'ç”µä»·': None
    }
    for col in df.columns:
        col_str = str(col).strip().lower()
        if 'æ—¥æœŸ' in col_str:
            key_columns['æ—¥æœŸ'] = col
        elif 'æ—¶æ®µ' in col_str and 'åç§°' not in col_str:
            key_columns['æ—¶æ®µ'] = col
        elif 'æ—¶æ®µåç§°' in col_str:
            key_columns['æ—¶æ®µåç§°'] = col
        elif 'ç”µé‡' in col_str:
            key_columns['ç”µé‡'] = col
        elif 'ç”µä»·' in col_str:
            key_columns['ç”µä»·'] = col
    if key_columns['ç”µé‡'] is None and key_columns['ç”µä»·'] is None:
        return pd.DataFrame()
    selected_cols = [col for col in key_columns.values() if col is not None]
    return df[selected_cols].copy()

# -------------------------- çœä»½ä¸“å±é…ç½® --------------------------
# ========== æ¹–åŒ—é…ç½® ==========
def get_hubei_default_params():
    return {
        "é£å‚¨ä¸€æœŸ": {"online": 0.8, "prefer": 0.725, "limit": 0.7, "mechanism": 0.0},
        "é£å‚¨äºŒæœŸ": {"online": 0.8, "prefer": 0.725, "limit": 0.7, "mechanism": 0.0},
        "æ —æºª": {"online": 0.8, "prefer": 0.725, "limit": 0.7, "mechanism": 0.0},
        "å³ªå±±ä¸€æœŸ": {"online": 0.8, "prefer": 0.725, "limit": 0.7, "mechanism": 0.0},
        "åœ£å¢ƒå±±": {"online": 0.8, "prefer": 0.725, "limit": 0.7, "mechanism": 0.0},
        "è¥„åŒ—å†œå…‰": {"online": 0.8, "prefer": 0.775, "limit": 0.8, "mechanism": 0.0},
        "æµ æ°´æ¸”å…‰": {"online": 0.8, "prefer": 0.775, "limit": 0.8, "mechanism": 0.0}
    }

def get_hubei_unit_mapping():
    return {
        "è¥„é˜³ååˆå³ªå±±æ³‰æ°´é£ç”µ": "å³ªå±±ä¸€æœŸ",
        "è†é—¨ååˆåœ£å¢ƒå±±é£ç”µ": "åœ£å¢ƒå±±",
        "è¥„é˜³èšåˆå…‰ä¼": "è¥„åŒ—å†œå…‰",
        "ä¸‰ç‹é£ç”µ": "é£å‚¨ä¸€æœŸ",
        "è†é—¨ååˆæ —æºªé£ç”µ": "æ —æºª",
        "è¥„å·ååˆä¸‰ç‹é£å…‰å‚¨èƒ½ç”µç«™é£ç”µäºŒæœŸ": "é£å‚¨äºŒæœŸ",
        "æµ æ°´èšåˆå…³å£å…‰ä¼": "æµ æ°´æ¸”å…‰"
    }

HUBEI_STATION_TYPE_MAP = {
    "é£ç”µ": ["è†é—¨æ —æºª", "è†é—¨åœ£å¢ƒå±±", "è¥„åŒ—é£å‚¨äºŒæœŸ", "è¥„åŒ—é£å‚¨ä¸€æœŸ", "è¥„å·å³ªå±±ä¸€æœŸ"],
    "å…‰ä¼": ["è¥„åŒ—å†œå…‰", "æµ æ°´æ¸”å…‰"]
}

# ========== è´µå·é…ç½®ï¼ˆå¯è‡ªå®šä¹‰ï¼‰ ==========
def get_guizhou_default_params():
    # è´µå·è¿ç»­ç«ä»·è°ƒæ•´é»˜è®¤å‚æ•°ï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰
    return {
        "è´µå·é£ç”µåœº1": {"online": 0.85, "prefer": 0.75, "limit": 0.65, "mechanism": 0.0},
        "è´µå·å…‰ä¼åœº1": {"online": 0.82, "prefer": 0.78, "limit": 0.75, "mechanism": 0.0}
    }

def get_guizhou_unit_mapping():
    # è´µå·äº¤æ˜“å•å…ƒæ˜ å°„ï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰
    return {
        "è´µå·é£ç”µåœº1": "è´µå·é£ç”µåœº1",
        "è´µå·å…‰ä¼åœº1": "è´µå·å…‰ä¼åœº1"
    }

GUIZHOU_STATION_TYPE_MAP = {
    "é£ç”µ": ["è´µå·é£ç”µåœº1", "è´µå·é£ç”µåœº2"],
    "å…‰ä¼": ["è´µå·å…‰ä¼åœº1", "è´µå·å…‰ä¼åœº2"]
}

# -------------------------- æ ¸å¿ƒåŠŸèƒ½æ¨¡å— --------------------------
# ========== æ¨¡å—1ï¼šè¿ç»­ç«ä»·è°ƒæ•´ï¼ˆæ”¯æŒå¤šçœä»½ï¼‰ ==========
def bidding_adjustment_module(province):
    st.title(f"ğŸ”§ {province} - è¿ç»­ç«ä»·è°ƒæ•´")
    st.divider()
    
    # åŠ è½½çœä»½ä¸“å±é…ç½®
    if province == "æ¹–åŒ—":
        DEFAULT_PARAMS = get_hubei_default_params()
        UNIT_MAPPING = get_hubei_unit_mapping()
    elif province == "è´µå·":
        DEFAULT_PARAMS = get_guizhou_default_params()
        UNIT_MAPPING = get_guizhou_unit_mapping()
    
    # çœä»½ä¸“å±å­˜å‚¨è·¯å¾„
    STORAGE_DIR = os.path.join(os.path.expanduser('~'), f'{province}_power_analysis_storage')
    CONTRACT_DIR = os.path.join(STORAGE_DIR, 'monthly_contracts')
    PARAM_SAVE_PATH = os.path.join(STORAGE_DIR, "station_params.json")
    os.makedirs(CONTRACT_DIR, exist_ok=True)
    
    # åˆå§‹åŒ–çœä»½ä¸“å±session_state
    province_data = st.session_state.province_data[province]["ç«ä»·è°ƒæ•´"]
    if "station_params" not in province_data:
        def load_params():
            if os.path.exists(PARAM_SAVE_PATH):
                try:
                    with open(PARAM_SAVE_PATH, "r", encoding="utf-8") as f:
                        saved = json.load(f)
                    final = {}
                    for name in DEFAULT_PARAMS.keys():
                        final[name] = {**DEFAULT_PARAMS[name], **saved.get(name, {})}
                    return final
                except:
                    return DEFAULT_PARAMS.copy()
            return DEFAULT_PARAMS.copy()
        province_data["station_params"] = load_params()
    
    if "cached_editable_params" not in province_data:
        param_summary = []
        for name, params in province_data["station_params"].items():
            online = float(params.get("online", 0.8))
            prefer = float(params.get("prefer", 0.725))
            limit = float(params.get("limit", 0.7))
            mechanism = float(params.get("mechanism", 0.0))
            final_coeff = round(online - prefer - limit - mechanism, 6)
            param_summary.append({
                "åœºç«™åç§°": str(name),
                "ä¸Šç½‘ç”µé‡æŠ˜ç®—ç³»æ•°": online,
                "ä¼˜å‘ä¼˜è´­æ¯”ä¾‹": prefer,
                "é™ç”µç‡": limit,
                "æœºåˆ¶ç”µé‡æ¯”ä¾‹": mechanism,
                "æœ€ç»ˆè®¡ç®—ç³»æ•°": final_coeff
            })
        province_data["cached_editable_params"] = pd.DataFrame(param_summary)
    
    # ========== ä¾§è¾¹æ æ–‡ä»¶ç®¡ç† ==========
    with st.sidebar:
        st.subheader(f"ğŸ“ {province} - åˆçº¦æ–‡ä»¶ç®¡ç†")
        
        # 1. æ‰¹é‡ä¸Šä¼ åˆçº¦æ–‡ä»¶
        new_contract_files = st.file_uploader(
            "é€‰æ‹©åˆçº¦æ–‡ä»¶ï¼ˆæ”¯æŒæ‰¹é‡ï¼‰",
            type=["xlsx", "xls"],
            accept_multiple_files=True,
            key=f"{province}_contract_upload"
        )
        selected_month = st.text_input(
            "æ–‡ä»¶å¯¹åº”æœˆä»½ï¼ˆ2025-11ï¼‰",
            value=datetime.now().strftime("%Y-%m"),
            key=f"{province}_contract_month"
        )
        
        def save_contract_file(file, month):
            safe_name = re.sub(r'[^\w\.-]', '_', file.name)
            path = os.path.join(CONTRACT_DIR, f"{month}_{safe_name}")
            with open(path, 'wb') as f:
                f.write(file.getbuffer())
            return path
        
        if st.button("ä¿å­˜æœˆåº¦æ–‡ä»¶", key=f"{province}_save_contract"):
            if not new_contract_files:
                st.warning("âš ï¸ è¯·é€‰æ‹©æ–‡ä»¶ï¼")
            elif not selected_month:
                st.warning("âš ï¸ è¯·è¾“å…¥æœˆä»½ï¼")
            else:
                with st.spinner("ä¿å­˜ä¸­..."):
                    saved = []
                    failed = []
                    for f in new_contract_files:
                        try:
                            save_contract_file(f, selected_month)
                            saved.append(f.name)
                        except Exception as e:
                            failed.append(f"{f.name}: {str(e)}")
                    if saved:
                        st.success(f"âœ… ä¿å­˜{len(saved)}ä¸ªæ–‡ä»¶")
                    if failed:
                        st.error(f"âŒ å¤±è´¥{len(failed)}ä¸ªæ–‡ä»¶")
        
        # 2. é€‰æ‹©åˆ†ææœˆä»½
        def get_uploaded_months():
            months = set()
            for f in os.listdir(CONTRACT_DIR):
                if f.startswith(('2024-', '2025-')) and f.endswith(('.xlsx', '.xls')):
                    month = f.split('_')[0]
                    if len(month) == 7:
                        months.add(month)
            return sorted(list(months))
        
        uploaded_months = get_uploaded_months()
        if uploaded_months:
            province_data["selected_months"] = st.multiselect(
                "å‹¾é€‰åˆ†ææœˆä»½",
                uploaded_months,
                default=uploaded_months,
                key=f"{province}_selected_months"
            )
            for m in uploaded_months:
                st.write(f"â€¢ {m}ï¼š{len(os.listdir(CONTRACT_DIR))}ä¸ªæ–‡ä»¶")
        else:
            province_data["selected_months"] = []
            st.info("æš‚æ— ä¸Šä¼ æ–‡ä»¶")
        
        # 3. ä¸Šä¼ åŠŸç‡é¢„æµ‹æ–‡ä»¶
        province_data["forecast_file"] = st.file_uploader(
            "ä¸Šä¼ åŠŸç‡é¢„æµ‹æ–‡ä»¶",
            type=["xlsx", "xls"],
            key=f"{province}_forecast_upload"
        )
    
    # ========== ä¸»é¡µé¢å‚æ•°ç¼–è¾‘ ==========
    editable_df = province_data["cached_editable_params"].copy()
    required_cols = ["åœºç«™åç§°", "ä¸Šç½‘ç”µé‡æŠ˜ç®—ç³»æ•°", "ä¼˜å‘ä¼˜è´­æ¯”ä¾‹", "é™ç”µç‡", "æœºåˆ¶ç”µé‡æ¯”ä¾‹", "æœ€ç»ˆè®¡ç®—ç³»æ•°"]
    
    if editable_df.empty or not all(col in editable_df.columns for col in required_cols):
        param_summary = []
        for name, params in DEFAULT_PARAMS.items():
            final = params["online"] - params["prefer"] - params["limit"] - params["mechanism"]
            param_summary.append({
                "åœºç«™åç§°": name,
                "ä¸Šç½‘ç”µé‡æŠ˜ç®—ç³»æ•°": params["online"],
                "ä¼˜å‘ä¼˜è´­æ¯”ä¾‹": params["prefer"],
                "é™ç”µç‡": params["limit"],
                "æœºåˆ¶ç”µé‡æ¯”ä¾‹": params["mechanism"],
                "æœ€ç»ˆè®¡ç®—ç³»æ•°": round(final, 6)
            })
        editable_df = pd.DataFrame(param_summary)
        province_data["cached_editable_params"] = editable_df
    
    # å¯ç¼–è¾‘è¡¨æ ¼
    st.subheader("ğŸ“Š åœºç«™å‚æ•°é…ç½®ï¼ˆç¼–è¾‘åä¿å­˜ç”Ÿæ•ˆï¼‰")
    edited_df = st.data_editor(
        editable_df,
        use_container_width=True,
        hide_index=True,
        column_config={
            "åœºç«™åç§°": st.column_config.TextColumn(disabled=True),
            "ä¸Šç½‘ç”µé‡æŠ˜ç®—ç³»æ•°": st.column_config.NumberColumn(min_value=0, max_value=1, step=0.001, format="%.3f"),
            "ä¼˜å‘ä¼˜è´­æ¯”ä¾‹": st.column_config.NumberColumn(min_value=0, max_value=1, step=0.001, format="%.3f"),
            "é™ç”µç‡": st.column_config.NumberColumn(min_value=0, max_value=1, step=0.001, format="%.3f"),
            "æœºåˆ¶ç”µé‡æ¯”ä¾‹": st.column_config.NumberColumn(min_value=0, max_value=1, step=0.001, format="%.3f"),
            "æœ€ç»ˆè®¡ç®—ç³»æ•°": st.column_config.NumberColumn(disabled=True, format="%.6f")
        },
        key=f"{province}_params_editor"
    )
    
    # ä¿å­˜å‚æ•°æŒ‰é’®
    col1, col2 = st.columns([1, 9])
    with col1:
        if st.button("ğŸ’¾ ä¿å­˜å‚æ•°", type="primary", key=f"{province}_save_params"):
            edited_df["æœ€ç»ˆè®¡ç®—ç³»æ•°"] = edited_df.apply(
                lambda x: round(float(x["ä¸Šç½‘ç”µé‡æŠ˜ç®—ç³»æ•°"]) - float(x["ä¼˜å‘ä¼˜è´­æ¯”ä¾‹"]) - float(x["é™ç”µç‡"]) - float(x["æœºåˆ¶ç”µé‡æ¯”ä¾‹"]), 6),
                axis=1
            )
            province_data["cached_editable_params"] = edited_df
            
            updated_params = {}
            for _, row in edited_df.iterrows():
                updated_params[row["åœºç«™åç§°"]] = {
                    "online": float(row["ä¸Šç½‘ç”µé‡æŠ˜ç®—ç³»æ•°"]),
                    "prefer": float(row["ä¼˜å‘ä¼˜è´­æ¯”ä¾‹"]),
                    "limit": float(row["é™ç”µç‡"]),
                    "mechanism": float(row["æœºåˆ¶ç”µé‡æ¯”ä¾‹"])
                }
            province_data["station_params"] = updated_params
            
            # ä¿å­˜åˆ°æœ¬åœ°
            try:
                with open(PARAM_SAVE_PATH, "w", encoding="utf-8") as f:
                    json.dump(updated_params, f, ensure_ascii=False, indent=4)
                st.success("âœ… å‚æ•°ä¿å­˜æˆåŠŸï¼")
            except Exception as e:
                st.error(f"âŒ ä¿å­˜å¤±è´¥ï¼š{str(e)}")
    
    # ========== æµ‹ç®—åŠŸèƒ½ ==========
    selected_months = province_data.get("selected_months", [])
    forecast_file = province_data.get("forecast_file")
    run_disabled = not (selected_months and forecast_file)
    
    with col2:
        if st.button("ğŸš€ å¼€å§‹æµ‹ç®—", type="secondary", disabled=run_disabled, key=f"{province}_run_calc"):
            with st.spinner("æµ‹ç®—ä¸­..."):
                # æ ¸å¿ƒæµ‹ç®—é€»è¾‘ï¼ˆå¤ç”¨åŸæœ‰ä»£ç ï¼‰
                def load_contract_files(months):
                    files = []
                    for m in months:
                        for f in os.listdir(CONTRACT_DIR):
                            if f.startswith(f"{m}_") and f.endswith(('.xlsx', '.xls')):
                                with open(os.path.join(CONTRACT_DIR, f), 'rb') as fp:
                                    bytes_io = BytesIO(fp.read())
                                    bytes_io.name = f
                                    files.append(bytes_io)
                    return files
                
                def generate_integrated_file(files, mapping):
                    unit_data = {u: [] for u in mapping.keys()}
                    for f in files:
                        try:
                            xls = pd.ExcelFile(f, engine='openpyxl')
                            for sheet in xls.sheet_names:
                                df = xls.parse(sheet)
                                if df.empty:
                                    continue
                                key_df = extract_key_columns(df)
                                if key_df.empty:
                                    continue
                                for idx, row in df.iterrows():
                                    try:
                                        raw_unit = row.iloc[0]
                                        cleaned = clean_unit_name(raw_unit)
                                        if cleaned not in mapping:
                                            continue
                                        key_row = key_df.iloc[idx:idx+1].copy()
                                        key_row['æ•°æ®æ¥æº'] = f"æ–‡ä»¶ï¼š{f.name} | å·¥ä½œè¡¨ï¼š{sheet}"
                                        unit_data[cleaned].append(key_row)
                                    except:
                                        continue
                        except:
                            continue
                    
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        for unit, name in mapping.items():
                            data = unit_data.get(unit, [])
                            if not data:
                                pd.DataFrame({"æç¤º": [f"æ— æ•°æ®ï¼š{unit}"]}).to_excel(writer, sheet_name=name, index=False)
                                format_worksheet(writer.sheets[name])
                                continue
                            merged = pd.concat(data, ignore_index=True)
                            if 'æ—¥æœŸ' in merged.columns:
                                merged['æ—¥æœŸ'] = pd.to_datetime(merged['æ—¥æœŸ'], errors='coerce')
                                merged = merged.sort_values(by=['æ—¥æœŸ', 'æ—¶æ®µ']).reset_index(drop=True)
                            for col in merged.columns:
                                if 'ç”µé‡' in col or 'ç”µä»·' in col:
                                    merged[col] = merged[col].apply(truncate_to_two_decimal)
                            merged.to_excel(writer, sheet_name=name, index=False)
                            format_worksheet(writer.sheets[name])
                    output.seek(0)
                    return output
                
                def process_power_forecast(f):
                    output = BytesIO()
                    try:
                        xls = pd.ExcelFile(f, engine='openpyxl')
                        today = date.today()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            for sheet in xls.sheet_names:
                                if sheet == 'å¡«å†™è¯´æ˜':
                                    continue
                                df = xls.parse(sheet)
                                if df.empty:
                                    continue
                                time_col = df.iloc[:, 0]
                                times = []
                                for t in time_col:
                                    try:
                                        times.append(pd.to_datetime(t).time())
                                    except:
                                        times.append(None)
                                valid = [t is not None for t in times]
                                times = [t for t in times if t is not None]
                                df = df[valid].reset_index(drop=True)
                                if not times:
                                    continue
                                processed = []
                                for col in df.columns[1:]:
                                    try:
                                        col_date = pd.to_datetime(col).date()
                                        if col_date >= today:
                                            col_data = df[col]
                                            avg_data = []
                                            for i in range(0, len(col_data), 4):
                                                seg = col_data[i:i+4]
                                                avg = seg.mean() if not seg.isna().all() else None
                                                avg_data.append(truncate_to_two_decimal(avg))
                                            if any(pd.notna(avg_data)):
                                                processed.append([col_date] + avg_data)
                                    except:
                                        continue
                                if not processed:
                                    continue
                                time_points = [time(hour=i) for i in range(24)]
                                cols = ['æ—¶é—´'] + [row[0] for row in processed]
                                proc_df = pd.DataFrame(columns=cols)
                                proc_df['æ—¶é—´'] = [t.strftime('%H:%M:%S') for t in time_points]
                                for i, row in enumerate(processed):
                                    col_name = row[0]
                                    for j in range(min(24, len(row[1:]))):
                                        proc_df.loc[j, col_name] = row[j+1]
                                proc_df = proc_df.dropna(axis=1, how='all')
                                proc_df.to_excel(writer, sheet_name=sheet, index=False)
                                format_worksheet(writer.sheets[sheet])
                    except:
                        pass
                    output.seek(0)
                    return output
                
                def calculate_difference(forecast, integrated, params):
                    coeff = {n: p["online"] - p["prefer"] - p["limit"] - p["mechanism"] for n, p in params.items()}
                    result = {}
                    try:
                        forecast_xls = pd.ExcelFile(forecast, engine='openpyxl')
                        integrated_xls = pd.ExcelFile(integrated, engine='openpyxl')
                        for sheet in forecast_xls.sheet_names:
                            if sheet == 'å¡«å†™è¯´æ˜' or sheet not in integrated_xls.sheet_names or sheet not in coeff:
                                continue
                            try:
                                f_df = forecast_xls.parse(sheet)
                                i_df = integrated_xls.parse(sheet)
                            except:
                                continue
                            if f_df.empty:
                                continue
                            current_coeff = coeff[sheet]
                            time_col = f_df.iloc[:, 0]
                            forecast_cols = f_df.columns[1:]
                            q_cols = [c for c in i_df.columns if 'ç”µé‡' in c]
                            p_cols = [c for c in i_df.columns if 'ç”µä»·' in c]
                            if not q_cols:
                                continue
                            q_col = q_cols[0]
                            p_col = p_cols[0] if p_cols else None
                            processed = []
                            for idx, row in f_df.iterrows():
                                if idx >= len(i_df):
                                    continue
                                current_time = row[0]
                                row_data = [current_time]
                                current_price = truncate_to_two_decimal(i_df.iloc[idx][p_col]) if (p_col and pd.notna(i_df.iloc[idx][p_col])) else None
                                for col in forecast_cols:
                                    f_val = row[col]
                                    row_data.append(f_val)
                                    try:
                                        q_val = i_df.iloc[idx][q_col]
                                        if pd.notna(f_val) and pd.notna(q_val):
                                            corrected = float(f_val) * current_coeff
                                            diff = truncate_to_two_decimal(corrected - float(q_val))
                                            diff = max(diff, -float(q_val)) if diff < 0 else diff
                                            row_data.append(diff)
                                        else:
                                            row_data.append(None)
                                    except:
                                        row_data.append(None)
                                row_data.append(current_price)
                                processed.append(row_data)
                            new_cols = ['æ—¶é—´']
                            for col in forecast_cols:
                                new_cols.extend([col, f'{col} (ä¿®æ­£åå·®é¢)'])
                            new_cols.append('å¯¹åº”æ—¶æ®µç”µä»·')
                            proc_df = pd.DataFrame(processed, columns=new_cols)
                            if 'å¯¹åº”æ—¶æ®µç”µä»·' in proc_df.columns:
                                proc_df['å¯¹åº”æ—¶æ®µç”µä»·'] = proc_df['å¯¹åº”æ—¶æ®µç”µä»·'].apply(truncate_to_two_decimal)
                            result[sheet] = proc_df
                    except Exception as e:
                        st.error(f"æµ‹ç®—å‡ºé”™ï¼š{str(e)}")
                    return result, coeff
                
                # æ‰§è¡Œæµ‹ç®—
                contract_files = load_contract_files(selected_months)
                integrated_io = generate_integrated_file(contract_files, UNIT_MAPPING)
                forecast_processed = process_power_forecast(forecast_file)
                result_data, coeff = calculate_difference(forecast_processed, integrated_io, province_data["station_params"])
                
                # å±•ç¤ºç»“æœ
                st.divider()
                st.header("ğŸ“ˆ æµ‹ç®—ç»“æœ")
                if result_data:
                    tabs = st.tabs(list(result_data.keys()))
                    for tab, (name, df) in zip(tabs, result_data.items()):
                        with tab:
                            st.subheader(f"ğŸ“ {name}ï¼ˆç³»æ•°ï¼š{coeff[name]:.6f}ï¼‰")
                            st.dataframe(
                                df,
                                use_container_width=True,
                                hide_index=True,
                                column_config={
                                    "æ—¶é—´": st.column_config.TextColumn(width="small"),
                                    "å¯¹åº”æ—¶æ®µç”µä»·": st.column_config.NumberColumn(format="%.2f")
                                }
                            )
                            csv = df.to_csv(index=False, encoding="utf-8-sig")
                            st.download_button(
                                f"ğŸ“¥ ä¸‹è½½{name}æ•°æ®",
                                data=csv,
                                file_name=f"{name}_æµ‹ç®—ç»“æœ.csv",
                                mime="text/csv"
                            )
                else:
                    st.warning("æš‚æ— æµ‹ç®—ç»“æœï¼ˆæ•°æ®ä¸åŒ¹é…ï¼‰")
                st.success("âœ… æµ‹ç®—å®Œæˆï¼")
        
        if run_disabled:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ åˆçº¦æ–‡ä»¶+é€‰æ‹©æœˆä»½+ä¸Šä¼ é¢„æµ‹æ–‡ä»¶")

# ========== æ¨¡å—2ï¼šå…‰ä¼/é£ç”µæ•°æ®ç®¡ç†ï¼ˆæ”¯æŒå¤šçœä»½ï¼‰ ==========
def pv_wind_module(province):
    st.title(f"ğŸ“ˆ {province} - å…‰ä¼/é£ç”µæ•°æ®ç®¡ç†å·¥å…·")
    st.divider()
    
    # åŠ è½½çœä»½ä¸“å±é…ç½®
    if province == "æ¹–åŒ—":
        STATION_TYPE_MAP = HUBEI_STATION_TYPE_MAP
    elif province == "è´µå·":
        STATION_TYPE_MAP = GUIZHOU_STATION_TYPE_MAP
    
    # åˆå§‹åŒ–çœä»½ä¸“å±çŠ¶æ€
    province_data = st.session_state.province_data[province]["å…‰ä¼é£ç”µ"]
    if "multi_month_data" not in province_data:
        province_data["multi_month_data"] = {}
    if "current_month" not in province_data:
        province_data["current_month"] = ""
    if "module_config" not in province_data:
        province_data["module_config"] = {
            "generated": {
                "time_col": 4, "wind_power_col": 9, "pv_power_col": 5,
                "pv_list": "æµ æ°´æ¸”å…‰,è¥„åŒ—å†œå…‰" if province == "æ¹–åŒ—" else "è´µå·å…‰ä¼åœº1,è´µå·å…‰ä¼åœº2",
                "conv": 1000, "skip_rows": 1, "keyword": "å†å²è¶‹åŠ¿"
            },
            "hold": {"hold_col": 3, "skip_rows": 1},
            "price": {"spot_col": 1, "wind_contract_col": 2, "pv_contract_col": 3, "skip_rows": 1}
        }
    
    # å·¥å…·å‡½æ•°ï¼ˆå…‰ä¼é£ç”µä¸“å±ï¼‰
    class DataProcessor:
        @staticmethod
        @st.cache_data(show_spinner="æ¸…æ´—æ•°æ®ä¸­...", hash_funcs={BytesIO: lambda x: x.getvalue()})
        def clean_power_value(value):
            if pd.isna(value):
                return None
            val_str = str(value).strip()
            num_match = re.search(r'(\d+\.?\d*)', val_str)
            if not num_match:
                return None
            try:
                return float(num_match.group(1))
            except:
                return None
        
        @staticmethod
        @st.cache_data(show_spinner="æå–å®å‘æ•°æ®...", hash_funcs={BytesIO: lambda x: x.getvalue()})
        def extract_generated_data(file, config, station_type):
            try:
                power_col = config["wind_power_col"] if station_type == "é£ç”µ" else config["pv_power_col"]
                suffix = file.name.split(".")[-1].lower()
                engine = "openpyxl" if suffix in ["xlsx", "xlsm"] else "xlrd"
                df = pd.read_excel(
                    BytesIO(file.getvalue()),
                    header=None,
                    usecols=[config["time_col"], power_col],
                    skiprows=config["skip_rows"],
                    engine=engine
                )
                df = force_unique_columns(df)
                df = df.iloc[:, :2]
                df.columns = ["æ—¶é—´", "åŠŸç‡(kW)"]
                df["åŠŸç‡(kW)"] = df["åŠŸç‡(kW)"].apply(DataProcessor.clean_power_value)
                df["æ—¶é—´"] = pd.to_datetime(df["æ—¶é—´"], errors="coerce")
                df = df.dropna(subset=["æ—¶é—´", "åŠŸç‡(kW)"]).sort_values("æ—¶é—´").reset_index(drop=True)
                base_name = file.name.split(".")[0].split("-")[0].strip()
                month = extract_month_from_file(file, df)
                unique_name = f"{standardize_column_name(base_name)}_{month}"
                df[unique_name] = df["åŠŸç‡(kW)"] / config["conv"]
                return df[["æ—¶é—´", unique_name]].copy(), base_name, month
            except Exception as e:
                st.error(f"å¤„ç†å¤±è´¥ï¼š{str(e)}")
                return pd.DataFrame(columns=["æ—¶é—´"]), "", ""
        
        @staticmethod
        @st.cache_data(show_spinner="æå–æŒä»“æ•°æ®...", hash_funcs={BytesIO: lambda x: x.getvalue()})
        def extract_hold_data(file, config):
            try:
                suffix = file.name.split(".")[-1].lower()
                engine = "openpyxl" if suffix in ["xlsx", "xlsm"] else "xlrd"
                df = pd.read_excel(
                    BytesIO(file.getvalue()),
                    header=None,
                    usecols=[config["hold_col"]],
                    skiprows=config["skip_rows"],
                    engine=engine
                )
                df = force_unique_columns(df)
                df.columns = ["å‡€æŒæœ‰ç”µé‡"]
                df["å‡€æŒæœ‰ç”µé‡"] = pd.to_numeric(df["å‡€æŒæœ‰ç”µé‡"], errors="coerce").fillna(0)
                return round(df["å‡€æŒæœ‰ç”µé‡"].sum(), 2)
            except Exception as e:
                st.error(f"å¤„ç†å¤±è´¥ï¼š{str(e)}")
                return 0.0
        
        @staticmethod
        @st.cache_data(show_spinner="æå–ç”µä»·æ•°æ®...", hash_funcs={BytesIO: lambda x: x.getvalue()})
        def extract_price_data(file, config):
            try:
                suffix = file.name.split(".")[0].split("-")[-1].lower()
                engine = "openpyxl" if suffix in ["xlsx", "xlsm"] else "xlrd"
                df = pd.read_excel(
                    BytesIO(file.getvalue()),
                    header=None,
                    usecols=[0, config["spot_col"], config["wind_contract_col"], config["pv_contract_col"]],
                    skiprows=config["skip_rows"],
                    engine=engine,
                    nrows=24
                )
                df = force_unique_columns(df)
                df = df.iloc[:, :4]
                df.columns = ["æ—¶æ®µ", "ç°è´§å‡ä»·(å…ƒ/MWh)", "é£ç”µåˆçº¦å‡ä»·(å…ƒ/MWh)", "å…‰ä¼åˆçº¦å‡ä»·(å…ƒ/MWh)"]
                df["æ—¶æ®µ"] = [f"{i:02d}:00" for i in range(24)]
                for col in ["ç°è´§å‡ä»·(å…ƒ/MWh)", "é£ç”µåˆçº¦å‡ä»·(å…ƒ/MWh)", "å…‰ä¼åˆçº¦å‡ä»·(å…ƒ/MWh)"]:
                    df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)
                return df
            except Exception as e:
                st.error(f"å¤„ç†å¤±è´¥ï¼š{str(e)}")
                return pd.DataFrame()
        
        @staticmethod
        def calculate_24h_generated(merged_df, config):
            if merged_df.empty:
                st.warning("æ•°æ®ä¸ºç©º")
                return pd.DataFrame(), {}
            merged_df = force_unique_columns(merged_df)
            time_diff = merged_df["æ—¶é—´"].diff().dropna()
            avg_interval = time_diff.dt.total_seconds().mean() / 3600
            avg_interval = avg_interval if avg_interval > 0 else 1/4
            merged_df["æ—¶æ®µ"] = merged_df["æ—¶é—´"].dt.hour.apply(lambda x: f"{x:02d}:00")
            station_cols = [c for c in merged_df.columns if c not in ["æ—¶é—´", "æ—¶æ®µ"]]
            try:
                df_24h = merged_df.groupby("æ—¶æ®µ")[station_cols].apply(
                    lambda x: (x * avg_interval).sum()
                ).round(2).reset_index()
                df_24h = force_unique_columns(df_24h)
                total = {s: round(df_24h[s].sum(), 2) for s in station_cols if s in df_24h.columns}
                return df_24h, total
            except Exception as e:
                st.error(f"æ±‡æ€»å¤±è´¥ï¼š{str(e)}")
                return pd.DataFrame(), {}
        
        @staticmethod
        def calculate_excess_profit(gen_24h, hold_total, price_24h, month):
            if gen_24h.empty or not hold_total or price_24h.empty:
                st.warning("æ•°æ®ä¸å®Œæ•´")
                return pd.DataFrame()
            gen_24h = force_unique_columns(gen_24h)
            price_24h = force_unique_columns(price_24h)
            merged = pd.merge(gen_24h, price_24h, on="æ—¶æ®µ", how="inner")
            if merged.empty:
                st.warning("æ—¶æ®µä¸åŒ¹é…")
                return pd.DataFrame()
            result = []
            station_cols = [c for c in gen_24h.columns if c != "æ—¶æ®µ"]
            for station in station_cols:
                base_station = re.sub(r'_\d{4}-\d{2}$', '', station)
                base_station = re.sub(r'_[a-f0-9]{4,6}$', '', base_station)
                station_type = None
                contract_col = None
                for wind in STATION_TYPE_MAP["é£ç”µ"]:
                    if wind in base_station or base_station in wind:
                        station_type = "é£ç”µ"
                        contract_col = "é£ç”µåˆçº¦å‡ä»·(å…ƒ/MWh)"
                        break
                if not station_type:
                    for pv in STATION_TYPE_MAP["å…‰ä¼"]:
                        if pv in base_station or base_station in pv:
                            station_type = "å…‰ä¼"
                            contract_col = "å…‰ä¼åˆçº¦å‡ä»·(å…ƒ/MWh)"
                            break
                if not station_type:
                    continue
                total_hold = 0
                for h_station, h_val in hold_total.items():
                    if h_station in base_station or base_station in h_station:
                        total_hold = h_val
                        break
                if total_hold == 0:
                    continue
                hourly_hold = total_hold / 24
                for _, row in merged.iterrows():
                    gen = row.get(station, 0)
                    spot = row.get("ç°è´§å‡ä»·(å…ƒ/MWh)", 0)
                    contract = row.get(contract_col, 0)
                    excess_qty = max(0, gen - hourly_hold)
                    excess_profit = excess_qty * (spot - contract)
                    if excess_profit > 0:
                        result.append({
                            "åœºç«™åç§°": base_station,
                            "åœºç«™ç±»å‹": station_type,
                            "æœˆä»½": month,
                            "æ—¶æ®µ": row["æ—¶æ®µ"],
                            "æ—¶æ®µå®å‘é‡(MWh)": round(gen, 2),
                            "æ—¶æ®µæŒä»“é‡(MWh)": round(hourly_hold, 2),
                            "è¶…é¢ç”µé‡(MWh)": round(excess_qty, 2),
                            "ç°è´§å‡ä»·(å…ƒ/MWh)": round(spot, 2),
                            "åˆçº¦å‡ä»·(å…ƒ/MWh)": round(contract, 2),
                            "è¶…é¢è·åˆ©(å…ƒ)": round(excess_profit, 2)
                        })
            return pd.DataFrame(result)
    
    # è·å–å½“å‰æœˆä»½æ•°æ®
    def get_current_core_data():
        month = province_data["current_month"]
        if month not in province_data["multi_month_data"]:
            province_data["multi_month_data"][month] = {
                "generated": {"raw": pd.DataFrame(), "24h": pd.DataFrame(), "total": {}},
                "hold": {"total": {}, "config": {}},
                "price": {"24h": pd.DataFrame(), "excess_profit": pd.DataFrame()}
            }
        return province_data["multi_month_data"][month]
    
    # ========== æœˆä»½é€‰æ‹© ==========
    col_month, _ = st.columns([2, 8])
    with col_month:
        all_months = list(province_data["multi_month_data"].keys())
        if all_months:
            province_data["current_month"] = st.selectbox(
                "ğŸ“… é€‰æ‹©æœˆä»½",
                all_months,
                key=f"{province}_pv_wind_month"
            )
        else:
            st.info("â„¹ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆä¸Šä¼ æ–‡ä»¶")
    
    st.divider()
    
    # ========== æ¨¡å—1ï¼šå®å‘é…ç½® ==========
    with st.expander("ğŸ“Š æ¨¡å—1ï¼šåœºç«™å®å‘é…ç½®", expanded=False):
        st.subheader("1.1 æ•°æ®ä¸Šä¼ ")
        col1, col2 = st.columns(2)
        with col1:
            station_type = st.radio("é€‰æ‹©åœºç«™ç±»å‹", ["é£ç”µ", "å…‰ä¼"], key=f"{province}_pv_wind_type")
            gen_files = st.file_uploader(
                f"ä¸Šä¼ {station_type}å®å‘æ–‡ä»¶",
                accept_multiple_files=True,
                type=["xlsx", "xls", "xlsm"],
                key=f"{province}_pv_wind_gen_upload"
            )
        with col2:
            if gen_files:
                st.success(f"âœ… å·²ä¸Šä¼ {len(gen_files)}ä¸ªæ–‡ä»¶")
                if st.button("å¤„ç†å®å‘æ•°æ®", key=f"{province}_pv_wind_process_gen"):
                    file_month_map = {}
                    all_raw = {}
                    for f in gen_files:
                        df, station, month = DataProcessor.extract_generated_data(
                            f, province_data["module_config"]["generated"], station_type
                        )
                        if not df.empty and month:
                            if month not in file_month_map:
                                file_month_map[month] = []
                                all_raw[month] = []
                            file_month_map[month].append((df, station))
                            all_raw[month].append(df)
                    for month, dfs in all_raw.items():
                        if dfs:
                            merged = dfs[0].copy()
                            for df in dfs[1:]:
                                merged = pd.merge(merged, df, on="æ—¶é—´", how="outer")
                            merged = merged.sort_values("æ—¶é—´").dropna(subset=["æ—¶é—´"]).reset_index(drop=True)
                            core_data = get_current_core_data() if month == province_data["current_month"] else {
                                "generated": {"raw": pd.DataFrame(), "24h": pd.DataFrame(), "total": {}},
                                "hold": {"total": {}, "config": {}},
                                "price": {"24h": pd.DataFrame(), "excess_profit": pd.DataFrame()}
                            }
                            core_data["generated"]["raw"] = merged
                            gen_24h, gen_total = DataProcessor.calculate_24h_generated(merged, province_data["module_config"]["generated"])
                            core_data["generated"]["24h"] = gen_24h
                            core_data["generated"]["total"] = gen_total
                            province_data["multi_month_data"][month] = core_data
                    st.success(f"âœ… å¤„ç†å®Œæˆï¼è¯†åˆ«{len(file_month_map)}ä¸ªæœˆä»½")
                    if file_month_map and not province_data["current_month"]:
                        province_data["current_month"] = list(file_month_map.keys())[0]
        
        # é…ç½®é¡¹
        st.subheader("1.2 åˆ—ç´¢å¼•é…ç½®")
        col3, col4, col5 = st.columns(3)
        with col3:
            province_data["module_config"]["generated"]["time_col"] = st.number_input(
                "æ—¶é—´åˆ—ç´¢å¼•", min_value=0, value=province_data["module_config"]["generated"]["time_col"], key=f"{province}_pv_wind_time_col"
            )
        with col4:
            province_data["module_config"]["generated"]["wind_power_col"] = st.number_input(
                "é£ç”µåŠŸç‡åˆ—ç´¢å¼•", min_value=0, value=province_data["module_config"]["generated"]["wind_power_col"], key=f"{province}_pv_wind_wind_col"
            )
        with col5:
            province_data["module_config"]["generated"]["pv_power_col"] = st.number_input(
                "å…‰ä¼åŠŸç‡åˆ—ç´¢å¼•", min_value=0, value=province_data["module_config"]["generated"]["pv_power_col"], key=f"{province}_pv_wind_pv_col"
            )
        
        st.subheader("1.3 åŸºç¡€å‚æ•°")
        col6, col7, col8 = st.columns(3)
        with col6:
            province_data["module_config"]["generated"]["conv"] = st.number_input(
                "åŠŸç‡è½¬æ¢ç³»æ•°", min_value=1, value=province_data["module_config"]["generated"]["conv"], key=f"{province}_pv_wind_conv"
            )
        with col7:
            province_data["module_config"]["generated"]["skip_rows"] = st.number_input(
                "è·³è¿‡è¡¨å¤´è¡Œæ•°", min_value=0, value=province_data["module_config"]["generated"]["skip_rows"], key=f"{province}_pv_wind_skip_rows"
            )
        with col8:
            province_data["module_config"]["generated"]["pv_list"] = st.text_input(
                "å…‰ä¼åœºç«™åå•", value=province_data["module_config"]["generated"]["pv_list"], key=f"{province}_pv_wind_pv_list"
            )
        
        # æ•°æ®é¢„è§ˆ
        if province_data["current_month"]:
            core_data = get_current_core_data()
            if not core_data["generated"]["raw"].empty:
                st.subheader(f"ğŸ“‹ {province_data['current_month']} å®å‘æ•°æ®é¢„è§ˆ")
                raw = force_unique_columns(core_data["generated"]["raw"].copy())
                gen_24h = force_unique_columns(core_data["generated"]["24h"].copy())
                tab1, tab2 = st.tabs(["åŸå§‹æ•°æ®", "24æ—¶æ®µæ±‡æ€»"])
                with tab1:
                    st.dataframe(raw, use_container_width=True)
                    st.download_button(
                        f"ä¸‹è½½{province_data['current_month']}åŸå§‹æ•°æ®",
                        data=to_excel(raw, f"{province_data['current_month']}åŸå§‹æ•°æ®"),
                        file_name=f"{province_data['current_month']}_å®å‘åŸå§‹æ•°æ®.xlsx",
                        key=f"{province}_pv_wind_download_raw"
                    )
                with tab2:
                    st.dataframe(gen_24h, use_container_width=True)
                    st.download_button(
                        f"ä¸‹è½½{province_data['current_month']}æ±‡æ€»æ•°æ®",
                        data=to_excel(gen_24h, f"{province_data['current_month']}æ±‡æ€»æ•°æ®"),
                        file_name=f"{province_data['current_month']}_å®å‘æ±‡æ€»æ•°æ®.xlsx",
                        key=f"{province}_pv_wind_download_24h"
                    )
    
    # ========== æ¨¡å—2ï¼šæŒä»“é…ç½® ==========
    with st.expander("ğŸ“¦ æ¨¡å—2ï¼šä¸­é•¿æœŸæŒä»“é…ç½®", expanded=False):
        st.subheader("2.1 æ•°æ®ä¸Šä¼ ")
        col1, col2 = st.columns(2)
        with col1:
            hold_files = st.file_uploader(
                "ä¸Šä¼ æŒä»“æ–‡ä»¶",
                accept_multiple_files=True,
                type=["xlsx", "xls", "xlsm"],
                key=f"{province}_pv_wind_hold_upload"
            )
        with col2:
            if hold_files and province_data["current_month"]:
                st.success(f"âœ… å·²ä¸Šä¼ {len(hold_files)}ä¸ªæ–‡ä»¶")
                if st.button("å¤„ç†æŒä»“æ•°æ®", key=f"{province}_pv_wind_process_hold"):
                    core_data = get_current_core_data()
                    hold_total = {}
                    for f in hold_files:
                        month = extract_month_from_file(f)
                        if month != province_data["current_month"]:
                            st.warning(f"æ–‡ä»¶{f.name}å±äº{month}ï¼Œè·³è¿‡")
                            continue
                        base_name = f.name.split(".")[0].split("-")[0].strip()
                        total = DataProcessor.extract_hold_data(f, province_data["module_config"]["hold"])
                        hold_total[standardize_column_name(base_name)] = total
                    core_data["hold"]["total"] = hold_total
                    province_data["multi_month_data"][province_data["current_month"]] = core_data
                    st.success("âœ… æŒä»“æ•°æ®å¤„ç†å®Œæˆï¼")
                    st.write(f"ğŸ“Š {province_data['current_month']} æ€»æŒä»“ï¼š")
                    st.write(hold_total)
        
        st.subheader("2.2 é…ç½®å‚æ•°")
        province_data["module_config"]["hold"]["hold_col"] = st.number_input(
            "å‡€æŒæœ‰ç”µé‡åˆ—ç´¢å¼•", min_value=0, value=province_data["module_config"]["hold"]["hold_col"], key=f"{province}_pv_wind_hold_col"
        )
        province_data["module_config"]["hold"]["skip_rows"] = st.number_input(
            "è·³è¿‡è¡¨å¤´è¡Œæ•°", min_value=0, value=province_data["module_config"]["hold"]["skip_rows"], key=f"{province}_pv_wind_hold_skip"
        )
    
    # ========== æ¨¡å—3ï¼šç”µä»·é…ç½® ==========
    with st.expander("ğŸ’° æ¨¡å—3ï¼šæœˆåº¦ç”µä»·é…ç½®", expanded=False):
        st.subheader("3.1 æ•°æ®ä¸Šä¼ ")
        col1, col2 = st.columns(2)
        with col1:
            price_file = st.file_uploader(
                "ä¸Šä¼ ç”µä»·æ–‡ä»¶",
                accept_multiple_files=False,
                type=["xlsx", "xls", "xlsm"],
                key=f"{province}_pv_wind_price_upload"
            )
        with col2:
            if price_file and province_data["current_month"]:
                st.success("âœ… å·²ä¸Šä¼ ç”µä»·æ–‡ä»¶")
                if st.button("å¤„ç†ç”µä»·æ•°æ®", key=f"{province}_pv_wind_process_price"):
                    core_data = get_current_core_data()
                    price_df = DataProcessor.extract_price_data(price_file, province_data["module_config"]["price"])
                    core_data["price"]["24h"] = price_df
                    province_data["multi_month_data"][province_data["current_month"]] = core_data
                    st.success("âœ… ç”µä»·æ•°æ®å¤„ç†å®Œæˆï¼")
        
        st.subheader("3.2 åˆ—ç´¢å¼•é…ç½®")
        col3, col4, col5 = st.columns(3)
        with col3:
            province_data["module_config"]["price"]["spot_col"] = st.number_input(
                "ç°è´§å‡ä»·åˆ—ç´¢å¼•", min_value=0, value=province_data["module_config"]["price"]["spot_col"], key=f"{province}_pv_wind_spot_col"
            )
        with col4:
            province_data["module_config"]["price"]["wind_contract_col"] = st.number_input(
                "é£ç”µåˆçº¦åˆ—ç´¢å¼•", min_value=0, value=province_data["module_config"]["price"]["wind_contract_col"], key=f"{province}_pv_wind_wind_contract_col"
            )
        with col5:
            province_data["module_config"]["price"]["pv_contract_col"] = st.number_input(
                "å…‰ä¼åˆçº¦åˆ—ç´¢å¼•", min_value=0, value=province_data["module_config"]["price"]["pv_contract_col"], key=f"{province}_pv_wind_pv_contract_col"
            )
        
        # ç”µä»·é¢„è§ˆ
        if province_data["current_month"]:
            core_data = get_current_core_data()
            if not core_data["price"]["24h"].empty:
                st.subheader(f"ğŸ“‹ {province_data['current_month']} ç”µä»·æ•°æ®é¢„è§ˆ")
                price_df = force_unique_columns(core_data["price"]["24h"].copy())
                st.dataframe(price_df, use_container_width=True)
                st.download_button(
                    f"ä¸‹è½½{province_data['current_month']}ç”µä»·æ•°æ®",
                    data=to_excel(price_df, f"{province_data['current_month']}ç”µä»·æ•°æ®"),
                    file_name=f"{province_data['current_month']}_ç”µä»·æ•°æ®.xlsx",
                    key=f"{province}_pv_wind_download_price"
                )
    
    # ========== æ¨¡å—4ï¼šè¶…é¢è·åˆ©è®¡ç®— ==========
    if province_data["current_month"]:
        st.subheader(f"ğŸ¯ {province_data['current_month']} è¶…é¢è·åˆ©è®¡ç®—")
        core_data = get_current_core_data()
        if st.button("è®¡ç®—è¶…é¢è·åˆ©", key=f"{province}_pv_wind_calc_profit"):
            profit_df = DataProcessor.calculate_excess_profit(
                core_data["generated"]["24h"],
                core_data["hold"]["total"],
                core_data["price"]["24h"],
                province_data["current_month"]
            )
            core_data["price"]["excess_profit"] = profit_df
            province_data["multi_month_data"][province_data["current_month"]] = core_data
            
            if not profit_df.empty:
                st.success("âœ… è®¡ç®—å®Œæˆï¼")
                profit_df = force_unique_columns(profit_df)
                st.dataframe(profit_df, use_container_width=True)
                total_profit = profit_df["è¶…é¢è·åˆ©(å…ƒ)"].sum()
                st.metric(f"ğŸ’° æ€»è¶…é¢è·åˆ©", value=round(total_profit, 2))
                st.download_button(
                    f"ä¸‹è½½{province_data['current_month']}è·åˆ©æ•°æ®",
                    data=to_excel(profit_df, f"{province_data['current_month']}è·åˆ©æ•°æ®"),
                    file_name=f"{province_data['current_month']}_è¶…é¢è·åˆ©æ•°æ®.xlsx",
                    key=f"{province}_pv_wind_download_profit"
                )
                # å¯è§†åŒ–
                fig = px.bar(
                    profit_df,
                    x="æ—¶æ®µ",
                    y="è¶…é¢è·åˆ©(å…ƒ)",
                    color="åœºç«™åç§°",
                    title=f"{province_data['current_month']} åˆ†æ—¶æ®µè¶…é¢è·åˆ©",
                    barmode="group"
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("â„¹ï¸ æš‚æ— è¶…é¢è·åˆ©æ•°æ®")

# -------------------------- ä¸»ç¨‹åºå…¥å£ --------------------------
def main():
    # ä¾§è¾¹æ ï¼šçœä»½é€‰æ‹© + åŠŸèƒ½èœå•
    with st.sidebar:
        st.title("ğŸŒ å¤šçœä»½æ–°èƒ½æºç®¡ç†ç³»ç»Ÿ")
        st.divider()
        
        # 1. çœä»½é€‰æ‹©
        st.session_state[CURRENT_PROVINCE_KEY] = st.selectbox(
            "é€‰æ‹©çœä»½",
            PROVINCES,
            index=PROVINCES.index(st.session_state[CURRENT_PROVINCE_KEY]),
            key="province_selector"
        )
        
        st.divider()
        
        # 2. åŠŸèƒ½èœå•
        st.session_state[CURRENT_FUNCTION_KEY] = st.radio(
            "é€‰æ‹©åŠŸèƒ½æ¨¡å—",
            ["è¿ç»­ç«ä»·è°ƒæ•´", "å…‰ä¼/é£ç”µæ•°æ®ç®¡ç†"],
            index=0 if st.session_state[CURRENT_FUNCTION_KEY] == "è¿ç»­ç«ä»·è°ƒæ•´" else 1,
            key="function_selector"
        )
        
        st.divider()
        st.info("ğŸ’¡ åˆ‡æ¢çœä»½/åŠŸèƒ½åï¼Œæ•°æ®å°†è‡ªåŠ¨éš”ç¦»å­˜å‚¨")
    
    # æ ¹æ®é€‰æ‹©åŠ è½½å¯¹åº”æ¨¡å—
    current_province = st.session_state[CURRENT_PROVINCE_KEY]
    current_function = st.session_state[CURRENT_FUNCTION_KEY]
    
    if current_function == "è¿ç»­ç«ä»·è°ƒæ•´":
        bidding_adjustment_module(current_province)
    elif current_function == "å…‰ä¼/é£ç”µæ•°æ®ç®¡ç†":
        pv_wind_module(current_province)

if __name__ == "__main__":
    main()
